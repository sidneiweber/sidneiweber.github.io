[{"categories":null,"content":"Sistema desenvolvido para uma loja na qual trabalhava. O catálogo facilitava muito o trabalho pois era possível cadastrar e pesquisar produtos por código de diversas marcas, ter uma visão rápido do preço do produto, a aplicação dos modelos de carro, além de visualizar a foto do produto. Presente no sistema: Menu principal Cadastro de produtos Clientes Cadastro de clientes Gerenciamento de clientes (Edição) Financeiro Cadastro de contas a pagar Gerenciamento de contas a pagar (Edição e alteração de status) Orçamentos (Orçamentos cadastrados) Carrinho (Produtos inseridos no carrinho para realizar pedido venda/orçamento) Gerenciamento de contas a pagar Pesquisa de produtos Coisas que não foram feitas: Contas a receber baseado nas vendas cadastradas no sistema Melhorar a inserção dos produtos no carrinho Cadastro e edição de usuários ","date":"01/01/0001","objectID":"/catalogo-auto-pecas/:0:0","tags":null,"title":"Catálogo para Auto Peças","uri":"/catalogo-auto-pecas/"},{"categories":null,"content":"Instalação: Instalar servidor web (Apache \u0026 PHP) Editar arquivos conexao/config.php e processa.php inserindo as informações do banco de dados. Importar banco de dados que está dentro da pasta conexao ","date":"01/01/0001","objectID":"/catalogo-auto-pecas/:1:0","tags":null,"title":"Catálogo para Auto Peças","uri":"/catalogo-auto-pecas/"},{"categories":null,"content":"Github Ou para quem quiser contribuir tem Github também. ","date":"01/01/0001","objectID":"/catalogo-auto-pecas/:2:0","tags":null,"title":"Catálogo para Auto Peças","uri":"/catalogo-auto-pecas/"},{"categories":null,"content":"Imagens ","date":"01/01/0001","objectID":"/catalogo-auto-pecas/:3:0","tags":null,"title":"Catálogo para Auto Peças","uri":"/catalogo-auto-pecas/"},{"categories":null,"content":"Estoque da casa Sempre tive problema com listas de compras, as vezes esquecia de anotar alguma coisa que precisava, as vezes esquecia a própria lista que tinha feito. Por isso resolvi fazer algo simples e que não pudesse esquecer (tá na ☁️). Posso acessar de qualquer lugar desde que tenha internet. Com simples clique posso zerar o estoque do produto fazendo ele ir para a lista de compras. Estando na lista de coisas para comprar no mercado, após “jogar” o que quero no carrinho, basta poucos cliques para adicionar ao estoque novamente e o produto já não está mais na lista :magic:. Levar papel e caneta pra ficar riscando no mercado e empurrando o carrinho, isso quando não é um cesto, é pouco prático. Os produtos podem ser cadastrados usando categoria, o que ajuda na hora das compras pois a lista é ordenada por essa categoria. Produtos da mesma categoria geralmente ficam no mesmo corredor, então poupa um certo tempo na busca. O projeto foi escrito usando a liguagem node, provavelmente não dá melhor forma, mas pretendo melhorar. E como base de dados estou usando o Mysql. O layout não está dos mais bonitos mas vou arrumando as poucos. Em breve disponibilizarei no github para quem tiver interesse. ","date":"01/01/0001","objectID":"/estoque-da-casa/:0:0","tags":null,"title":"Estoque da casa","uri":"/estoque-da-casa/"},{"categories":null,"content":"Imagens Desktop e Mobile ","date":"01/01/0001","objectID":"/estoque-da-casa/:1:0","tags":null,"title":"Estoque da casa","uri":"/estoque-da-casa/"},{"categories":null,"content":"Projeto feito para gerar senhas seguras.","date":"01/01/0001","objectID":"/gerador-senhas/","tags":null,"title":"Gerador de senhas","uri":"/gerador-senhas/"},{"categories":null,"content":"\u003c!DOCTYPE html\u003e Gerador de senhas randômico Gerador de senhas randômico Conjunto de caracteres: Customizado: Tamanho:  characters Entropia:  bits Senha:   Fontes da entropia: ✓ Math.random() (low security) crypto.getRandomValues() (high security) ","date":"01/01/0001","objectID":"/gerador-senhas/:0:0","tags":null,"title":"Gerador de senhas","uri":"/gerador-senhas/"},{"categories":null,"content":"O Projeto PRI teve uma história bem diferente! Uma menina + Um sonho + Uma pessoa necessitando! Veja o video que explica todo a história! ","date":"01/01/0001","objectID":"/projeto-pri/:0:0","tags":null,"title":"Projeto PRI","uri":"/projeto-pri/"},{"categories":null,"content":"O que eu tentei fazer Gravar frases usando python: ","date":"01/01/0001","objectID":"/projeto-pri/:0:1","tags":null,"title":"Projeto PRI","uri":"/projeto-pri/"},{"categories":null,"content":"O que achei mais interessante Consegui fazer uma interface com electron que com um clique é possível ouvir frases pré programadas Github do projeto com várias versões criadas pela comunidade: https://github.com/projeto-pri ","date":"01/01/0001","objectID":"/projeto-pri/:0:2","tags":null,"title":"Projeto PRI","uri":"/projeto-pri/"},{"categories":null,"content":"Projeto que fiz para facilitar o envio de arquivos de uma máquina para outra com o SCP, usando YAD. SCP Fácil ","date":"01/01/0001","objectID":"/scp-facil/:0:0","tags":null,"title":"SCP Fácil","uri":"/scp-facil/"},{"categories":null,"content":" O Redis é um banco de dados em memória de código aberto, conhecido por seu alto desempenho e versatilidade. Entretanto um polêmica foi criada recentemente com a alteração do tipo de licença, deixando de ser um software livre. Diversas empresas já estão correndo para criar ou buscar alternativas que sejam mais atrativas e com certeza olhem para a comunidade. ","date":"02/04/2024","objectID":"/4-alternativas-ao-redis/","tags":["redis","database"],"title":"4 Alternativas ao Redis","uri":"/4-alternativas-ao-redis/"},{"categories":null,"content":"Mas o que é esse tal de Redis? O Redis é um banco de dados em memória de código aberto, conhecido por seu alto desempenho e versatilidade. Utilizado principalmente como um armazenamento em cache, ele também suporta estruturas de dados complexas, como listas, conjuntos e mapas, o que o torna ideal para aplicativos que necessitam de baixa latência e alta escalabilidade. Além disso, sua capacidade de persistência e replicação o tornam uma opção viável para casos de uso que exigem alta disponibilidade e confiabilidade nos dados. Porém, uma polêmica foi lançada recentemente, a empresa por trás do Redis decidiu mudar a licença de distribuição, e com essa nova licença o projeto passará a não ter mais uma licença que se enquadre como software livre. Caso queira mais detalhes sobre o caso, recomendo assistir o vídeo abaixo que contém bastante informação: As principais alternativas ","date":"02/04/2024","objectID":"/4-alternativas-ao-redis/:0:0","tags":["redis","database"],"title":"4 Alternativas ao Redis","uri":"/4-alternativas-ao-redis/"},{"categories":null,"content":"Valkey O projeto mais promissor até o momento, pois o projeto é basicamente uma continuação do Redis mantendo as licenças no modelo opensource. O nome é baseado na estrutura do banco, chave-valor (key-value = Valkey). Inclusive a contribuição nesse projeto tem sido de empresas e pessoas que já apoiavam o projeto anteriormente, como AWS, Google e Oracle. Valkey foi lançado pela Linux Foundation. https://www.linuxfoundation.org/press/linux-foundation-launches-open-source-valkey-community https://github.com/valkey-io/valkey ","date":"02/04/2024","objectID":"/4-alternativas-ao-redis/:1:0","tags":["redis","database"],"title":"4 Alternativas ao Redis","uri":"/4-alternativas-ao-redis/"},{"categories":null,"content":"Garnet Garnet é um projeto de pesquisa da Microsoft Research. É um armazenamento de cache remoto projetado para oferecer alto desempenho, extensibilidade e baixa latência. Garnet é escalonável por thread em um único nó. Ele também oferece suporte à execução de cluster fragmentado, com replicação, pontos de verificação, failover e transações. Ele pode operar na memória principal e também no armazenamento em camadas (como SSD e Azure Storage). Garnet suporta uma superfície de API rica e um modelo de extensibilidade poderoso. Garnet é compatível com Redis, pois utiliza o protocolo RESP. https://www.microsoft.com/en-us/research/project/garnet/ https://github.com/microsoft/garnet ","date":"02/04/2024","objectID":"/4-alternativas-ao-redis/:2:0","tags":["redis","database"],"title":"4 Alternativas ao Redis","uri":"/4-alternativas-ao-redis/"},{"categories":null,"content":"KeyDB Outro projeto opensource que pode ser utilizado como alternativa ao Redis. Foi projetado para lidar com cargas de trabalho pesadas com benchmarking de nó único a mais de 1 milhão de operações/seg. KeyDB é um banco de dados multithread e superará o desempenho do Redis por nó segundo consta no próprio site. Existem diversas outras melhorias que o projeto também trouxe em relação ao Redis, como, replicação ativa e expiração de sub-chave. https://github.com/Snapchat/KeyDB https://docs.keydb.dev ","date":"02/04/2024","objectID":"/4-alternativas-ao-redis/:3:0","tags":["redis","database"],"title":"4 Alternativas ao Redis","uri":"/4-alternativas-ao-redis/"},{"categories":null,"content":"DragonFly Outra alternativa ao Redis que promete ter uma melhor performance e compatibilidade com as APIs do Redis. Segundo o próprio site: O Dragonfly foi projetado para oferecer a escalabilidade exigida pelas cargas de trabalho de dados modernas. Diga adeus aos ambientes complexos de vários nós com infinitas opções de configuração e infinitos pontos de falha. O Dragonfly pode ser facilmente ampliado para lidar com mais de 1 TB de dados e 4 milhões de QPS em um único nó, com um simples nó primário. https://www.dragonflydb.io Como podemos perceber existem diversos projetos opensource que seguem a mesma linha do Redis, entregando as mesmas features ou até mesmo mais features. A maioria possui compatibilidade direta com o Redis o que pode facilitar durante uma migração. Ainda assim é sempre importante testar o máximo possível para validar se uma nova ferramenta vai continuar atendendo ao seu propósito ","date":"02/04/2024","objectID":"/4-alternativas-ao-redis/:4:0","tags":["redis","database"],"title":"4 Alternativas ao Redis","uri":"/4-alternativas-ao-redis/"},{"categories":null,"content":" O Traefik é uma ferramenta muito poderosa e uma ótima alternativa para utilizar como ingress controller/proxy reverso em seu cluster Kubernetes. Uma ferramenta super leve, escrita em go e com diversas funcionalidades adicionais incluídas por padrão ","date":"22/03/2024","objectID":"/como-utilizar-traefik-ingress-controller-no-kubernetes/","tags":["k8s","kubernetes","eks","traefik","ingress"],"title":"Como utilizar o Traefik como ingress controller no Kubernetes","uri":"/como-utilizar-traefik-ingress-controller-no-kubernetes/"},{"categories":null,"content":"O que é Traefik Traefik (pronuncia-se “traffic”) é um proxy reverso e balanceador de carga para microsserviços de código aberto. Traefik pode nos ajudar a subir serviços mais rapidamente sem barrar no excesso de configurações de infra e simplificar o ambiente. Ele é escrito em go e é super leve e rápido, como exemplo a imagem docker possui 43MB imagem-latest. Alguns recursos úteis que o Traefik nos disponibiliza: Auto Discovery Metrics SSL Dashboard Circuit breakers (LatencyAtQuantileMS, NetworkErrorRatio, ResponseCodeRatio) Rate Limit Retry (Enable retry sending request if network error) Sticky sessions Health Check Canary deployments (Kubernetes) Mirroring (Kubernetes) Traefik ","date":"22/03/2024","objectID":"/como-utilizar-traefik-ingress-controller-no-kubernetes/:1:0","tags":["k8s","kubernetes","eks","traefik","ingress"],"title":"Como utilizar o Traefik como ingress controller no Kubernetes","uri":"/como-utilizar-traefik-ingress-controller-no-kubernetes/"},{"categories":null,"content":"Instalando Traefik ","date":"22/03/2024","objectID":"/como-utilizar-traefik-ingress-controller-no-kubernetes/:2:0","tags":["k8s","kubernetes","eks","traefik","ingress"],"title":"Como utilizar o Traefik como ingress controller no Kubernetes","uri":"/como-utilizar-traefik-ingress-controller-no-kubernetes/"},{"categories":null,"content":"Pré-requisitos Precisamos obviamente de um cluster Kubernetes, para nosso exemplo utilizaremos um cluster EKS na AWS, se você não sabe como criar um cluster na AWS pode dar uma olhada nesse artigo que escrevi. Também precisaremos de duas ferramentas instaladas: helm kubectl Caso ainda não conheça o helm, sugiro dar uma lida nesse artigo da Red Hat: https://www.redhat.com/pt-br/topics/devops/what-is-helm ","date":"22/03/2024","objectID":"/como-utilizar-traefik-ingress-controller-no-kubernetes/:2:1","tags":["k8s","kubernetes","eks","traefik","ingress"],"title":"Como utilizar o Traefik como ingress controller no Kubernetes","uri":"/como-utilizar-traefik-ingress-controller-no-kubernetes/"},{"categories":null,"content":"Instalação do Traefik Primeiro vamos criar um arquivo yaml onde iremos declarar alguns ajustes referentes ao traefik e que iremos utilizar durante a instalação. Editando o arquivo traefik-values.yaml: ingressClass: enabled: true isDefaultClass: true fallbackApiVersion: v1 ingressRoute: dashboard: enabled: false service: annotations: service.beta.kubernetes.io/aws-load-balancer-type: nlb globalArguments: - \"--api.insecure=true\" Bom o arquivo aqui é autodeclarativo, mas basicamente estamos dizendo para que durante a instalação seja criado o ingressClass do traefik no nosso cluster e o mesmo, seja utilizado como padrão. Também estamos desabilitando a rota para acessar o dashboard (configuraremos isso em outro post) e também estamos indicando que o tipo de balanceador de carga que iremos utilizar, e aqui será do tipo NLB (Network Load Balancer). Para mais detalhes sobe os valores disponíveis, podemos acessar o arquivo https://github.com/traefik/traefik-helm-chart/blob/master/traefik/values.yaml. Com nosso arquivo em mãos podemos prosseguir adicionando o repositório helm do Traefik, seguido da atualização dos repositórios e a instalação do Traefik. ➜ helm repo add traefik https://helm.traefik.io/traefik ➜ helm repo update ➜ helm install traefik traefik/traefik --create-namespace --namespace=traefik --values=traefik-values.yaml ","date":"22/03/2024","objectID":"/como-utilizar-traefik-ingress-controller-no-kubernetes/:2:2","tags":["k8s","kubernetes","eks","traefik","ingress"],"title":"Como utilizar o Traefik como ingress controller no Kubernetes","uri":"/como-utilizar-traefik-ingress-controller-no-kubernetes/"},{"categories":null,"content":"Testando Se nenhum erro ocorreu durante o processo já teremos o Traefik instalado e pronto para ser testado. Primeiramente vamos verificar os recursos criados durante a instalação em nosso cluster. ➜ kubectl get all -n traefik NAME READY STATUS RESTARTS AGE pod/traefik-6b894fd4d7-m9b7k 1/1 Running 0 60s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik LoadBalancer 10.100.235.23 a07cb2aa5c1384a14801dfee6b2dee7c-921b181b479547f4.elb.us-east-1.amazonaws.com 80:32181/TCP,443:32292/TCP 61s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik 1/1 1 1 61s NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-6b894fd4d7 1 1 1 61s Podemos verificar que diversos recursos foram criados, mas gostaria de destacar o service criado e automaticamente associado a uma load balancer na AWS, conforme solicitamos no nosso arquivo traefik-values.yaml. É através desse load balancer que faremos todas as nossas requisições para o cluster. Por desencargo de consciência vamos tentar o acesso ao endereço: ➜ curl a07cb2aa5c1384a14801dfee6b2dee7c-921b181b479547f4.elb.us-east-1.amazonaws.com 404 page not found Ao acessar nosso endereço recebemos um erro 404, mas até aí tudo bem, esse é um erro esperado. Ainda não temos nenhum serviço dentro cluster e a resposta padrão do Traefik quando não encontra nenhum serviço é de fato retornar um erro 404. Para termos certeza que tudo vai funcionar como esperado, vamos adicionar um serviço e associar a ele uma regra de acesso. Vamos criar o arquivo 2048.yaml. apiVersion: apps/v1 kind: Deployment metadata: name: deployment-2048 spec: selector: matchLabels: app: app-2048 replicas: 1 template: metadata: labels: app: app-2048 spec: containers: - image: alexwhen/docker-2048 imagePullPolicy: Always name: app-2048 ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: service-2048 spec: ports: - port: 80 targetPort: 80 protocol: TCP type: NodePort selector: app: app-2048 --- apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: 2048-ingress annotations: kubernetes.io/ingress.class: traefik spec: entryPoints: - web routes: - match: PathPrefix(`/`) kind: Rule services: - name: service-2048 port: 80 Para nosso exemplo vamos nos atentar principalmente ao último bloco do arquivo onde ficam as configurações específicas do Traefik. Configuramos aqui uma regra (Rule) onde os acessos ao cluster que acessem na rota principal (/), ou seja, o próprio endereço do cluster será redirecionado para o serviço que criamos. Essa regra poderia ser um path especifico assim como um endereço ou sub domínio, mais exemplos na documentação. Vamos conferir se o serviço subiu corretamente: ➜ kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE deployment-2048 1/1 1 1 11m Para garantir também vamos dar aquela conferida na nossa regra criada para o Traefik. ➜ kubectl get ingressroute NAME AGE 2048-ingress 11m ➜ kubectl describe ingressroute 2048-ingress Name: 2048-ingress Namespace: default Labels: \u003cnone\u003e Annotations: kubernetes.io/ingress.class: traefik API Version: traefik.containo.us/v1alpha1 Kind: IngressRoute Metadata: Creation Timestamp: 2024-03-21T18:40:48Z Generation: 4 Resource Version: 6036 UID: 31b125f9-b7e9-40ec-a367-352d8fc76de7 Spec: Entry Points: web Routes: Kind: Rule Match: PathPrefix(`/`) Services: Name: service-2048 Port: 80 Events: \u003cnone\u003e Bom, então agora só nos falta o teste final, vamos tentar abrir o endereço do load balancer diretamente no navegador: Serviço rodando E pronto, aí está nosso serviço sendo exposto através do Traefik. Poderíamos deixar nosso Traefik mais parrudo, adicionando certificado, criando regras especificas, adicionando health check e outros recursos que o Traefik disponibiliza, mas vamos deixar para um próximo artigo. Mas antes de irmos embora vamos criar um novo serviço e ver como a coisa fica muito simples e que realmente funciona. Vamos criar o arquivo whoami.yaml e seu conteúdo será muito parecido com o outro serviço, obviamente mudando a regra","date":"22/03/2024","objectID":"/como-utilizar-traefik-ingress-controller-no-kubernetes/:2:3","tags":["k8s","kubernetes","eks","traefik","ingress"],"title":"Como utilizar o Traefik como ingress controller no Kubernetes","uri":"/como-utilizar-traefik-ingress-controller-no-kubernetes/"},{"categories":null,"content":"Uma API REST (Representational State Transfer) é um estilo arquitetural para o design de serviços web que se baseia nos princípios fundamentais da web. Essa abordagem permite a comunicação entre sistemas distribuídos usando os protocolos padrão da web, como HTTP.","date":"07/03/2024","objectID":"/criando-api-rest-em-python-com-flask/","tags":["devops","observabilidade","monitoramento","sre","python","flask"],"title":"Criando uma API REST em Python com Flask","uri":"/criando-api-rest-em-python-com-flask/"},{"categories":null,"content":"O que é uma API REST Uma API REST (Representational State Transfer ou Transferência de Estado Representacional) é um tipo de arquitetura para a construção serviços. Essa abordagem permite a comunicação entre os sistemas usando os protocolos padrão da web, como HTTP. REST API Principais características de uma API REST: Arquitetura cliente-servidor: A comunicação ocorre entre um cliente (como um navegador web ou um aplicativo móvel) e um servidor, seguindo o modelo de requisição e resposta. Estado Representacional: Os recursos (dados ou funcionalidades) são representados por meio de URLs acessíveis através do HTTP, e o estado do recurso é transferido entre o cliente e o servidor nas requisições e respostas. Operações HTTP: As operações HTTP (GET, POST, PUT, DELETE, etc.) são utilizadas para manipular os recursos. Por exemplo, GET é usado para recuperar recursos, POST para criar novos recursos, PUT para atualizar recursos existentes e DELETE para remover recursos. Sem estado (Stateless): Cada requisição do cliente para o servidor deve conter todas as informações necessárias para o servidor entender e processar a requisição, sem depender de nenhum estado mantido no servidor entre as requisições. Interoperabilidade: As APIs REST são independentes de linguagem de programação e plataforma, o que significa que podem ser desenvolvidas e consumidas por uma variedade de tecnologias. Formatos de Representação de Dados: As APIs REST geralmente suportam vários formatos de dados, como JSON (JavaScript Object Notation) e XML (eXtensible Markup Language), para representar os recursos transferidos entre o cliente e o servidor. ","date":"07/03/2024","objectID":"/criando-api-rest-em-python-com-flask/:1:0","tags":["devops","observabilidade","monitoramento","sre","python","flask"],"title":"Criando uma API REST em Python com Flask","uri":"/criando-api-rest-em-python-com-flask/"},{"categories":null,"content":"Exemplo prático ","date":"07/03/2024","objectID":"/criando-api-rest-em-python-com-flask/:2:0","tags":["devops","observabilidade","monitoramento","sre","python","flask"],"title":"Criando uma API REST em Python com Flask","uri":"/criando-api-rest-em-python-com-flask/"},{"categories":null,"content":"VirtualEnv Para facilitar precisamos ter instalado o virtualenv para Python. Isso faz com que as dependências sejam sempre instaladas em uma virtualenv específica, não mais no sistema operacional. A partir daí, cada projeto executa seu código-fonte utilizando sua virtualenv própria. No Debian/Ubuntu podemos instalar com o seguinte comando: apt install virtualenv Ou podemos utilizar o próprio pip do Python pip install virtualenv Vamos criar um virtualenv chamado venv. Existem duas formas de fazermos isso, utilizando o próprio virtualenv ou com o python diretamente: virtualenv venv # Ou utilizando o python com opção -m python3 -m venv . Para ativar o virtualenv criado utilizamos o comando source: source venv/bin/activate Com isso já temos tudo pronto para começar a instalar nossas bibliotecas e criar nosso código. ","date":"07/03/2024","objectID":"/criando-api-rest-em-python-com-flask/:2:1","tags":["devops","observabilidade","monitoramento","sre","python","flask"],"title":"Criando uma API REST em Python com Flask","uri":"/criando-api-rest-em-python-com-flask/"},{"categories":null,"content":"Instalando Flask e começando a codar Instalando Flask: pip install flask Para o nosso código vamos criar o arquivo app.py. Começaremos importando as bibliotecas que vamos utilizar em nosso código: # Importando bibliotecas from flask import Flask, jsonify, request Após isso precisamos criar nossa aplicação utilizando o Flask: # Criar flask app app = Flask(__name__) Agora precisamos criar nossa rota que será acessada e a lógica que ela vai executar quando for chamada: # Criação da rota @app.route('/') def home(): data = \"hello world\" return jsonify({'data': data}) Aqui a lógica é simples, quando a rota for acessada uma variável chamada data receberá uma string e será retornada em um JSON. Agora só nos resta inicializar tudo que foi codificado anteriormente. # Inicializando if __name__ == '__main__': app.run(debug = True) E o arquivo completo fica assim: # Importando bibliotecas from flask import Flask, jsonify, request # Criar flask app app = Flask(__name__) # Criação de rotas @app.route('/') def home(): data = \"hello world\" return jsonify({'data': data}) # Inicializando if __name__ == '__main__': app.run(debug = True) ","date":"07/03/2024","objectID":"/criando-api-rest-em-python-com-flask/:2:2","tags":["devops","observabilidade","monitoramento","sre","python","flask"],"title":"Criando uma API REST em Python com Flask","uri":"/criando-api-rest-em-python-com-flask/"},{"categories":null,"content":"Rodando nossa aplicação Para rodar nossa aplicação rodaremos o seguinte comando: python app.py Se a saída no terminal for parecida com a imagem abaixo é por que deu tudo certo: Flask rodando E para testar é muito simples, podemos executar um curl no endereço localhost e na porta 5000 (porta padrão do flask). ➜ curl 127.0.0.1:5000 { \"data\": \"hello world\" } Bom, se não ocorreu nenhum erro já está funcionando, mas para não ficarmos em um exemplo tão simples e trivial, vamos adicionar alguma lógica nesse serviço. Vamos criar um serviço que gere números aleatórios em um range solicitado, como se fosse uma API sorteadora de números. Vamos adicionar algumas novas bibliotecas que iremos utilizar e ajustar a nossa rota principal com o código abaixo: # Importando bibliotecas from flask import Flask, jsonify, request from random import randint from datetime import datetime # Criar flask app app = Flask(__name__) @app.route('/') def home(): pessoas = request.args.get('pessoas', default=10, type=int) sorteados = request.args.get('sorteados', default=1, type=int) data = datetime.now() numbers = set() while len(numbers) \u003c sorteados: # enough is defined somewhere... numbers.add(randint(0, pessoas)) s = list(numbers) return jsonify({'numeros_sorteados': s, 'data': data.strftime('%d/%m/%Y %H:%M')}) if __name__ == '__main__': app.run(debug=True) Vamos testar novamente, por padrão será sorteado somente um número de 1 a 10, podemos passar também valores específicos como verá nos exemplos abaixo: ➜ curl 127.0.0.1:5000 { \"data\": \"07/03/2024 15:27\", \"numeros_sorteados\": [ 10 ] } ➜ curl '127.0.0.1:5000/?pessoas=100\u0026sorteados=3' { \"data\": \"07/03/2024 15:29\", \"numeros_sorteados\": [ 33, 6, 71 ] } ➜ curl '127.0.0.1:5000/?pessoas=100\u0026sorteados=1' { \"data\": \"07/03/2024 15:29\", \"numeros_sorteados\": [ 30 ] } Se o retorno foi um JSON com os números sorteados está feito, temos nossa primeira API REST escrita, simples ainda, mas que logo usaremos para ir avançando para exemplificar alguns conceitos que podem nos ajudar no dia a dia do mundo Devops, Cloud e Observabilidade. https://www.hostinger.com.br/tutoriais/api-restful https://flask.palletsprojects.com/en/2.2.x/tutorial/ ","date":"07/03/2024","objectID":"/criando-api-rest-em-python-com-flask/:2:3","tags":["devops","observabilidade","monitoramento","sre","python","flask"],"title":"Criando uma API REST em Python com Flask","uri":"/criando-api-rest-em-python-com-flask/"},{"categories":null,"content":"Em um ambiente digital cada vez mais exigente e competitivo, a tríade de SLA, SLI e SLO emerge como um farol orientador para as organizações que buscam manter a confiança dos clientes e garantir a excelência operacional. Ao compreender e integrar esses elementos em suas práticas de gestão de serviços, as empresas podem não apenas atender, mas superar as expectativas dos clientes, estabelecendo-se como líderes em um mundo movido pela qualidade, confiabilidade e inovação.","date":"23/02/2024","objectID":"/um-pouco-sobre-sla-sli-slo/","tags":["devops","observabilidade","monitoramento","sre"],"title":"Um pouco sobre SLA, SLI e SLO","uri":"/um-pouco-sobre-sla-sli-slo/"},{"categories":null,"content":"Introdução Algumas métricas são importantes para entender como nossos serviços estão performando mas também existem métricas que nos dão uma visão sobre a confiabilidade e disponibilidade desses serviços. Entre elas estão o SLI e SLO, que vamos entender um pouco mais nesse texto. Primeiramente é necessário entender que são métricas e dados importantes para medir a confiabilidade dos serviços através da observabilidade, um dos principais pilares de SRE (Site Reliability Engineering). O conceito de engenharia de confiabilidade foi criado pela equipe de engenharia do Google. ","date":"23/02/2024","objectID":"/um-pouco-sobre-sla-sli-slo/:1:0","tags":["devops","observabilidade","monitoramento","sre"],"title":"Um pouco sobre SLA, SLI e SLO","uri":"/um-pouco-sobre-sla-sli-slo/"},{"categories":null,"content":"Exemplo prático Vamos supor que o SLI seja a LATÊNCIA de uma API, o SLO seja de ter 97% das requisições abaixo de 1s nos últimos 30 dias, e o SLA firmado com o cliente é de responder em até 1s, 93% das requisições. ","date":"23/02/2024","objectID":"/um-pouco-sobre-sla-sli-slo/:2:0","tags":["devops","observabilidade","monitoramento","sre"],"title":"Um pouco sobre SLA, SLI e SLO","uri":"/um-pouco-sobre-sla-sli-slo/"},{"categories":null,"content":"SLI (Service Level Indicator) São métricas que podem ser medidas (quantificáveis) em relação aos serviços, e que caso não estejam em bons números podem impactar a performance do serviço. Ex: Latência Taxa de erros Saturação Disponibilidade Nem toda métrica pode se tornar um SLI, devemos entender as métricas que impactam a experiência do usuário ou o desempenho do sistema. ","date":"23/02/2024","objectID":"/um-pouco-sobre-sla-sli-slo/:3:0","tags":["devops","observabilidade","monitoramento","sre"],"title":"Um pouco sobre SLA, SLI e SLO","uri":"/um-pouco-sobre-sla-sli-slo/"},{"categories":null,"content":"SLO (Service Level Object) Com o SLO podemos medir a maturidade dos serviços (internamente), é um valor na qual nos comprometemos em manter para não corromper a qualidade dos serviços e ambientes e também podendo dar direcionando nas ações. É importante que cada service level objective seja atingível, repetitivo, mensurável, compreensível, significante e controlável, além de conter as possíveis gratificações e penalidades previamente definidas para ambas as partes envolvidas. É de suma importância que a organização esteja comprometida em manter os bons níveis do serviço e que o SLO não seja comprometido. Alguns exemplos: Disponibilidade: SLI: Quantidade de erros em relação a quantidade de requests/processamentos. SLO: 98% de requests/processamentos com sucesso. Latência: SLI: Tempo de resposta ou tempo de processamento SLO: 98% das requisições ou processamentos abaixo de X milissegundos. ","date":"23/02/2024","objectID":"/um-pouco-sobre-sla-sli-slo/:4:0","tags":["devops","observabilidade","monitoramento","sre"],"title":"Um pouco sobre SLA, SLI e SLO","uri":"/um-pouco-sobre-sla-sli-slo/"},{"categories":null,"content":"Como ter sucesso com SLI e SLO Considerar expectativas dos clientes (internos e externos); Deixar acordos de SLO bem claros; O SLO deve ser visto como um recurso para garantir a melhoria contínua; Escolher bem as métricas para compor o SLI; ","date":"23/02/2024","objectID":"/um-pouco-sobre-sla-sli-slo/:4:1","tags":["devops","observabilidade","monitoramento","sre"],"title":"Um pouco sobre SLA, SLI e SLO","uri":"/um-pouco-sobre-sla-sli-slo/"},{"categories":null,"content":"SLA (Service Level Agreement) Ainda temos o SLA que é um acordo entre quem está entregando o serviço e o usuário final, garantindo um certo nível de serviço (SLO). O não cumprimento desse acordo (SLA), pode gerar consequências, dentre elas podemos citar a penalidade financeira, gerando descontos por exemplo para o cliente afetado. Para mais informações sobre o assunto podemos conferir no material do Google https://sre.google/ https://www.atlassian.com/br/incident-management/kpis/sla-vs-slo-vs-sli ","date":"23/02/2024","objectID":"/um-pouco-sobre-sla-sli-slo/:5:0","tags":["devops","observabilidade","monitoramento","sre"],"title":"Um pouco sobre SLA, SLI e SLO","uri":"/um-pouco-sobre-sla-sli-slo/"},{"categories":null,"content":"Continuando nossa série sobre Kubernetes, hoje iremos criar um cluster na AWS (EKS) utilizando uma ferramenta chamada eksctl.","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Introdução Após o último post sobre Kubernetes criando um cluster localmente, continuaremos a saga, mas agora criando um cluster Kubernetes na AWS, em um cenário um pouco mais próxima da realidade. Para criar um cluster kubernetes na AWS utilizaremos uma ferramenta chamada eksctl. eksctl é uma ferramenta CLI simples para criar e gerenciar clusters no EKS – serviço Kubernetes gerenciado da Amazon para EC2. Está escrito em Go, usa CloudFormation, foi criado pela Weaveworks e aceita contribuições da comunidade. ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:1:0","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Instalando o eksctl ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:2:0","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Linux # for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7` ARCH=amd64 PLATFORM=$(uname -s)_$ARCH curl -sLO \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz\" # (Optional) Verify checksum curl -sL \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt\" | grep $PLATFORM | sha256sum --check tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp \u0026\u0026 rm eksctl_$PLATFORM.tar.gz sudo mv /tmp/eksctl /usr/local/bin ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:2:1","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Windows e Mac choco install eksctl https://eksctl.io/installation/#for-windows brew tap weaveworks/tap brew install weaveworks/tap/eksctl https://eksctl.io/installation/#for-macos Vamos testar se está tudo funcionando: ➜ eksctl info eksctl version: 0.167.0 kubectl version: v1.28.2 OS: linux Com a ferramenta eksctl precisamos também que as credenciais da AWS já estejam configuradas, a partir dai podemos começar a utilizar a ferramenta. Temos duas formas que criar um cluster EKS, utilizando somente a linha de comando, passando todos os parâmetros necessários ou com um arquivo YAML de configuração para definirmos como queremos criar o nosso cluster. ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:2:2","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Criando cluster via linha de comando Primeiro podemos testar se já temos algum cluster criado: ➜ eksctl get cluster No clusters found Como podemos ver ainda não temos nenhum cluster criado. Vamos então criar um cluster simples utilizando a linha de comando: ➜ eksctl create cluster [ℹ] using region us-west-2 [ℹ] setting availability zones to [us-west-2a us-west-2c us-west-2b] [ℹ] subnets for us-west-2a - public:192.168.0.0/19 private:192.168.96.0/19 [ℹ] subnets for us-west-2c - public:192.168.32.0/19 private:192.168.128.0/19 [ℹ] subnets for us-west-2b - public:192.168.64.0/19 private:192.168.160.0/19 [ℹ] nodegroup \"ng-98b3b83a\" will use \"ami-05ecac759c81e0b0c\" [AmazonLinux2/1.11] [ℹ] creating EKS cluster \"floral-unicorn-1540567338\" in \"us-west-2\" region [ℹ] will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup [ℹ] if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-west-2 --cluster=floral-unicorn-1540567338' [ℹ] 2 sequential tasks: { create cluster control plane \"floral-unicorn-1540567338\", create nodegroup \"ng-98b3b83a\" } [ℹ] building cluster stack \"eksctl-floral-unicorn-1540567338-cluster\" [ℹ] deploying stack \"eksctl-floral-unicorn-1540567338-cluster\" [ℹ] building nodegroup stack \"eksctl-floral-unicorn-1540567338-nodegroup-ng-98b3b83a\" [ℹ] --nodes-min=2 was set automatically for nodegroup ng-98b3b83a [ℹ] --nodes-max=2 was set automatically for nodegroup ng-98b3b83a [ℹ] deploying stack \"eksctl-floral-unicorn-1540567338-nodegroup-ng-98b3b83a\" [✔] all EKS cluster resource for \"floral-unicorn-1540567338\" had been created [✔] saved kubeconfig as \"~/.kube/config\" [ℹ] adding role \"arn:aws:iam::376248598259:role/eksctl-ridiculous-sculpture-15547-NodeInstanceRole-1F3IHNVD03Z74\" to auth ConfigMap [ℹ] nodegroup \"ng-98b3b83a\" has 1 node(s) [ℹ] node \"ip-192-168-64-220.us-west-2.compute.internal\" is not ready [ℹ] waiting for at least 2 node(s) to become ready in \"ng-98b3b83a\" [ℹ] nodegroup \"ng-98b3b83a\" has 2 node(s) [ℹ] node \"ip-192-168-64-220.us-west-2.compute.internal\" is ready [ℹ] node \"ip-192-168-8-135.us-west-2.compute.internal\" is ready [ℹ] kubectl command should work with \"~/.kube/config\", try 'kubectl get nodes' [✔] EKS cluster \"floral-unicorn-1540567338\" in \"us-west-2\" region is ready Como não passamos nenhum parâmetro o cluster será criado com os valores padrões: Nome gerado automaticamente Dois worker nodes de tamanho m5.large Usa o AWS EKS AMI oficial Regiãous-west-2 Uma VPC dedicada Podemos também personalizar nosso cluster personalizando os parâmetros passados, como, por exemplo, personalizar nome, quantidade de nós do cluster e especificar a versão do kubernetes utilizada. eksctl create cluster --name=cluster-dev --nodes=4 --version=1.28 Para saber quais parâmetros que podemos utilizar, podemos usar o comando abaixo: ➜ eksctl create cluster --help ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:3:0","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Criando cluster via arquivo de configuração Outra forma de criar um cluster é utilizando um arquivo de configuração. Eu acredito ser a maneira ideal, pois podemos compartilhar o arquivo ou manter-lô em um repositório como o github, por exemplo. No nosso exemplo estamos criando um cluster na região us-east-1 com dois node groups de tamanhos e capacidades diferentes. Daremos o nome para o arquivo de cluster.yaml: apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: basic-cluster region: us-east-1 nodeGroups: - name: ng-1 instanceType: m5.large desiredCapacity: 10 - name: ng-2 instanceType: m5.xlarge desiredCapacity: 2 Para criar o cluster só precisamos apontar o arquivo de configuração que criamos na etapa anterior: eksctl create cluster -f cluster.yaml ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:4:0","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Gerenciando o cluster Após o cluster ser criado já podemos gerenciar o mesmo usando kubectl ou qualquer ferramenta que prefira. Primeiro vamos conferir o cluster criado: ➜ eksctl get cluster NAME REGION EKSCTL CREATED cluster-dev us-east-1 True No console da AWS: Console AWS Realizando algumas validações com alguns comandos no kubectl: ➜ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-192-168-42-117.ec2.internal Ready \u003cnone\u003e 106s v1.28.5-eks-5e0fdde ➜ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-node-626mv 2/2 Running 0 2m13s kube-system coredns-86969bccb4-sxgkp 1/1 Running 0 8m6s kube-system coredns-86969bccb4-xc5gh 1/1 Running 0 8m6s kube-system kube-proxy-lttsv 1/1 Running 0 2m13s ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:5:0","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":"Deletando cluster Caso seu cluster seja somente para testes e não queira gastar deixando ele ligado por muito tempo, podemos deletar o cluster com o comando abaixo: ➜ eksctl delete cluster cluster-dev 2024-02-07 08:54:36 [ℹ] deleting EKS cluster \"cluster-dev\" 2024-02-07 08:54:38 [ℹ] will drain 0 unmanaged nodegroup(s) in cluster \"cluster-dev\" 2024-02-07 08:54:38 [ℹ] starting parallel draining, max in-flight of 1 2024-02-07 08:54:39 [ℹ] deleted 0 Fargate profile(s) 2024-02-07 08:54:40 [✔] kubeconfig has been updated 2024-02-07 08:54:40 [ℹ] cleaning up AWS load balancers created by Kubernetes objects of Kind Service or Ingress 2024-02-07 08:54:43 [ℹ] 2 sequential tasks: { delete nodegroup \"ng-3bc9974c\", delete cluster control plane \"cluster-dev\" [async] } 2024-02-07 08:54:43 [ℹ] will delete stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 08:54:43 [ℹ] waiting for stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" to get deleted 2024-02-07 08:54:44 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 08:55:14 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 08:55:56 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 08:57:36 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 08:59:09 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 08:59:48 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 09:01:29 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 09:02:01 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 09:03:24 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 09:04:44 [ℹ] waiting for CloudFormation stack \"eksctl-cluster-dev-nodegroup-ng-3bc9974c\" 2024-02-07 09:04:44 [ℹ] will delete stack \"eksctl-cluster-dev-cluster\" 2024-02-07 09:04:45 [✔] all cluster resources were deleted Para mais configurações podemos acessar a documentação oficial https://eksctl.io/getting-started/ ","date":"07/02/2024","objectID":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/:6:0","tags":["k8s","kubernetes","eks","eksctl","aws"],"title":"Como criar um cluster kubernetes EKS na AWS com eksctl","uri":"/como-criar-cluster-kubernetes-eks-na-aws-com-eksctl/"},{"categories":null,"content":" O Kubernetes se tornou uma das plataformas de orquestração de containers mais utilizada. Existem diversos fatores positivos e negativos no uso do Kubernetes no processo de desenvolvimento, implantação e gerenciamento de aplicações. Kubernetes oferece uma orquestração avançada, permitindo que as aplicações cresçam conforme a demanda. Ele permite também abstrair a infraestrutura, ou seja, se a aplicação roda em um cluster Kubernetes, muito provavelmente roda em qualquer outro cluster de mesma versão. E vem se tornado um padrão dentro das grandes organizações, diminuindo um pouco a complexidade quando um funcionário passa de uma empresa para outra. ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"⚓ Introdução O Kubernetes se tornou uma das plataformas de orquestração de containers mais utilizada no mundo. Existem diversos fatores positivos e negativos no uso do Kubernetes no processo de desenvolvimento, implantação e gerenciamento de aplicações. Kubernetes oferece uma orquestração avançada, permitindo que as aplicações cresçam conforme a demanda. Ele permite também abstrair a infraestrutura, ou seja, se a aplicação roda em um cluster Kubernetes, muito provavelmente roda em qualquer outro cluster de mesma versão. E vem se tornado um padrão de mercado dentro das grandes organizações, diminuindo um pouco a complexidade quando um funcionário passa de uma empresa para outra. ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:1:0","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"▶️ Kind ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:2:0","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Sobre Kind é uma ferramenta para executar clusters locais do Kubernetes usando “nós” de contêiner Docker. Kind foi projetado principalmente para testar o próprio Kubernetes, mas pode ser usado para desenvolvimento local ou CI. ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:2:1","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Instalação Para usar o kind precisamos já ter o docker instalado. Caso ainda não tenho, pode seguir o tutorial a seguir https://docs.docker.com/engine/install/ Linux [ $(uname -m) = x86_64 ] \u0026\u0026 curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64 chmod +x ./kind sudo mv ./kind /usr/local/bin/kind Mac # For Intel Macs [ $(uname -m) = x86_64 ] \u0026\u0026 curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-darwin-amd64 # For M1 / ARM Macs [ $(uname -m) = arm64 ] \u0026\u0026 curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-darwin-arm64 chmod +x ./kind mv ./kind /some-dir-in-your-PATH/kind Windows curl.exe -Lo kind-windows-amd64.exe https://kind.sigs.k8s.io/dl/v0.20.0/kind-windows-amd64 Move-Item .\\kind-windows-amd64.exe c:\\some-dir-in-your-PATH\\kind.exe ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:2:2","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Exemplos Para criarmos um cluster utilizando o Kind: kind create cluster # Criar cluster simples kind create cluster --name kind-2 # Criar cluster especificando o nome kind get clusters # Listar clusters Para deletarmos um cluster: kind delete cluster Para criarmos um cluster com mais de um node, podemos criar um arquivo de configuração e utilizá-lo como parâmetro. O arquivo pode ser parecido com o abaixo, onde definimos um node como controle plane e dois nodes como workers: kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane - role: worker - role: worker Com o arquivo criado, podemos executar o comando: kind create cluster --config kind-example-config.yaml ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:2:3","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"▶️ K3d ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:3:0","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Sobre k3d é um wrapper leve para executar k3s (distribuição mínima do Kubernetes do Rancher Lab) no docker. O k3d torna muito fácil a criação de clusters k3s de nó único e de vários nós no docker, por exemplo, para o desenvolvimento local no Kubernetes. Nota: k3d é um projeto conduzido pela comunidade, mas não é um produto oficial do Rancher (SUSE). ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:3:1","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Instalação Para o k3d também precisamos ter o docker instalado previamente. Linux wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash Windows choco install k3d Mac brew install k3d ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:3:2","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Exemplo Criando cluster com k3d: k3d cluster create mycluster kubectl get nodes Assim como no kind, também podemos criar clusters a partir de um arquivo de configuração. Segue um exemplo onde criaremos também um cluster com um node para control plane e dois nodes workers: apiVersion: k3d.io/v1alpha5 kind: Simple servers: 1 agents: 2 E para executar a criação utilizando o arquivo: k3d cluster create --config example-config.yaml ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:3:3","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"▶️ Minikube ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:4:0","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Sobre O Minikube configura rapidamente um cluster Kubernetes local no macOS, Linux e Windows. Acredito que o Minikube seja a opção mais conhecida e utilizada até hoje. Um dois maiores diferenciais do Minikube é poder criar o cluster usando diversos provisionadores. Além do docker como as outras ferramentas, também podemos utilizar Qemu, VirtualBox, dentre outros. ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:4:1","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Instalação Para realizar a instalação no Linux, utilizaremos os comandos abaixo: curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube No Mac, o procedimento de instalação é parecido com o do Linux: curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 sudo install minikube-darwin-amd64 /usr/local/bin/minikube Para instalação no Windows, poderemos utilizar o choco: choco install minikube ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:4:2","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"Exemplo Para criar um cluster simples podemos utilizar os comandos abaixo: minikube start minikube kubectl -- get po -A minikube stop minikube delete --all Para criar um cluster personalizado, com mais recursos temos diversas opções de comando. Podemos personalizar cpu, memória e outras opções. Todas as opções podem ser conferidas com o comando minikube start --help minikube start --cpus=4 --memory=8g --addons=ingress minikube start --help ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:4:3","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":"✅ Conclusão Essas são algumas das opções para criarmos cluster localmente em nossos computadores. Mas a lista de opções é maior e pode ser explorada caso você não esteja satisfeito com estas opções. O importante é que não faltam alternativas para nos mantermos produtivos, pois podemos usar essas ferramentas para estudos, testes e até mesmo para trabalho. ","date":"18/01/2024","objectID":"/3-maneiras-iniciar-cluster-kubernetes-localmente/:5:0","tags":["k8s","kubernetes"],"title":"3 maneiras de iniciar um cluster Kubernetes localmente","uri":"/3-maneiras-iniciar-cluster-kubernetes-localmente/"},{"categories":null,"content":" Kafka é um dos serviços mais utilizados quando estamos falando de streaming de eventos e mensageria. Nesse artigo vamos realizar a instalação de um servidor Kafka utilizando Ubuntu Server e também realizaremos algumas operações para enviar e receber mensagens no servidor. ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"O que é o Kafka Resumidamente o Kafka é usado para trabalhar com fila de mensagens e como uma plataforma de streaming de eventos, usando um modelo de “publicar/assinar”. Foi criado e disponibilizado pelo Linkedin em 2011. Ele permite que os produtores consigam gravar mensagens no Kafka, que posteriormente podem ser lidas por um ou mais consumidores. Esses registros não podem ser modificados após serem enviados para o Kafka. Ele é executado como um cluster de um ou mais servidores, ou seja, mesmo que só tenhamos um servidor ele mesmo assim é considerado um cluster. Cada nó desse cluster é também chamado de broker. Para saber mais detalhes sobre Kafka acesse meu outro post. ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:1:0","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Instalação do Java Neste tutorial, usaremos o Ubuntu 22.04 LTS Server, mas as etapas também devem ser semelhantes em outras versões do Ubuntu. Antes de começar, vamos nos certificar que o Java está instalado no servidor. Você pode verificar se o Java já está instalado executando o seguinte comando: java -version Command 'java' not found, but can be installed with: sudo apt install openjdk-11-jre-headless # version 11.0.20.1+1-0ubuntu1~22.04, or sudo apt install default-jre # version 2:1.11-72build2 sudo apt install openjdk-17-jre-headless # version 17.0.8.1+1~us1-0ubuntu1~22.04 sudo apt install openjdk-18-jre-headless # version 18.0.2+9-2~22.04 sudo apt install openjdk-19-jre-headless # version 19.0.2+7-0ubuntu3~22.04 sudo apt install openjdk-8-jre-headless # version 8u382-ga-1~22.04.1 Se o Java não estiver instalado, como no exemplo acima, você poderá instalá-lo executando o seguinte comando: sudo apt-get update \u0026\u0026 sudo apt-get install default-jre ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:2:0","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Instalação do Kafka Agora que temos o Java instalado, podemos prosseguir com a instalação do Kafka. Primeiro, baixe a versão mais recente do Kafka no site do Apache Kafka. No momento que estou escrevendo, a versão mais recente é a 3.6.1. Você pode baixá-lo usando wget: wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz Após baixar o arquivo, vamos extrai-lo: tar -xzf kafka_2.13-3.6.1.tgz Isto criará um novo diretório chamado “kafka_2.13-3.6.1”. Entre para este diretório: cd kafka_2.13-3.6.1 O Kafka usa um arquivo de configuração chamado server.properties, a configuração padrão deve funcionar para a maioria dos casos de uso, mas você pode personalizá-lo conforme necessário. Você pode, por exemplo, alterar o número da porta que o Kafka executa ou o número de threads do servidor, para mais detalhes podemos acessar a documentação. Se quiser dar uma conferida no arquivo, podemos executar o comando abaixo: cat config/server.properties ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:3:0","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Iniciar o servidor Kafka Aviso do autor Gostaria de deixar claro que as instruções a seguir não se aplicam a um ambiente de produção, eu considero esse cenário ideal para ambientes de testes ou cenários específicos como testar alguma configuração ou algo do gênero. Aqui teremos duas opções para iniciar o servidor Kafka, o modo tradicional, iniciando o servidor Kafka com o Zookeeper e o modo “Kraft” que é uma maneira recente de iniciar o Kafka sem utilizar o Zookeeper, saiba mais sobre aqui. Escolha uma das opções para iniciar o servidor e então poderemos avançar para os testes. ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:4:0","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Iniciando servidor com Zookeeper Em um terminal iremos iniciar o Zookeeper, lembrando que os comandos precisam ser executados nessa ordem: bin/zookeeper-server-start.sh config/zookeeper.properties Em outro terminal vamos iniciar o servidor Kafka: bin/kafka-server-start.sh config/server.properties ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:4:1","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Iniciando servidor sem Zookeeper Para iniciar o Kafka sem Zookeeper executaremos os comandos abaixo, primeiro geraremos um valor de Cluster UUID: KAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\" Com o valor de Cluster UUID iremos formatar o diretório de logs: bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties E por fim iniciaremos o servidor Kafka: bin/kafka-server-start.sh config/kraft/server.properties ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:4:2","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Realizando alguns testes Alguns exemplos de eventos que podem ser usados em um servidor Kafka são transações de pagamento, geolocalização, pedidos de compras, medições de sensores de dispositivos IoT e diversas outras. Esses eventos são organizados em tópicos. De maneira simples o tópico é como se fosse uma pasta, uma maneira de organizar as coisas. Agora que o servidor Kafka está em execução (podemos ver pelas mensagens de log quando iniciamos o servidor), podemos realizar alguns testes para ver o servidor em funcionamento. Para nosso teste vamos criar um tópico e enviar alguma mensagem para ele. Para criar o tópico vamos executar o seguinte comando: ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:5:0","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Criando Tópicos bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic teste Created topic teste. Para validar se o tópico foi criado, podemos listar os tópicos do servidor: bin/kafka-topics.sh --list --bootstrap-server localhost:9092 Created topic teste. Também podemos descrever o tópico criado para entender os detalhes: bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic teste Topic: teste TopicId: _oSFFE0hTTy3I7t1qUDwEQ PartitionCount: 1 ReplicationFactor: 1 Configs: segment.bytes=1073741824 Topic: teste Partition: 0 Leader: 1 Replicas: 1 Isr: 1 ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:5:1","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Produzindo mensagens Podemos produzir mensagens pela linha de comando, para isso podemos utilizar o producer linha. Cada linha digitada realizará a gravação de um evento separado no tópico. bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic teste \u003ePrimeira mensagem \u003eSegunda mensagem Para encerrar o envio de mensagens aperte as teclas CTRL+C ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:5:2","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Consumindo mensagens Para consumir as mensagens vamos executar o comando abaixo: bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic teste --from-beginning Primeira mensagem Segunda mensagem Se você ver as mensagens digitadas anteriormente é sinal que tudo deu certo. Um teste bem legal de ser feito é deixar o terminal aberta conectado com o consumidor e em outro terminal utilizar o comando para produzir mensagens. Você poderá ver as mensagens entrando imediatamente no terminal onde o consumidor está ativo. Consumer Kafka recebendo mensagens Bom agora já conseguimos fazer o básico no nosso servidor Kafka, em breve estarei escrevendo algumas outras dicas sobre Kafka. Até lá. ","date":"10/01/2024","objectID":"/instalacao-servidor-kafka-ubuntu/:5:3","tags":["kafka","zookeeper"],"title":"Instalação servidor Kafka no Ubuntu Server","uri":"/instalacao-servidor-kafka-ubuntu/"},{"categories":null,"content":"Por mais que você possa sempre estar atarefado, existem momentos em que você pode não estar tocando um projeto especifico ou grande. Para evitar aquele sentimento de não estar contribuindo, seguem minhas pequenas dicas para se manter na ativa e mostrando serviço.","date":"27/11/2023","objectID":"/tarefas-engenheiro-devops-quando-nao-tem-fazer/","tags":["devops"],"title":"Tarefas para um engenheiro DevOps fazer quando não tiver o que fazer","uri":"/tarefas-engenheiro-devops-quando-nao-tem-fazer/"},{"categories":null,"content":"Documentar Possivelmente nem todo mundo gosta de escrever documentação, mas é algo muito necessário. Aproveitar o tempo “livre” para documentar o que está fazendo ou já fez, pode trazer diversos benefícios. Durante o processo de documentação, você também estará revisando e ajudando a fixar o que fez. Pode encontrar algum ponto de melhoria no projeto, por que não, nem tudo é perfeito. Sua equipe também pode se beneficiar disso, tendo materiais de consulta sempre que necessário, diminuindo as interrupções por perguntas básicas sobre algum projeto. Por isso é muito importante documentar e também manter as documentações atualizadas, pior do que não documentar é ter algo documentado errado. Conversar com pessoas Esse é um ponto que às vezes esquecemos de visitar, estamos tão atarefados ou imersos em um problema técnico que esquecemos das pessoas. Converse com pessoas do seu e de outros times para entender os problemas que eles estão enfrentando, talvez você saiba como ajudá-los. Converse sobre as coisas que você já fez, saiba se está sendo útil, se não há nada que possa ser melhorado. Tenho certeza que sempre tem alguém enfrentando algum problema ou executando uma tarefa que poderia facilmente ser automatizada ou otimizada. Analisar suas métricas Deixa eu adivinhar, você já montou sua estrutura de observabilidade, como por exemplo o Prometheus e Grafana? Se sua resposta for sim, provavelmente há várias métricas para serem analisadas. Analisar como anda os recursos dos servidores e serviços pode trazer vários pontos de melhorias ou algum serviço que esteja se degradando com o passar do tempo. Analise, descubra o motivo e encontre uma solução Bora analisar essas métricas e trazer melhorias? Otimizar os custos Não gaste seu dinheiro à toa Eis um ponto indiscutível, ninguém gosta de gastar mais do que deveria. Não seria diferente no mundo da tecnologia (mesmo para aquela empresa enorme e cheio de investimentos), principalmente quando estamos trabalhando com serviços de cloud. Verifica onde está sendo o maior gasto, analise se não há maneiras de diminuir o custo (obviamente sem perder performance). Alguns pontos que podem ser relevantes: Dimensionamento incorreto de CPU e memória; Muito tráfego de rede entre zonas de disponibilidade; Excesso de consultas a banco de dados; Ambientes de desenvolvimento ligados fora do horário de trabalho; Esse são somente alguns pontos, ainda podem existir diversos outros. Não esquecendo que é possível montar relatórios de custos por time ou serviço, trazendo uma visão muito mais simplificada dos gastos. Prova de conceito Sabe aquela ferramenta ou tecnologia que você acha que pode trazer melhorias? É um bom momento para realizar sua POC e validar se ela pode trazer algum benefício para os ambientes. Sempre importante validar durante os testes se ela vai trazer alguma redução de custo, otimização de processos ou mesmo simplificar alguma tarefa. Mas lembre-se, é muito importante que essa POC tenha como objetivo trazer algum resultado, converse com seus colegas e gestores para validar suas ideias. Nada de querer brincar com aquela ferramenta só por que todo mundo diz que é boa ou empresa X está usando. Passagem de conhecimento Além da parte de documentação citada anteriormente, também é possível realizar apresentações/workshops com seu time ou empresa para passar conhecimento, mostrar os serviços realizadas e as melhorias que você vem trazendo. Dê muita atenção aos colegas de time que estão começando, dedique um tempo para ensiná-los da forma correta, tenho certeza que muitos lembrarão de você quando estiverem em outras empresas. Também é possível passar conhecimento para pessoas de fora da sua empresa, como em artigos (como este), vídeos no Youtube ou participação em fóruns e conferências. Lembre-se, quem não é visto não é lembrado ;). Testes de caos Não fique perdido O que aconteceria se o principal banco de dados da sua empresa ficasse fora? Não sabe, então esse é um bom motivo para criar teste de caos. E","date":"27/11/2023","objectID":"/tarefas-engenheiro-devops-quando-nao-tem-fazer/:0:0","tags":["devops"],"title":"Tarefas para um engenheiro DevOps fazer quando não tiver o que fazer","uri":"/tarefas-engenheiro-devops-quando-nao-tem-fazer/"},{"categories":null,"content":"Excelentes herós se unem em um propósito comum e maior, resolver os conflitos do mundo da tecnologia","date":"10/08/2023","objectID":"/os-vingadores-devops/","tags":["devops","sre"],"title":"Os vingadores DevOps","uri":"/os-vingadores-devops/"},{"categories":null,"content":" Aviso do autor Essa história pode ter sido baseada em fatos reais (ou não) e pode contar ironia (ou não). ","date":"10/08/2023","objectID":"/os-vingadores-devops/:0:0","tags":["devops","sre"],"title":"Os vingadores DevOps","uri":"/os-vingadores-devops/"},{"categories":null,"content":"Guerra Infinita da Tecnologia: Capítulo 1 Em uma metrópole futurista chamada Techropolis, onde inovação e tecnologia eram a essência da vida, dois indivíduos com um poder sobrenatural surgiram. Alex, o Prodigy Códigus, era um jovem gênio da programação, capaz de criar códigos complexos com um piscar de olhos. Em outro canto da cidade, Diana, a Executora Operativa, era uma mestra em infraestrutura e operações, mantendo os sistemas em funcionamento com sua habilidade sem igual. A rotina em Techropolis havia se tornado complicada, parada no tempo e com conflitos constantes entre os dois lados da cidade, era uma questão de tempo até tudo ficar ainda pior. A população clamava para que alguma atitude fosse tomada para evitar um caos tecnológico iminente. Em uma bela noite, enquanto observavam as estrelas de suas respectivas varandas, Alex e Diana tiveram uma revelação simultaneamente. Eles perceberam que seus poderes combinados poderiam revolucionar Techropolis, trazendo ordem ao caos tecnológico. Inspirados pelos antigos mitos de colaboração heróica, eles se uniram para criar uma nova abordagem que combinasse seus talentos: a Liga DevOps. ","date":"10/08/2023","objectID":"/os-vingadores-devops/:1:0","tags":["devops","sre"],"title":"Os vingadores DevOps","uri":"/os-vingadores-devops/"},{"categories":null,"content":"A União Transformadora: Capítulo 2 Unindo suas forças, Alex e Diana enfrentaram o ceticismo inicial das empresas de Techropolis. Com determinação inabalável, eles montaram a “Fortaleza da Colaboração”, um espaço onde desenvolvedores e operadores poderiam trabalhar juntos em harmonia. Sua presença magnética e exemplo inspirador convenceram as equipes a se unirem para alcançar um objetivo comum. Os dois heróis realizavam “Tarefas de Transformação”, resolvendo bugs em tempo recorde e automatizando processos com a velocidade de um relâmpago. Enquanto isso, o sinistro vilão chamado “Desconexión” tentava semear a discórdia entre as equipes, mas a aliança de Alex e Diana se mostrava inquebrável. Eles até mesmo inventaram o “Amuleto de Integração Contínua”, uma ferramenta mágica que mantinha o caos à distância. ","date":"10/08/2023","objectID":"/os-vingadores-devops/:2:0","tags":["devops","sre"],"title":"Os vingadores DevOps","uri":"/os-vingadores-devops/"},{"categories":null,"content":"A Era da Colaboração: Capítulo 3 A dupla de heróis DevOps se tornou lendária, suas histórias sendo contadas por toda Techropolis. Eles receberam o “Título de Honra da Tecnologia” em uma cerimônia grandiosa, onde até mesmo os supercomputadores aplaudiram. Alex e Diana continuaram a inspirar uma nova geração de desenvolvedores e operadores, provando que, com a união certa, até mesmo os desafios tecnológicos mais formidáveis podem ser superados. E assim, Techropolis se transformou de um lugar de desordem para um farol de colaboração e excelência tecnológica, graças à aliança heroica de Alex, o Prodigy Códigus, e Diana, a Executora Operativa, os guardiões da DevOps. ","date":"10/08/2023","objectID":"/os-vingadores-devops/:3:0","tags":["devops","sre"],"title":"Os vingadores DevOps","uri":"/os-vingadores-devops/"},{"categories":null,"content":"Muito além das métricas de CPU e memória podemos ter métricas efetivas e que nos ajudam a entender a saúde do nosso ambiente e resolver problemas de forma mais rápida caso eles ocorram..","date":"02/02/2023","objectID":"/os-quatro-sinais-ouro-observabilidade/","tags":["observabilidade","devops","sre"],"title":"Os quatro sinais de ouro da observabilidade","uri":"/os-quatro-sinais-ouro-observabilidade/"},{"categories":null,"content":"Muito além das métricas de CPU e memória podemos ter métricas efetivas e que nos ajudam a entender a saúde do nosso ambiente e resolver problemas de forma mais rápida caso eles ocorram. Nos primórdios (que não faz tanto tempo assim) as aplicações tinham pouca ou quase nenhuma monitoração. Quando tinham alguma monitoração, tínhamos somente informações básicas de hardware, rede e com alguma sorte quando algum serviço ficava indisponível. Com as mudanças de serviços únicos (monolitos) para centenas ou até milhares de microserviços, ambientes complexos, velozes, na nuvem e com uma visibilidade cada vez mais difícil, foi necessário mudar os padrões de indicadores para algo mais efetivo para quem mais sofre, o usuário/cliente. Após o Google disponibilizar seu livro sobre SRE a engenharia de confiabilidade vem se tornando algo cada vez mais presente e necessário. Um dos principais pontos do livro que iremos comentar aqui é sobre os quatro sinais de ouro da observabilidade. ","date":"02/02/2023","objectID":"/os-quatro-sinais-ouro-observabilidade/:0:0","tags":["observabilidade","devops","sre"],"title":"Os quatro sinais de ouro da observabilidade","uri":"/os-quatro-sinais-ouro-observabilidade/"},{"categories":null,"content":"O que é Como o próprio nome sugere, os quatro sinais de ouro são os pontos cruciais a serem observados em um ambiente ou sistema que podem afetar diretamente o cliente ou pontos muito importantes que podem impactar no todo. A coleta dessas métricas é importante para nos ajudar a resolver problemas, criar alertas e ajudar no planejamento de capacidade dos recursos. ","date":"02/02/2023","objectID":"/os-quatro-sinais-ouro-observabilidade/:1:0","tags":["observabilidade","devops","sre"],"title":"Os quatro sinais de ouro da observabilidade","uri":"/os-quatro-sinais-ouro-observabilidade/"},{"categories":null,"content":"Latência A latência é uma métrica que impacta diretamente o usuário, ela mede o tempo que um sistema demora para responder o cliente. Vale deixar claro que é importante medir a latência das requisições com sucesso e com erro, pois um erro pode retornar de maneira rápida e acabar afetando os valores medidos. ","date":"02/02/2023","objectID":"/os-quatro-sinais-ouro-observabilidade/:1:1","tags":["observabilidade","devops","sre"],"title":"Os quatro sinais de ouro da observabilidade","uri":"/os-quatro-sinais-ouro-observabilidade/"},{"categories":null,"content":"Tráfego Nessa métrica medimos basicamente a quantidade de acessos que um sistema ou site recebe, mas pode depender do tipo do sistema que estamos falando como, por exemplo, um serviço de streaming, onde o tráfego pode ser baseado na taxa de rede ou sessões simultâneas. ","date":"02/02/2023","objectID":"/os-quatro-sinais-ouro-observabilidade/:1:2","tags":["observabilidade","devops","sre"],"title":"Os quatro sinais de ouro da observabilidade","uri":"/os-quatro-sinais-ouro-observabilidade/"},{"categories":null,"content":"Erros Aqui medimos a quantidade de erros de um sistema ou aplicação. Vale ressaltar que não são somente os erros HTTP (4XX e/ou 5XX) que se enquadram aqui, podem ser erros de negócio, requisições que ultrapassem deterimado tempo, etc. ","date":"02/02/2023","objectID":"/os-quatro-sinais-ouro-observabilidade/:1:3","tags":["observabilidade","devops","sre"],"title":"Os quatro sinais de ouro da observabilidade","uri":"/os-quatro-sinais-ouro-observabilidade/"},{"categories":null,"content":"Saturação Na saturação podemos saber o quanto os recursos estão ocupados, como CPU, memória e disco, por exemplo, e novamente, tudo depende do ambiente envolvido. Se o sistema exigir mais memória, devemos medir com mais atenção esse ponto. Outro ponto muito importante é testar e saber em que ponto o sistema começa a sofrer com degradação, se é perto dos 100% ou é antes dos 90%, ou após determinado período. A saturação também pode ajudar com previsões de problemas, como o disco ficará cheio dentro de 2 dias, baseado nas métricas que já possui. É claro que essas informações sozinhas podem não entregar valor mas bem aplicadas e organizadas podem gerar muita confiança nos sistemas observados. Temos ainda diversos outros pontos que podem complementar esses pontos vistos aqui, como logs, traces, a própria ferramenta de alertas, entre outros. Mas veremos esses pontos em outra oportunidade. Fonte: https://sre.google/sre-book/monitoring-distributed-systems/#xref_monitoring_golden-signals ","date":"02/02/2023","objectID":"/os-quatro-sinais-ouro-observabilidade/:1:4","tags":["observabilidade","devops","sre"],"title":"Os quatro sinais de ouro da observabilidade","uri":"/os-quatro-sinais-ouro-observabilidade/"},{"categories":null,"content":" Quando queremos testar algumas coisas servidor, como teste de carga ou teste de desempenho podemos utilizar essa ferramenta que simula conexões dos usuários. ","date":"09/06/2021","objectID":"/simular-trafego-usuario-servidor/","tags":["linux"],"title":"Simular tráfego de usuário para um servidor","uri":"/simular-trafego-usuario-servidor/"},{"categories":null,"content":"Vamos simular o tráfego para um servidor utlizando a ferramenta ab que foi criado pelo Apache para testar seu próprio serviço. ab -c 20 -n 100 -m GET http://127.0.0.1/ ","date":"09/06/2021","objectID":"/simular-trafego-usuario-servidor/:0:0","tags":["linux"],"title":"Simular tráfego de usuário para um servidor","uri":"/simular-trafego-usuario-servidor/"},{"categories":null,"content":"Onde: -c Número de solicitações enviadas ao mesmo tempo -n Número total de solicitações enviadas para o servidor -m Método HTTP utilizado Existem diversas outras opções que podem ser encontradas aqui. Como resposta teremos diversas informações que podem nos ajudar a entender se o servidor está preparado para receber bastante tráfego, se o desempenho seria satisfatório e assim por diante. This is ApacheBench, Version 2.3 \u003c$Revision: 1879490 $\u003e Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 127.0.0.1 (be patient).....done Server Software: Apache/2.4.18 Server Hostname: 127.0.0.1 Server Port: 80 Document Path: / Document Length: 2817 bytes Concurrency Level: 20 Time taken for tests: 0.047 seconds Complete requests: 100 Failed requests: 0 Total transferred: 300800 bytes HTML transferred: 281700 bytes Requests per second: 2116.45 [#/sec] (mean) Time per request: 9.450 [ms] (mean) Time per request: 0.472 [ms] (mean, across all concurrent requests) Transfer rate: 6217.06 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 0 Processing: 1 9 11.8 3 34 Waiting: 1 9 11.8 3 34 Total: 1 9 11.9 3 34 Percentage of the requests served within a certain time (ms) 50% 3 66% 4 75% 4 80% 31 90% 33 95% 34 98% 34 99% 34 100% 34 (longest request) ","date":"09/06/2021","objectID":"/simular-trafego-usuario-servidor/:0:1","tags":["linux"],"title":"Simular tráfego de usuário para um servidor","uri":"/simular-trafego-usuario-servidor/"},{"categories":null,"content":"A redução de custos no ambiente de nuvem é um assunto constante, a utlização é simples porém o desperdício de recursos pode ocorrer com bastante facilidade. Para te ajudar vou dividir as dicas em três partes, dividindo em EC2, ECS e RDS, três serviços distintos da [AWS](https://aws.amazon.com/pt/).","date":"16/02/2021","objectID":"/reduzindo-custos-na-aws-ec2-parte-1/","tags":["aws","ec2"],"title":"Reduzindo custos na AWS (EC2) - Parte 1","uri":"/reduzindo-custos-na-aws-ec2-parte-1/"},{"categories":null,"content":"A redução de custos no ambiente de nuvem é um assunto constante, a utlização é simples porém o desperdício de recursos pode ocorrer com bastante facilidade. Para te ajudar vou dividir as dicas em três partes, dividindo em EC2, ECS e RDS, três serviços distintos da AWS. Na primeira parte começaremos com o EC2, que permite a criação de instâncias (“máquinas virtuais”) com facilidade, podendo ser usado tanto com Windows, quanto com Linux. Bom pra quem ainda não sabe, os recursos da AWS são cobrados por uso, então quando criamos uma instância no EC2, ela será cobrada pelo tempo que estiver ligada e veria de valor dependendo da tipo de instância escolhida. Bom a dica pode ser usada por quem utiliza os recursos EC2 durante o expediente de trabalho, seja em produção, que precise estar funcionando somente no horário de trabalho ou ambientes de desenvolvimento, que geralmente são usados por um determinado periodo do dia. A gente irá programar o start/stop dessas instâncias. Iremos utlizar funções Lambdas combinadas com eventos do Cloudwatch. Precisaremos de uma função IAM com permissão para acessar os recursos EC2. Pode usar o nome que achar melhor. Aqui vai uma colinha da política, lembrando que a função precisa ser configurada com o serviço Lambda: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"ec2:StartInstances\", \"ec2:StopInstances\", \"logs:PutLogEvents\" ], \"Resource\": [ \"arn:aws:logs:*:*:log-group:*:*:*\", \"arn:aws:ec2:*:*:instance/*\" ] }, { \"Sid\": \"VisualEditor1\", \"Effect\": \"Allow\", \"Action\": [ \"ec2:DescribeInstances\" ], \"Resource\": \"*\" }, { \"Sid\": \"VisualEditor2\", \"Effect\": \"Allow\", \"Action\": [ \"logs:CreateLogStream\", \"logs:PutLogEvents\" ], \"Resource\": \"arn:aws:logs:*:*:log-group:*\" } ] } Acessando Lambda no Console da AWS, clicaremos em criar uma função: Iremos escolher a opção para criar do zero, escolheremos um nome, a linguagem Python 2.7, usar uma função existente e escolher a função IAM criada anteriormente. A primeira função será para realizar o stop das instâncias. No código da função (imagem abaixo) iremos alterar para o seguinte código, lembrando de alterar na linha 3 a região utilizada e na linha 5 os seus Instances IDs, se tiver mais de um basta separar por vírgula: import boto3 # Enter the region your instances are in e.g., 'eu-west-1' region = 'us-east-1' # Enter your instance IDs here instances = ['i-02fb6a97792f0802a'] def lambda_handler(event, context): ec2 = boto3.client('ec2', region_name=region) ec2.stop_instances(InstanceIds=instances) print 'Instances are now stopped: ' + str(instances) Usandos os mesmos passos já podemos criar a função lambda para iniciar as instâncias, bastando mudar o código da função: import boto3 # Enter the region your instances are in e.g., 'eu-west-1' region = 'us-east-1' # Enter your instance IDs here instances = ['i-02fb6a97792f0802a'] def lambda_handler(event, context): ec2 = boto3.client('ec2', region_name=region) ec2.start_instances(InstanceIds=instances) print 'Instances started: ' + str(instances) Agora vamos a criação do gatilho para acionar os eventos do Cloudwatch. Clicando em adicionar gatilho, vamos escolher a opção Eventos do Cloudwatch. Vamos criar uma nova regra para esse gatilho, dando um nome e escolhendo a Expressão de programação, que é uma expressão Cron. Não esquecendo que esse cron é ajustado para UTC. Podemos adicionar o gatilho Faremos o mesmo na função de Start E está pronto, nos horários programados as instâncias definidas irão ser desligadas e ligadas, reduzindo o custo nesse tempo que irá permanecer desligadas. Qualquer dúvida ou correção basta deixar nos comentários :). ","date":"16/02/2021","objectID":"/reduzindo-custos-na-aws-ec2-parte-1/:0:0","tags":["aws","ec2"],"title":"Reduzindo custos na AWS (EC2) - Parte 1","uri":"/reduzindo-custos-na-aws-ec2-parte-1/"},{"categories":null,"content":" SWAP é um espaço no disco que é utilizado quando a quantidade de memória RAM física está cheia. Quando um sistema Linux fica sem RAM, os blocos de memória inativos são movidos da RAM para a área de SWAP. ","date":"29/01/2021","objectID":"/criando-araquivo-swap-linux/","tags":["linux"],"title":"Criando arquivo de SWAP no Linux","uri":"/criando-araquivo-swap-linux/"},{"categories":null,"content":"O que é o SWAP SWAP é um espaço no disco que é utilizado quando a quantidade de memória RAM física está cheia. Quando um sistema Linux fica sem RAM, os blocos de memória inativos são movidos da RAM para a área de SWAP. ","date":"29/01/2021","objectID":"/criando-araquivo-swap-linux/:1:0","tags":["linux"],"title":"Criando arquivo de SWAP no Linux","uri":"/criando-araquivo-swap-linux/"},{"categories":null,"content":"Instalação Criando arquivo de SWAP sudo dd if=/dev/zero of=/swapfile bs=1024 count=1048576 Com o comando acima iremos criar um arquivo de SWAP com 1 GB de tamanho Iremos ajustar as permissões para o correto funcionamento sudo chmod 600 /swapfile Usaremos o comando mkswap para setar o arquivo criado anteriormente como uma área de SWAP: sudo mkswap /swapfile Habilitaremos o SWAP com o seguinte momento: sudo swapon /swapfile Para que essas alterações sejam permanentes precisamos adicionar uma entrada no arquivo /etc/fstab: /swapfile swap swap defaults 0 0 Para verificar se o SWAP está ativo podemos usar os comandos abaixos: sudo swapon --show sudo free -h ","date":"29/01/2021","objectID":"/criando-araquivo-swap-linux/:2:0","tags":["linux"],"title":"Criando arquivo de SWAP no Linux","uri":"/criando-araquivo-swap-linux/"},{"categories":null,"content":" Resumidamente o Kafka é usado para trabalhar com fila de mensagens e uma plataforma de streaming de eventos, usando um modelo de \"publicar/assinar\". Foi criado e disponibilizado pelo Linkedin em 2011. Ele permite que os produtores consigam gravar mensagens no Kafka, que posteriormente podem ser lidos por um ou mais consumidor. Esses registros não podem ser modificados após serem enviados para o Kafka. Ele é executado como um cluster de um ou mais servidores, ou seja, mesmo que só tenhamos um servidor ele mesmo assim é considerado um cluster. Cada nó desse cluster é também chamado de broker. ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"O que é o Kafka Resumidamente o Kafka é usado para trabalhar com fila de mensagens e como uma plataforma de streaming de eventos, usando um modelo de “publicar/assinar”. Foi criado e disponibilizado pelo Linkedin em 2011. Ele permite que os produtores consigam gravar mensagens no Kafka, que posteriormente podem ser lidas por um ou mais consumidores. Esses registros não podem ser modificados após serem enviados para o Kafka. Ele é executado como um cluster de um ou mais servidores, ou seja, mesmo que só tenhamos um servidor ele mesmo assim é considerado um cluster. Cada nó desse cluster é também chamado de broker. Kafka Cluster ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/:1:0","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"Tópicos Os registros são organizados em tópicos. Cada consumidor pode assinar um ou mais tópicos para ler os registros. Esses registros consistem em uma chave, um valor e data/hora. Cada tópico pode ser separado em várias partições dependendo do seu tamanho e configuração, por padrão só uma partição é utilizada, mas para escalar os consumidores o aumento de partições se faz necessária, pois cada partição é assinada por somente um consumidor por vez. Kafka Tópico \u003e\u003c ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/:1:1","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"Grupo de consumidores Os consumidores são identificados com um nome de grupo de consumidores. Esse grupo pode ter mais de um consumidor em um tópico trabalhando juntos, desde haja mais de uma partição, sempre que uma nova mensagem é recebida, só um membro desse grupo consome essa mensagem. ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/:1:2","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"Offset Uma questão bem importante para uso do Kafka é o entendimento dos offsets. O offset é quem controla a posição onde o consumidor parou de ler as mensagens ou qual a próxima mensagem. Esse controle é feito pelo próprio consumidor. Por exemplo, cada vez que um determinado consumidor ler uma mensagem, ele vai incrementando seu offset para saber exatamente onde ele parou e caso desconecte e conecte novamente, tenha um ponto de partida. O consumidor ainda pode ser configurado para iniciar seu offset, caso não tenha nenhum, da primeira ou da última mensagem do tópico. Kafka Offset \u003e\u003c ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/:1:3","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"Tempo de retenção Um ponto que se deve ter bastante atenção em entender e configurar da maneira correta, para não termos dores de cabeça (experiência própria), é com o tempo de retenção dos dados. Vou citar aqui duas das principais configurações relativas à retenção, na documentação podemos achar várias outras. log.retention.hours: Relativo a quantidade de horas para manter uma mensagem. Após o tempo determinado aqui a mensagem é excluída do servidor. Por padrão são 168 horas (7 dias). offsets.retention.minutes: Depois que um grupo de consumidor fica vazio, sem nenhum consumidor conectado, esse é o tempo que o offset do consumidor será mantido. Lembrando que se o offset é zerado o consumidor poderá consumir novamente as mensagens do tópico desde o início novamente, se aplicação não estiver preparada para validar se existe duplicação, pode ocorrer alguns problemas. Nas últimas versões o valor padrão é 10080 minutos (7 dias). ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/:1:4","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"Zookeeper Outro componente essencial para a execução do Kafka é o Zookeeper. Ele apoia ajudando na eleição de qual broker será líder de determinada partição, controlando caso algum nó caia, para que outros possam assumir essa liderança. O Zookeeper também mantém uma lista de todos os nós que estão funcionando e fazer parte do cluster. Controle dos tópicos, quais tópicos existem, quantas partições cada um tem, onde estão as réplicas, quem é o líder. Realizado também controle de quotas e controle de acesso. Existe um movimento em andamento para retirar o Zookeper como uma dependência para executar o Kafka, deixando para o próprio Kafka se autogerenciar. Acredito que isso possa diminuir a complexidade da arquitetura Kafka/Zookeeper ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/:1:5","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"Conclusão O Kafka se bem configurado e estruturado é uma ótima ferramenta para interligar serviços sem depender de uma conexão direta entre eles. Cada serviço manda e busca sua mensagem diretamente no Kafka tirando essa responsabilidade dos serviços. Como o Kafka já foi projetado para uma alta demanda, o crescimento em todos os aspectos é muito facilitado. Em outro texto vou mostrar como fazer uma configuração e instalação básica do Kafka e como podemos produzir e consumir algumas mensagens de maneira bem simples. Documentação: https://kafka.apache.org/documentation/ Understanding Kafka — A Distributed Streaming Platform ","date":"01/09/2020","objectID":"/kafka-tudo-que-precisamos-saber/:1:6","tags":["kafka","zookeeper"],"title":"Kafka tudo o que precisamos saber","uri":"/kafka-tudo-que-precisamos-saber/"},{"categories":null,"content":"Imagens que não são usadas e acabam nos atrapalhando.","date":"06/07/2020","objectID":"/remover-imagens-docker-com-tag/","tags":["docker"],"title":"Remover imagens Docker com TAG \"none\"","uri":"/remover-imagens-docker-com-tag/"},{"categories":null,"content":"Primeiro vamos fazer uma pesquisa sobre nossas imagens usando: docker images -a $ docker images -a sonarqube 0.8 34e889c54fe4 3 weeks ago 536MB \u003cnone\u003e \u003cnone\u003e 2e0435619f04 3 weeks ago 536MB \u003cnone\u003e \u003cnone\u003e e08451c98fcb 3 weeks ago 536MB \u003cnone\u003e \u003cnone\u003e 3cbb4fa1d367 3 weeks ago 510MB \u003cnone\u003e \u003cnone\u003e 9954766c4404 3 weeks ago 317MB \u003cnone\u003e \u003cnone\u003e 5471aca149e2 3 weeks ago 317MB \u003cnone\u003e \u003cnone\u003e de67c74cda48 3 weeks ago 536MB sonarqube 0.7 952b5e68f4df 3 weeks ago 536MB Podemos notar que aparecem diversas imagens com a TAG e podendo ocupar espaços consideráveis. Porém alguma dessas imagens sem TAG são imagens usadas por outras imagens e removê-las pode nos fazer perder um certo tempo, mesmo assim é possível removê-las também, mas veremos mais adiante. Para pesquisarmos somente as imagens que não estão sendo usadas, usamos o comando: docker images -a –filter “dangling=true” -q –no-trunc ╰─$ docker images -a --filter \"dangling=true\" -q --no-trunc sha256:031b0be81cf829258f102cb17dd8a07fe9aa06eeb20a6e5e2f67af54532c84f1 sha256:9959c80cfe039e7038fc188b2d0d3f22974d5f280e286a44e3195f3e45e0fa68\u003c/pre\u003e Essas imagens podemos ser removidas sem medo, então usaremos o comando abaixo: ╰─$ docker rmi $(docker images --filter \"dangling=true\" -q --no-trunc) Deleted: sha256:031b0be81cf829258f102cb17dd8a07fe9aa06eeb20a6e5e2f67af54532c84f1 Deleted: sha256:9959c80cfe039e7038fc188b2d0d3f22974d5f280e286a44e3195f3e45e0fa68 Deleted: sha256:6de7450e13547144dbb066a9afe8f0e0e2383a5696a9604e366e69ebba9fa3af Deleted: sha256:c7e984302b4ecf0b9428494665a09bc5c775ebaed5866ce3101a87c786741e29 Deleted: sha256:a8f885350961ed2cb5509033822f01e45e81ec0bed958e80381b0bf5529e14c9 Deleted: sha256:1f192881c9d640e62eeb03f6ed313e256a978c5ffc6e479a19954fcbe80e15b2 Deleted: sha256:f7b55b567ef38e97e7d836939f625e22a412444de9f901ba0c211737cc60a888 Deleted: sha256:355034eb63caebea98f56af94be376d31e29f47f33a50f56a9fb5d8691dd9b8e Deleted: sha256:56ab38708730dcabc3ac7c6e5e980cf88ea8680110aeacbe1820e0ff27f8348c Deleted: sha256:8bbd195ad543f77076ecc27a5cde47853add9d94232320ef651ca42225a80702 Para remover todas as imagens antigas e não usadas podemos usar o comando abaixo, porém muito cuidado ao usá-lo ╰─$ docker image prune ","date":"06/07/2020","objectID":"/remover-imagens-docker-com-tag/:0:0","tags":["docker"],"title":"Remover imagens Docker com TAG \"none\"","uri":"/remover-imagens-docker-com-tag/"},{"categories":null,"content":"Quanto acaba o espaço de uma instância Linux em produção, não podemos desligar ou reiniciar para dar manutenção, vamos ver como redimensionar volume principal no Linux EC2 sem precisar reiniciar, o famoso root. Sem nenhum downtime, com alguns poucos comandos.","date":"13/03/2020","objectID":"/como-redimensionar-volume-ebs-no-linux-sem-downtime/","tags":["aws","ec2","linux"],"title":"Como redimensionar volume EBS no Linux sem downtime","uri":"/como-redimensionar-volume-ebs-no-linux-sem-downtime/"},{"categories":null,"content":"Esse processo pode ser feito sempre que precisar aumentar o volume sem precisar desligar a instância ou desanexar o volume. Alterações em produção? Nesse caso sim :) Após estar logado em sua conta AWS vamos escolher a opção EC2 na lista de serviços Clicamos em “Volumes” no menu “ELASTIC BLOCK STORE” Escolha o volume que deseja redimensionar e com o botão direito do mouse clique em “Modify Volume” Verá uma janela como essa: Defina o novo tamanho para o volume, como no exemplo da imagem estamos estendendo o volume para 20GB Confirme no botão “Modify” Agora precisaremos extender a partição no sistema. Acesse a instância via SSH e rode o comando abaixo para listar o dispositivos. ubuntu@ip-172-31-23-184:~$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 89.1M 1 loop /snap/core/8268 loop1 7:1 0 18M 1 loop /snap/amazon-ssm-agent/1480 xvda 202:0 0 20G 0 disk └─xvda1 202:1 0 8G 0 part / Podemos ver o disco está com o novo tamanho (20GB), porém a partição continua com o tamanho antigo (8GB) e precisa ser estendido. Para isso vamos usar o comando (growpart): ubuntu@ip-172-31-23-184:~$ sudo growpart /dev/xvda 1 CHANGED: partition=1 start=2048 old: size=16775135 end=16777183 new: size=41940959,end=41943007 Levando em considreção o dispositivo e o número da partição. Vamos chegar novamente o tamanho da partição: ubuntu@ip-172-31-23-184:~$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 89.1M 1 loop /snap/core/8268 loop1 7:1 0 18M 1 loop /snap/amazon-ssm-agent/1480 xvda 202:0 0 20G 0 disk └─xvda1 202:1 0 20G 0 part / Podemos notar que a partição também está estendida, mas se olharmos o uso do disco podemos notar que o mesmo não foi alterado, isso porque ainda precisamos estender o sistema de arquivos. ubuntu@ip-172-31-23-184:~$ df -Th |grep /dev/xvda1 /dev/xvda1 ext4 7.7G 1.1G 6.7G 14% / ubuntu@ip-172-31-23-184:~$ E para estender o sistema de arquivos é simples, se o sistema de arquivos que está usando é ext2, ext3 ou ext4, basta executar o comando: ubuntu@ip-172-31-23-184:~$ sudo resize2fs /dev/xvda1 resize2fs 1.44.1 (24-Mar-2018) Filesystem at /dev/xvda1 is mounted on /; on-line resizing required old_desc_blocks = 1, new_desc_blocks = 3 The filesystem on /dev/xvda1 is now 5242619 (4k) blocks long. Agora se olharmos novamente o espaço utlizado com o comando df: ubuntu@ip-172-31-23-184:~$ df -Th |grep /dev/xvda1 /dev/xvda1 ext4 20G 1.1G 19G 6% / ubuntu@ip-172-31-23-184:~$ Pronto, volume estendido com 0 downtime. Bom proveito! ","date":"13/03/2020","objectID":"/como-redimensionar-volume-ebs-no-linux-sem-downtime/:0:0","tags":["aws","ec2","linux"],"title":"Como redimensionar volume EBS no Linux sem downtime","uri":"/como-redimensionar-volume-ebs-no-linux-sem-downtime/"},{"categories":null,"content":"Na [parte 1](https://sidneiweber.com.br/ansible-criado-ami-windows-personalizada-na-aws-parte-1/) aprendemos como usar um script AWS User Data para configurar uma senha de Administrador e configurar o WinRM no Windows. Agora que sabemos como criar uma instância setando um senha especifica, vamos ao restante dos procedimentos.  Vamos estruturar nosso projeto e manter as coisas organizadas.","date":"27/12/2019","objectID":"/ansible-criado-ami-windows-personalizada-na-aws-parte-2/","tags":["aws","ansible","windows"],"title":"Ansible: Criado AMI Windows personalizada na AWS (Parte 2)","uri":"/ansible-criado-ami-windows-personalizada-na-aws-parte-2/"},{"categories":null,"content":"Na parte 1 aprendemos como usar um script AWS User Data para configurar uma senha de Administrador e configurar o WinRM no Windows. Agora que sabemos como criar uma instância setando um senha especifica, vamos ao restante dos procedimentos. Vamos estruturar nosso projeto e manter as coisas organizadas. Recursos utilizados, caso não tenha algo instalado, não funcionará : Python 3.8.0 Módulos pip: boto boto3 pywinrm Ansible 2.9.2 Já podemos supor que você tenha o Ansible configurado corretamente para sua conta da AWS (por exemplo, boto instalado, credenciais do IAM configuradas). Consulte o Guia da AWS da Ansible se precisar de ajuda para fazer isso. Por simplicidade, esses exemplos também pressupõem que você tenha uma VPC padrão funcional em sua região (você deve ter, a menos que a tenha excluído). Se você precisar de ajuda para configurar isso, consulte a página da Amazon em VPCs padrão. Caso queira ir direto para os arquivos usados, pode acessar no github: https://github.com/sidneiweber/ansible-windows-ami Vamos iniciar pelas nossas variáveis, onde vamos setar a região da AWS, o tipo de instância, nossa chave, vpc e subnet, nossa senha que usamos na primeira parte do artigo e alguns detalhes sobre os volumes: # cat group_vars/all.yml target_aws_region: us-east-1 instance_type: t3.small keypair: keypair vpc_id: vpc-xxxxx subnet: subnet-xxxxx win_initial_password: myTempPassword123! volumes: - device_name: /dev/sda1 device_type: gp2 volume_size: 30 delete_on_termination: true Nosso arquivo hosts ficará assim. O grupo win é onde será adicionada a instância após a criação: localhost ansible_connection=local [win] [win:vars] ansible_connection=winrm ansible_ssh_port=5986 ansible_ssh_user=Administrator ansible_ssh_pass=\"{{ win_initial_password }}\" ansible_winrm_server_cert_validation=ignore Com essas váriaveis em mãos, vamos iniciar nossa instância base já usando o userdata assim como fizemos no painel da AWS, só que dessa vez diretamente pelo ansible: # cat roles/launch/tasks/main.yml - name: Find Windows AMI base in this region ec2_ami_facts: owners: 801119661308 filters: name: Windows_Server-2019-English-Full-Base* register: found_amis - name: Get AMI Windows set_fact: win_ami_id: \"{{ (found_amis.images | first).image_id }}\" - name: Ensure security group is present ec2_group: name: WinRM RDP description: Inbound WinRM and RDP region: \"{{ target_aws_region }}\" vpc_id: \"{{ vpc_id }}\" rules: - proto: tcp from_port: 80 to_port: 80 cidr_ip: 0.0.0.0/0 - proto: tcp from_port: 5986 to_port: 5986 cidr_ip: 0.0.0.0/0 - proto: tcp from_port: 3389 to_port: 3389 cidr_ip: 0.0.0.0/0 rules_egress: - proto: -1 cidr_ip: 0.0.0.0/0 register: sg_out - name: Ensure instances are running ec2: region: \"{{ target_aws_region }}\" image: \"{{ win_ami_id }}\" instance_type: \"{{ instance_type }}\" group_id: \"{{ sg_out.group_id }}\" key_name: \"{{ keypair }}\" wait: yes wait_timeout: 500 exact_count: 1 assign_public_ip: yes vpc_subnet_id: \"{{ subnet }}\" count_tag: Name: stock-win-ami-test instance_tags: Name: stock-win-ami-test user_data: \"{{ lookup('template', 'userdata.txt.j2') }}\" register: ec2_result - name: wait for WinRM to answer on all hosts wait_for: port: 5986 host: \"{{ item.public_ip }}\" delay: 30 timeout: 300 state: started with_items: \"{{ ec2_result.tagged_instances }}\" - name: add hosts to groups add_host: name: \"win-temp-{{ item.id }}\" ansible_ssh_host: \"{{ item.public_ip }}\" ec2_id: \"{{ item.id }}\" groups: win changed_when: false with_items: \"{{ ec2_result.tagged_instances }}\" Agora vamos conectar na instância e fazer a instalação do que precisamos, vamos contar com auxilio de um script para instalar o Chocolatey e algumas ferramentas (JDK e git) somente para exemplo. Vamos também instalar algumas features do Windows como IIS, Powershell e .NET Framework, também somente para aprendizado. Também usaremos o módulo do Chocolatey para instalar o 7zip. # cat roles/deploy/tasks/main.yml - name: Copy Script config win_copy: src: script.ps1 dest: C:\\Windows\\","date":"27/12/2019","objectID":"/ansible-criado-ami-windows-personalizada-na-aws-parte-2/:0:0","tags":["aws","ansible","windows"],"title":"Ansible: Criado AMI Windows personalizada na AWS (Parte 2)","uri":"/ansible-criado-ami-windows-personalizada-na-aws-parte-2/"},{"categories":null,"content":"Quando vamos trabalhar com Ansbile usando Windows na AWS notamos que as imagens padrões do Windows não estão com o WinRM configurado e as senhas são geradas aleatoriamente usando a chave selecionada, sendo somente acessíveis alguns minutos após a instância iniciar. [Conectando em uma instância Windows](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/connecting_to_windows_instance.html).","date":"27/11/2019","objectID":"/ansible-criado-ami-windows-personalizada-na-aws-parte-1/","tags":["aws","ansible","windows"],"title":"Ansible: Criado AMI Windows personalizada na AWS (Parte 1)","uri":"/ansible-criado-ami-windows-personalizada-na-aws-parte-1/"},{"categories":null,"content":"Quando vamos trabalhar com Ansbile usando Windows na AWS notamos que as imagens padrões do Windows não estão com o WinRM configurado e as senhas são geradas aleatoriamente usando a chave selecionada, sendo somente acessíveis alguns minutos após a instância iniciar. Conectando em uma instância Windows. Uma alternativa é criar uma AMI personalizada com WinRM configurado e uma senha pré-definida, estando assim disponível imediatamente para uso. O primeiro passo é iniciar uma instância Windows colocando o script abaixo em User Data. Atenção para o campo onde está definido a senha, o script também irá baixar e executar o script para configurar o WinRM. \u003cpowershell\u003e $admin = [adsi](\"WinNT://./administrator, user\") $admin.PSBase.Invoke(\"SetPassword\", \"myTempPassword123!\") Invoke-Expression ((New-Object System.Net.Webclient).DownloadString('https://raw.githubusercontent.com/ansible/ansible/devel/examples/scripts/ConfigureRemotingForAnsible.ps1')) \u003c/powershell\u003e Caso você use o Packer para gerar suas imagens esse script também por ser usado no parâmetro user_data_file. Na configuração de Security Group da instância lembre-se de liberar as portas 3389 e 5986. Caso não saiba a porta 5986 é usada para conexão segura com o WinRM, que é usado pelo Ansible para conexão. Após alguns instantes após iniciar a instância ela já vai estar liberada para o acesso. No arquivo de hosts do ansible, configure usando os dados abaixo e a senha definida no script acima [windows] ip-host-windows [windows:vars] ansible_connection=winrm ansible_ssh_port=5986 ansible_ssh_user=Administrator ansible_ssh_pass=myTempPassword123! Após alguns instantes estando a instância disponível para acesso. Podemos testar usando o módulo do ansible win_ping. No nosso exemplo usando o comando ansible windows -i hosts -m win_ping. O retorno deve ser parecido com esse: Bom essa é a primeira etapa, na parte 2 iremos ver como configurar o Windows e gerar uma nova AMI personalizada usando o Ansible ","date":"27/11/2019","objectID":"/ansible-criado-ami-windows-personalizada-na-aws-parte-1/:0:0","tags":["aws","ansible","windows"],"title":"Ansible: Criado AMI Windows personalizada na AWS (Parte 1)","uri":"/ansible-criado-ami-windows-personalizada-na-aws-parte-1/"},{"categories":null,"content":"Este tutorial explica os conceitos básicos de como gerenciar buckets do S3 e seus objetos usando o aws s3 cli usando os seguintes exemplos","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Este tutorial explica os conceitos básicos de como gerenciar buckets do S3 e seus objetos usando o aws s3 cli usando os seguintes exemplos: ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:0:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Criar bucket aws s3 mb s3://bucketname # região diferente aws s3 mb s3://bucketname --region us-east-2 ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:1:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Remover Bucket aws s3 rb s3://bucketname aws s3 rb s3://bucketname --force ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:2:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Opção ls aws s3 ls aws s3 ls s3://bucketname aws s3 ls s3://bucketname --recursive aws s3 ls s3://bucketname --recursive --human-readable --summarize ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:3:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Opção cp aws s3 cp getdata.php s3://bucketname aws s3 cp /local/dir/data s3://bucketname --recursive aws s3 cp s3://bucketname/getdata.php /local/dir/data aws s3 cp s3://bucketname/ /local/dir/data --recursive aws s3 cp s3://bucketname/init.xml s3://backup-bucket aws s3 cp s3://bucketname s3://backup-bucket --recursive ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:4:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Opção mv aws s3 mv source.json s3://bucketname aws s3 mv s3://bucketname/getdata.php /home/project aws s3 mv s3://bucketname/source.json s3://backup-bucket aws s3 mv /local/dir/data s3://bucketname/data --recursive aws s3 mv s3://bucketname s3://backup-bucket --recursive ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:5:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Opção rm aws s3 rm s3://bucketname/queries.txt aws s3 rm s3://bucketname --recursive ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:6:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Opção sync aws s3 sync backup s3://bucketname aws s3 sync s3://bucketname/backup /tmp/backup aws s3 sync s3://bucketname s3://backup-bucket ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:7:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Criar website bucket aws s3 website s3://bucketname/ --index-document index.html --error-document error.html Caso tenham mais dúvidas, segue a documentação oficial: https://docs.aws.amazon.com/cli/latest/reference/s3/ ","date":"25/10/2019","objectID":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/:8:0","tags":["aws","s3"],"title":"Exemplo de comandos da AWS S3 para gerenciar buckets","uri":"/exemplo-de-comandos-do-aws-s3-para-gerenciar-buckets/"},{"categories":null,"content":"Ansible AWX é a versão OpenSource do [ansible Tower](https://www.ansible.com/products/tower), produto  comercial desenvolvido pela Red Hat. O AWX fornece uma interface de usuário baseada na Web, API REST e um mecanismo de tarefas construído sobre o Ansible. Neste tutorial, mostrarei como instalar e configurar o AWX usando o Docker.","date":"09/09/2019","objectID":"/instalar-ansible-awx-com-docker-no-centos-7/","tags":["ansible"],"title":"Instalar Ansible AWX com Docker no Centos 7","uri":"/instalar-ansible-awx-com-docker-no-centos-7/"},{"categories":null,"content":"Ansible AWX é a versão OpenSource do ansible Tower, produto comercial desenvolvido pela Red Hat. O AWX fornece uma interface de usuário baseada na Web, API REST e um mecanismo de tarefas construído sobre o Ansible. Neste tutorial, mostrarei como instalar e configurar o AWX usando o Docker. Desabilitar SELinux: systemctl stop firewalld systemctl disable firewalld Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. Habilitar repositório epel: yum install -y epel-release Instalar pacotes necessários: yum install -y yum-utils device-mapper-persistent-data lvm2 ansible git python-devel python-pip python-docker-py vim-enhanced Configurar repositório stable do Docker e instalá-lo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce -y Iniciar serviço systemctl start docker systemctl enable docker Clonar repositório AWX git clone https://github.com/ansible/awx.git cd awx/ git clone https://github.com/ansible/awx-logos.git pwd /root/awx Entrar na pasta de instalação cd installer/ Executar playbook da instalação ansible-playbook -i inventory install.yml -vv A instalação irá subir alguns container, pode conferir com o comando abaixo: docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 318c7c95dcbb ansible/awx_task:latest \"/tini -- /bin/sh -c.\" 12 minutes ago Up 12 minutes 8052/tcp awx_task 642c2f272e31 ansible/awx_web:latest \"/tini -- /bin/sh -c.\" 12 minutes ago Up 12 minutes 0.0.0.0:80-\u003e8052/tcp awx_web 641b42ab536f memcached:alpine \"docker-entrypoint.s.\" 18 minutes ago Up 18 minutes 11211/tcp memcached b333012d90ac rabbitmq:3 \"docker-entrypoint.s.\" 19 minutes ago Up 19 minutes 4369/tcp, 5671-5672/tcp, 25672/tcp rabbitmq ada52935513a postgres:9.6 \"docker-entrypoint.s.\" 19 minutes ago Up 19 minutes 5432/tcp postgres [root@awx installer]# Para acessar basta acessar no navegador o endereço do seu computador. Se aparecer a tela login está tudo pronto para usar. O usuário para login é “admin” e a senha é “password”. ","date":"09/09/2019","objectID":"/instalar-ansible-awx-com-docker-no-centos-7/:0:0","tags":["ansible"],"title":"Instalar Ansible AWX com Docker no Centos 7","uri":"/instalar-ansible-awx-com-docker-no-centos-7/"},{"categories":null,"content":"Esse compactador consegue usar múltiplos núcleos.","date":"21/06/2019","objectID":"/pigz-compactador-eficiente-e-rapido/","tags":["gzip","pigz"],"title":"Pigz - Compactador eficiente e rápido","uri":"/pigz-compactador-eficiente-e-rapido/"},{"categories":null,"content":"Talvez nem todos saibam mas a compactação usando gzip temos uma limitação da ferramenta não conseguir executar com múltiplos processadores. Para contornos essa limitação podemos usar uma ferramenta chama PIGZ, que usando threads consegue utilizar múltiplos processadores. A instalação depende da sua distribuição, mas utiliziando as mais comuns temos ela nos repositórios. Caso não tenho basta baixar o fonte no site deles. Manjaro: pacman -S pigz Ubuntu: apt-get install pigz O uso do pigz se dá assim: Usage: pigz [options] [files ...] tar -c --use-compress-program=pigz -f tar.file dir_to_zip tar --use-compress-program=pigz -cf OUTPUT_FILE.tar.gz paths_to_archive Para teste vamos compactar uma mesma pasta usando as duas ferramentas, gzip e pigz usando compressão máxima (-9) ╭─sidnei@black ~ ╰─$ du -sh web 4,2G web ","date":"21/06/2019","objectID":"/pigz-compactador-eficiente-e-rapido/:0:0","tags":["gzip","pigz"],"title":"Pigz - Compactador eficiente e rápido","uri":"/pigz-compactador-eficiente-e-rapido/"},{"categories":null,"content":"Usando GZIP ╭─sidnei@black ~ ╰─$ time tar -cf - web/ |gzip -9 - \u0026gt; web.tar.gz tar -cf - web/ 2,81s user 30,31s system 9% cpu 5:56,01 total gzip -9 - \u0026gt; web.tar.gz 267,42s user 6,43s system 76% cpu 5:56,01 total ╭─sidnei@black ~ ╰─$ du -h web.tar.gz 2,2G web.tar.gz ","date":"21/06/2019","objectID":"/pigz-compactador-eficiente-e-rapido/:0:1","tags":["gzip","pigz"],"title":"Pigz - Compactador eficiente e rápido","uri":"/pigz-compactador-eficiente-e-rapido/"},{"categories":null,"content":"Usando PIGZ ╭─sidnei@black ~ ╰─$ time tar -c --use-compress-program=\"pigz -9\" -f web.tar.gz web/ 130 ↵ tar -c --use-compress-program=\"pigz -9\" -f web.tar.gz web/ 356,10s user 35,11s system 175% cpu 3:43,30 total ╭─sidnei@black ~ ╰─$ du -sh web.tar.gz 2,2G web.tar.gz Na comparação a compactação teve o mesmo tamanho final, porém com o uso de CPU muito maior por parte do PIGZ, lembrando que quanto melhor sua máquina, mais recursos, melhor será o desempenho. É claro que dependendo a quantidade de arquivos e os tamanhos você não notará tanta diferença, mas com grandes quantidades de arquivos é notório o melhor desempenho. Nesse site temos um comparativo bem legal com várias ferramentas de compressão. ","date":"21/06/2019","objectID":"/pigz-compactador-eficiente-e-rapido/:0:2","tags":["gzip","pigz"],"title":"Pigz - Compactador eficiente e rápido","uri":"/pigz-compactador-eficiente-e-rapido/"},{"categories":null,"content":"Alguns usos pouco conhecidos do comando ping.","date":"26/04/2019","objectID":"/exemplos-de-uso-do-comando-ping/","tags":["linux","rede"],"title":"Exemplos de uso do comando ping","uri":"/exemplos-de-uso-do-comando-ping/"},{"categories":null,"content":"Segundo o Wikipédia ping é … “Ping ou latência como podemos chamar, é um utilitário que usa o protocolo ICMP para testar a conectividade entre equipamentos. É um comando disponível praticamente em todos os sistemas operacionais. Seu funcionamento consiste no envio de pacotes para o equipamento de destino e na escuta das respostas. Se o equipamento de destino estiver ativo, uma resposta “pong”, uma analogia ao famoso jogo de ping-pong) é devolvida ao computador solicitante. ” Sabendo dessa teoria agora vamos a alguns exemplos: Exemplo 1: Aumentar ou diminuir o intervalo de tempo entre os pacotes enviados. O ping abaixo esperará cinco segundos antes de enviar o próximo pacote: ping -i 5 192.168.3.1 E para diminuir o intervalo de tempo: ping -i 0.3 192.168.3.1 Exemplo 2: Verificar se a interface está ativa. Por exemplo: ping 127.0.0.1 PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.046 ms 64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.054 ms 64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.055 ms 64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.052 ms Quando obtiver um tempo de resposta é por que a interface está comunicando, caso contrário irá exibir alguma mensagem de erro: ping 192.168.3.50 PING 192.168.3.50 (192.168.3.50) 56(84) bytes of data. From 192.168.3.18 icmp_seq=1 Destination Host Unreachable From 192.168.3.18 icmp_seq=2 Destination Host Unreachable From 192.168.3.18 icmp_seq=3 Destination Host Unreachable From 192.168.3.18 icmp_seq=4 Destination Host Unreachable Exemplo 3: Envie N pacotes e pare. No Linux e outras espécies Unix, o comando ping não termina até que você pressione Ctrl + C, para enviar um certo número de pacotes usamos o argumento -c. Vamos testar enviando 2 pacotes: ping -c 2 192.168.3.1 PING 192.168.3.1 (192.168.3.1) 56(84) bytes of data. 64 bytes from 192.168.3.1: icmp_seq=1 ttl=30 time=2.72 ms 64 bytes from 192.168.3.1: icmp_seq=2 ttl=30 time=2.70 ms --- 192.168.3.1 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 3ms rtt min/avg/max/mdev = 2.696/2.707/2.718/0.011 ms Exemplo 4: ping com áudio, envia um beep a cada ping com sucesso ping -a localhost Exemplo 5: “Inundar” a rede. Dísponivel somente para superusuários, envia cem ou mais pacotes por segundo, imprimindo um ponto por cada pacote enviado e um espaço quando recebido. sudo ping -f 192.168.3.1 2 ↵ [sudo] senha para sidnei: PING 192.168.3.1 (192.168.3.1) 56(84) bytes of data. .^C --- 192.168.3.1 ping statistics --- 1858 packets transmitted, 1857 received, 0.0538213% packet loss, time 412ms rtt min/avg/max/mdev = 1.962/2.381/48.167/2.565 ms, pipe 3, ipg/ewma 2.373/2.276 ms Exemplo 6: Encontrar o endereço IP de um domínio. Quando um ping é disparado em um nome domínio, antes do envio dos pacotes o comando escreve a saída padrão entre parênteses, depois do nome de domínio, o IP do mesmo. ping -c1 google.com PING google.com(2800:3f0:4001:803::200e (2800:3f0:4001:803::200e)) 56 data bytes 64 bytes from 2800:3f0:4001:803::200e (2800:3f0:4001:803::200e): icmp_seq=1 ttl=57 time=33.1 ms --- google.com ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 33.078/33.078/33.078/0.000 ms Exemplo 7: Mostrar apenas as estatísticas do comando. No final do comando é mostrado estatísticas como quantidade de pacotes transmitidos, recebidos, porcentagem de pacotes perdidos e tempo. Se queremos ver somente as estatísticas sem observar cada linha de pacote enviado podemos utilizar a opção -q (quiet). ping -c5 -q 127.0.0.1 PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. --- 127.0.0.1 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 63ms rtt min/avg/max/mdev = 0.047/0.058/0.090/0.017 ms Exemplo 8: Modificar o tamanho do pacote. Por padrão o tamanho do pacote do ping fica entre 56 a 100 bytes. Se utiliza o tamanho do pacote 100, verá 128 bytes, isto se deve a que 28 bytes é o tamanho do cabeçalho do ping. ping -","date":"26/04/2019","objectID":"/exemplos-de-uso-do-comando-ping/:0:0","tags":["linux","rede"],"title":"Exemplos de uso do comando ping","uri":"/exemplos-de-uso-do-comando-ping/"},{"categories":null,"content":"Primeitos passos usando o shell do Mongo.","date":"02/04/2019","objectID":"/iniciando-com-mongodb/","tags":["mongo"],"title":"Iniciando com MongoDB","uri":"/iniciando-com-mongodb/"},{"categories":null,"content":"Após termos realizado a instalação do MongoDB nesse post, hoje vamos iniciar com os primeiros passos com nosso banco de dados. ","date":"02/04/2019","objectID":"/iniciando-com-mongodb/:0:0","tags":["mongo"],"title":"Iniciando com MongoDB","uri":"/iniciando-com-mongodb/"},{"categories":null,"content":"Utilizando o Mongo Shell Quando estamos utilizando o mongo em localhost (127.0.0.1) não é necessário usuário e senha para realizar a conexão. $mongo MongoDB shell version v4.0.6 connecting to: mongodb://127.0.0.1:27017/?gssapiServiceName=mongodb Implicit session: session { \"id\" : UUID(\"319f1942-5755-4448-a5a5-282acf77ed6d\") } MongoDB server version: 4.0.6 Primeiro comando a ser usado é o use, utilizado para selecionar o banco usado. $use usuarios switched to db usuarios Método insert( ) para armazenar um documento contendo as chaves “name” e “idade”. As informações são armazenadas na estrutura, chave/valor, similar ao JSON. db.usuarios.insert({ name: \"Sidnei\", idade: 31} ) WriteResult({ \"nInserted\" : 1 }) No comando db.usuarios.insert, esse usuários corresponde a uma coleção, e ela não precisa de uma estrutura definida, podendo ser dinâmica caso haja necessidade. Podemos usar o comando abaixo sem alterar nenhum tipo de definição de estrutura que o insert irá funcionar normalmente. db.usuarios.insert({ name: \"Sidnei\", idade: 31, cidade: \"Sapiranga\" }) WriteResult({ \"nInserted\" : 1 }) Use o método find( ) para visualizar os documentos inseridos. Vamos buscar o que foi salvo na coleção usuarios: db.getCollection('usuarios').find({}) { \"_id\" : ObjectId(\"5ca3bbb7719bb01a6641f7cb\"), \"name\" : \"Sidnei\", \"idade\" : 31 } { \"_id\" : ObjectId(\"5ca3bd99719bb01a6641f7cc\"), \"name\" : \"Sidnei\", \"idade\" : 31, \"cidade\" : \"Sapiranga\" } Essa pesquisa também pode ser aprofundada, por exemplo pesquisando só quem está na cidade “Sapiranga” db.getCollection('usuarios').find({cidade:\"Sapiranga\"}) { \"_id\" : ObjectId(\"5ca3bd99719bb01a6641f7cc\"), \"name\" : \"Sidnei\", \"idade\" : 31, \"cidade\" : \"Sapiranga\" } E para sairmos do nosso shell basta executar o comando: $exit bye Para o início está de bom tamanho, até a próxima. ","date":"02/04/2019","objectID":"/iniciando-com-mongodb/:0:1","tags":["mongo"],"title":"Iniciando com MongoDB","uri":"/iniciando-com-mongodb/"},{"categories":null,"content":"Super fácil instalar o MongoDB no ubuntu usando gerenciador de pacotes.","date":"08/03/2019","objectID":"/instalando-mongodb-community-edition-4-0-no-ubuntu/","tags":["mongo"],"title":"Instalando MongoDB Community Edition 4.0 no Ubuntu","uri":"/instalando-mongodb-community-edition-4-0-no-ubuntu/"},{"categories":null,"content":"O que é MongoDB O MongoDB é um banco de dados NoSQL orientado a documentos de alto desempenho (sistema noSQL significa que ele não fornece tabelas, linhas, etc.). Ele armazena dados em documentos semelhantes a JSON com esquemas dinâmicos para melhor desempenho. ","date":"08/03/2019","objectID":"/instalando-mongodb-community-edition-4-0-no-ubuntu/:0:1","tags":["mongo"],"title":"Instalando MongoDB Community Edition 4.0 no Ubuntu","uri":"/instalando-mongodb-community-edition-4-0-no-ubuntu/"},{"categories":null,"content":"Adicionando repositórios Para instalar MongoDB Community Edition no Ubuntu, precisamos primeiro importar a chave pública usada pelo gerenciador de pacotes. sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 9DA31620334BD75D9DCB49F368818C72E52529D4 No Ubuntu 18.04 echo \"deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list sudo apt-get update No Ubuntu 16.04 echo \"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list sudo apt-get update No Ubuntu 14.04 echo \"deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/4.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list sudo apt-get update ","date":"08/03/2019","objectID":"/instalando-mongodb-community-edition-4-0-no-ubuntu/:0:2","tags":["mongo"],"title":"Instalando MongoDB Community Edition 4.0 no Ubuntu","uri":"/instalando-mongodb-community-edition-4-0-no-ubuntu/"},{"categories":null,"content":"Instalando o pacote sudo apt-get install -y mongodb-org ","date":"08/03/2019","objectID":"/instalando-mongodb-community-edition-4-0-no-ubuntu/:0:3","tags":["mongo"],"title":"Instalando MongoDB Community Edition 4.0 no Ubuntu","uri":"/instalando-mongodb-community-edition-4-0-no-ubuntu/"},{"categories":null,"content":"Habilitando e iniciando serviço systemctl enable mongod.service systemctl start mongod.service E pronto já podemos usar no mongo, lembrando que é necessário liberar a porta 27017 no firewall caso o mesmo esteja habilitado. Nos próximos posts falaremos um pouco mais sobre o mongo. ","date":"08/03/2019","objectID":"/instalando-mongodb-community-edition-4-0-no-ubuntu/:0:4","tags":["mongo"],"title":"Instalando MongoDB Community Edition 4.0 no Ubuntu","uri":"/instalando-mongodb-community-edition-4-0-no-ubuntu/"},{"categories":null,"content":" Instalando última versão do Ansible no Ubuntu/Debian. ","date":"22/01/2019","objectID":"/instalando-ultima-versao-ansible-no-ubuntu-debian/","tags":["ansible"],"title":"Instalando última versão do Ansible no Ubuntu/Debian","uri":"/instalando-ultima-versao-ansible-no-ubuntu-debian/"},{"categories":null,"content":"Caso não saiba o que é Ansible, pode dar uma lida nesse post. A forma mais simples para instalar o Ansible é com o comando abaixo, porém é instalado uma versão mais antiga. sudo apt-get update sudo apt-get install ansible Agora para baixar uma versão mais atualizada basta seguir os passos abaixo: sudo aptitude update sudo aptitude install python-pip sudo pip install ansible ","date":"22/01/2019","objectID":"/instalando-ultima-versao-ansible-no-ubuntu-debian/:0:0","tags":["ansible"],"title":"Instalando última versão do Ansible no Ubuntu/Debian","uri":"/instalando-ultima-versao-ansible-no-ubuntu-debian/"},{"categories":null,"content":"O comando ping utiliza o protocolo icmp e é muito útil para alguns testes de rede. O que pouca gente sabe é que durante a resposta do comando ping, uma informação pode nos informar qual o sistema operacional está respondendo. Essa informação é TTL (Time to Live). Ex: ping 127.0.0.1 PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data. 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.030 ms 64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.035 ms 64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.041 ms Podemos ver que nesse exemplo o TTL é 64 que corresponde ao Linux. É bom lembrar que cada vez que um pacote passa por um roteador é reduzido um do valor TTL. Caso a resposta seja 64, significa que o pacote veio de um Linux e passou por 2 roteadores. Unix = 255 Linux = 64 Windows = 128 ","date":"17/01/2019","objectID":"/identificar-sistema-operacional-com-ping/:0:0","tags":["rede"],"title":"Identificar sistema operacional com ping","uri":"/identificar-sistema-operacional-com-ping/"},{"categories":null,"content":"Caso sua lista de container esteja muito grande e queira remover alguns containers do seu host, podemos usar o comando abaixo para remover container parados a mais tempo: docker ps --filter \"status=exited\" | grep 'weeks ago' | awk '{print $1}' | xargs --no-run-if-empty docker rm Explicando: docker ps --filter \"status=exited\" Lista somente os containers parados, que não estão em execução grep 'weeks ago' Filtra por containers criados a semanas atrás awk '{print $1}' Exibe a primeira coluna, que refere ao CONTAINER ID xargs --no-run-if-empty docker rm Pega o que foi filtrado até agora e joga como parâmetro para o docker rm Sempre use os comandos com muito cuidado caso não tenha certeza do que está fazendo, não me responsabilizo por qualquer erro humano ;). ","date":"26/12/2018","objectID":"/limpar-container-antigos-docker/:0:0","tags":["docker"],"title":"Limpar container antigos Docker","uri":"/limpar-container-antigos-docker/"},{"categories":null,"content":"Quem nunca passou pela situação de executar um script e o mesmo apresentar erro. Normal, mas algumas vezes o erro ocorre pela formatação, principalmente se foi escrito ou salvo em um Windows. Ocorre de no final de cada linha ele acrescentar um ^M, o que não o Linux não consegue interpretar. Existem algumas formas de corrigir esse problema, a mais conhecida é usando o aplicativo dos2unix Mas o quero apresentar hoje é usando o poderoso Vim. Basta estando dentro do arquivo digitar o comando abaixo: :set ff=unix Simples e rápido, caso por algum motivo queira fazer o processo contrário, basta executar: :set ff=dos ","date":"06/11/2018","objectID":"/convertendo-arquivos-dos-m-com-vim/:0:0","tags":["linux","shell script"],"title":"Convertendo arquivos DOS ^M com Vim","uri":"/convertendo-arquivos-dos-m-com-vim/"},{"categories":null,"content":"O fuser é um programa que permite que saibamos qual processo está utilizando determinado arquivo, socket (portas) e sistema de arquivos especificado. Aprender sua manipulação é essencial para poder administrar um servidor para saber o que está acontecendo principalmente nas conexões. É um comando extremamente flexível, vamos ver suas opções e seu uso. Diretiva Descrição Exemplo -a, –all Mostra todos os arquivos, inclusive os que estão sem uso fuser -a * -k, –kill Desativa/Mata os processos que estão utilizando determinado arquivo fuser -k /home/zonebin -i, –interactive Pede confirmação sempre que for matar um processo utilizando um arquivo fuser -ik /home/zonebin -m, –mount Especifica um sistema de arquivos para descobrir qual processo está sendo utilizado fuser -m /dev/sda1 -s, –silent Realiza as operações indicadas silenciosamente, não use a opção -a, -u, -v fuser -ks /home -u, –user Mostra o nome de usuário que iniciou o processo que está utilizando o arquivo fuser -u /var/log/messages -4, –ipv4 Mostra processos de IPV4 somente fuser -4 ssh/tcp -6 -ipv6 Mostra somente processos de sockets IPV6 fuser -6 25/tcp Tipos de acesso: c Diretório atual e Arquivo executável rodando f Arquivo aberto (omitido no modo de display padrão) F arquivo aberto para escrita (omitido no modo de display padrão) r Diretório root m Arquivo mapeado ou biblioteca compartilhada Exemplos: Mostrar os processos em execução no diretório atual fuser -v . Verificando se está sendo usado socket TCP ou UDP, como a porta 22 (SSH): fuser -v -n tcp 22 Para mais informações: man fuser ","date":"06/11/2018","objectID":"/comando-fuser-quem-mexeu-no-meu-arquivo/:0:0","tags":["linux"],"title":"Comando fuser - Quem mexeu no meu arquivo","uri":"/comando-fuser-quem-mexeu-no-meu-arquivo/"},{"categories":null,"content":"Obviamente precisaremos ter instalado o docker e docker-compose, caso não saiba como instalar pode acessar o link e esse outro link. Precisaremos criar um arquivo docker-compose.yml com o seguinte conteúdo: persistentDB: img \"busybox:latest\" volumes: - /var/lib/mysql zabbixDB: img \"monitoringartist/zabbix-db-mariadb\" environment: MARIADB_USER: zabbix MARIADB_PASS: senha PHP_date_timezone: America/Sao_Paulo ZS_StartDiscoverers: \"5\" ZS_StartPingers: \"5\" volumes_from: - persistentDB volumes: - \"/etc/localtime:/etc/localtime:ro\" - \"/srv/zabbix/backups:/backups\" hostname: zabbix-db zabbix: img \"monitoringartist/zabbix-3.0-xxl:latest\" ports: - \"80:80\" - \"10051:10051\" volumes: - \"/etc/localtime:/etc/localtime:ro\" links: - \"zabbixDB:zabbix.db\" environment: ZS_DBHost: zabbix.db ZS_DBUser: zabbix ZS_DBPassword: senha TERM: xterm E iremos executar o seguinte comando: docker-compose up -d Caso queiram contribuir segue o github desse código: https://github.com/sidneiweber/zabbix-docker ","date":"06/09/2018","objectID":"/iniciando-zabbix-com-docker-compose/:0:0","tags":["zabbix"],"title":"Iniciando Zabbix com Docker Compose","uri":"/iniciando-zabbix-com-docker-compose/"},{"categories":["Linux"],"content":"Com SystemD é possível gerenciar o sistema e serviços no seu Linux. Ele usa o Control Groups (CGroups), cada serviço iniciado pelo systemd roda dentro de um cgroup separado, fazendo com que se tenha garantia que cada processo iniciado por serviço seja encerrado corretamente. Para listar todos os serviços em execução: systemctl -t service Para ver o status de um serviço: systemctl status cups.service Para ativar um serviço na inicialização: systemctl enable cups.service Para retirar um serviço da inicialização: systemctl disable cups.service Para listar units sendo executadas: systemctl systemctl list-units Para listar units que falharam: systemctl --failed Listar os serviços instalados: systemctl list-unit-files Reiniciar o sistema: systemctl reboot Desliga e encerra o sistema: systemctl poweroff Suspender o sistema: systemctl suspend Colocar o sistema em modo de hibernação: systemctl hibernate Colocar o sistema em modo de suspensão: systemctl hybrid-sleep ","date":"02/07/2018","objectID":"/gerenciando-servicos-com-systemd/:0:0","tags":["systemctl","systemd"],"title":"Gerenciando serviços com SystemD","uri":"/gerenciando-servicos-com-systemd/"},{"categories":null,"content":"Review Emmi Linux por Prof. Juliano Ramos","date":"02/07/2018","objectID":"/review-emmi-linux-por-prof-juliano-ramos/","tags":["linux","emmi linux"],"title":"Review Emmi Linux por Prof. Juliano Ramos [Vídeo]","uri":"/review-emmi-linux-por-prof-juliano-ramos/"},{"categories":null,"content":" ANSIBLE LOVES THE REPETITIVE WORK YOUR PEOPLE HATE Com essa frase começa a apresentação da ferramenta Ansible em seu próprio site. Bom, resumidamente o Ansible é um software que automatiza o provisionamento de software, gerenciamento de configuração e implantação de aplicativos. Ou seja, tudo aquilo que era feito repetidas vezes para configurar, atualizar um servidor ou serviço, pode ser automatizado com Ansible. Bem vindo ao mundo da automação 🙂 Obviamente o Ansible não é a única ferramenta que pode fazer esse trabalho, temos outras ferramentas como Chef, Puppet, Saltstack. Todas elas tem suas características, qualidades e defeitos em particular, não realizar comparação entre essas ferramentas, vou somente dar a minha posição de o por que escolhi o Ansible. Simplicidade e recursos: Ansible foi desenvolvido em Python, então praticamente todas as versões de Linux terão suporte a mesma. Mais de 1000 módulos para tudo quanto é tipo de áreas: banco de dados, monitoramento, nuvem e até para Windows. Comandos “ad-hoc” diretamente para diversos recursos. Podemos criar playbooks usando o padrão YAML de fácil entendimento. Possui módulos para Docker, Vmware, Proxmox, AWS, Openstack, Azure, gerenciamento de pacotes, enfim, são muitos módulos mesmo. Caso queira ver a lista completa, acesse este endereço. Sem agentes: Principal recurso que me fez optar em estudar o Ansible foi pelo fato de não necessitar o uso de agentes nos clientes, basta que o cliente tenha Python instalado e acesso via SSH ou Winrm para Windows. ","date":"19/06/2018","objectID":"/ansible-o-que-e-e-para-que-serve/:0:0","tags":["ansible","devops"],"title":"Ansible - O que é e para que serve","uri":"/ansible-o-que-e-e-para-que-serve/"},{"categories":null,"content":"Instalação Ansible: A instalação segue o mesmo nível de simplicidade de seu uso, basta utilizar o gerenciador de pacotes de sua distribuição: Ubuntu: sudo apt-get install software-properties-common sudo apt-add-repository ppa:ansible/ansible sudo apt-get update -y \u0026\u0026 sudo apt-get install -y ansible Centos, Fedora: yum install -y epel-release \u0026\u0026 yum install -y ansible ","date":"19/06/2018","objectID":"/ansible-o-que-e-e-para-que-serve/:0:1","tags":["ansible","devops"],"title":"Ansible - O que é e para que serve","uri":"/ansible-o-que-e-e-para-que-serve/"},{"categories":null,"content":"Execução: AD HOC vs Playbook Essa são as duas maneiras que temos de executar nossos comandos no Ansible como dito anteriormente. Um arquivo muito importante para é o /etc/ansible/hosts onde a gente pode organizar as máquinas onde poderemos realizar as execuções, em breve escrevei um artigo com alguns macetes desse arquivo. Vamos por a mão na massa executando nosso primeiro comando em localhost, somente para teste usaremos o módulo “ping”: root@localhost:~# ansible 127.0.0.1 -m ping 127.0.0.1 | SUCCESS { \"changed\": false, \"ping\": \"pong\" } Sucesso, tivemos o retorno do ping do nosso localhost ;). Bom no próximo artigo irei explicar como realizar execuções em algumas máquinas remotas ao mesmo tempo e alguns outro macetes. Até a próxima! ","date":"19/06/2018","objectID":"/ansible-o-que-e-e-para-que-serve/:0:2","tags":["ansible","devops"],"title":"Ansible - O que é e para que serve","uri":"/ansible-o-que-e-e-para-que-serve/"},{"categories":null,"content":"Estou realizando a instalação na última versão do Centos no momento, que seria a 7. Porém o procedimento para outras versões deve seguir o mesmo padrão. Instalando dependências: yum install -y make wget gcc readline-devel zlib-devel Vamos baixar a última versão do Postresql (10.3 no momento dos testes) e após o download concluído iremos descompactar: wget -c https://ftp.postgresql.org/pub/source/v10.3/postgresql-10.3.tar.gz tar -xzvf postgresql-10.3.tar.gz Após isso vamos realizar o processo de compilação, instalação e criação do usuário postgres. Dependendo da configuração de sua máquina esse processo pode demorar um pouco: ./configure gmake gmake install adduser postgres mkdir -p /usr/local/postgres/data chown postgres /usr/local/postgres/data Iniciaremos o serviço: su - postgres /usr/local/pgsql/bin/initdb -D /usr/local/postgres/data /usr/local/pgsql/bin/postgres -D /usr/local/postgres/data \u003elogfile 2\u003e\u00261 \u0026 [postgres@a984adfc81b5 ~]$ ps -ef |grep postgres root 8636 1 0 00:21 pts/0 00:00:00 su - postgres postgres 8637 8636 0 00:21 pts/0 00:00:00 -bash postgres 8667 8637 0 00:23 pts/0 00:00:00 /usr/local/pgsql/bin/postgres -D /usr/local/postgres/data postgres 8669 8667 0 00:23 ? 00:00:00 postgres: checkpointer process postgres 8670 8667 0 00:23 ? 00:00:00 postgres: writer process postgres 8671 8667 0 00:23 ? 00:00:00 postgres: wal writer process postgres 8672 8667 0 00:23 ? 00:00:00 postgres: autovacuum launcher process postgres 8673 8667 0 00:23 ? 00:00:00 postgres: stats collector process postgres 8674 8667 0 00:23 ? 00:00:00 postgres: bgworker: logical replication launcher postgres 8677 8637 0 00:23 pts/0 00:00:00 ps -ef Agora com tudo instalado e serviço iniciado realizar alguns testes: /usr/local/pgsql/bin/createdb teste /usr/local/pgsql/bin/psql teste psql (10.3) Type \"help\" for help. teste=# Instalação finalizada com sucesso 🙂 ","date":"03/05/2018","objectID":"/instalacao-postresql-no-centos-a-partir-do-codigo-fonte/:0:0","tags":["postgresql","centos"],"title":"Instalação Postresql no Centos a partir do código fonte","uri":"/instalacao-postresql-no-centos-a-partir-do-codigo-fonte/"},{"categories":null,"content":"Hoje lhes apresento uma ferramenta muito boa para gerenciar os programas no Windows, chamada Chocolatey. Para quem está acostumando com gerenciadores de pacotes do Linux como apt, yum, etc, vai se sentir em casa. Ele consegue instalar e atualizar e remover diversos programas, facilitando muito o trabalho dos técnicos e até para gerenciar um grande parque de máquinas do seu trabalho. O programa é suporte do Windows 7 em diante e Windows server 2003 em diante, tem como pré requisito o programa .NET Framework 4+. A instalação é bem simples e pode ser feita via cmd ou Powershell Instalando via CMD: @\"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\" \u0026\u0026 SET \"PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\" Instalando via Powershell Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) Após a instalação o comando choco já estará disponivel. Segue algumas opções do comando: list - Lista os pacotes disponíveis, enquanto fazia testes haviam incríveis 5644 pacotes search - Realiza pesquisa de pacotes info - Traz informações sobre um pacote install - Obviamente, instala upgrade - Atualiza uninstall - Adivinhe, remove 🙂 Caso queiramos instalar o VLC por exemplo: choco install vlc Há também uma página onde pode se verificar uma lista com os pacotes pelo link https://chocolatey.org/packages. Sem contar ainda em um gerenciador gráfico chamado Chocolatey GUI, que pode sem instalado com o comando choco install chocolateygui. ","date":"17/04/2018","objectID":"/instalando-e-gerenciando-programas-no-windows-com-chocolatey/:0:0","tags":["chocolatey"],"title":"Instalando e gerenciando programas no Windows com Chocolatey","uri":"/instalando-e-gerenciando-programas-no-windows-com-chocolatey/"},{"categories":null,"content":"O que é esse tal de Rundeck Falando a grosso modo Rundeck é um automatizador e agendador de tarefas. Obviamente que ele faz muito mais do que isso, ele consegue rodar essas tarefas tanto em Linux quanto em Windows. Consegue-se criar um workflow de tarefas, fazendo uma tarefa depender de outra ou conforme sua execução com sucesso ou insucesso. Escrito em java e tem sua administração por uma interface web bem simples de ser usado e usa ssh para conexões com Linux e Winrm para conexões com Windows. As configurações ficam salvas em arquivos, geralmente XML, tanto dos jobs (trabalhos) quanto dos nodes (hosts). Tem uma grande vantagem pois não precisa de agentes rodando nas máquinas clientes e se consegue fazer uma verdadeira orquestração de jobs, podendo escolher se os jobs vão rodar em paralelo ou sequência e assim por diante. Se consegue criar chaves de acesso, ou chaves com senhas dentro do próprio dashboard. Existe uma integração com diversos serviços: Uma das poucas desvantagens que achei até o momento, que algumas configurações como de usuários, nodes, terem que ser feitas pela linha de comando editando diretamente os arquivos. Para usar o Rundeck, precisamos ter instalado o java (1.8) em nosso servidor. Realizei alguns testes no Centos. java -version java version \"1.8.0_131\" Java(TM) SE Runtime Environment (build 1.8.0_131-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode) E instalaremos o rundeck adicionando o repositório. rpm -Uvh http://repo.rundeck.org/latest.rpm yum install rundeck Após instalação ocorrer tudo bem, podemos conferir verificando a porta onde o serviço roda. Lembrando que caso tenha algum firewall ou bloqueio de portas o mesmo deve ser liberado. netstat -an | egrep '4440|4443' tcp46 0 0 *.4440 *.* LISTEN Agora basta acessarmos o IP do nosso servidor seguido da porta. Ex: http://localhost:4440 e usar a famosa senha de admin/admin Bom de momento vamos ficar somente com a instalação, nos próximos artigos vamos aprender a cadastrar nodes, executar comandos, scripts e demais coisas que essa baita ferramenta disponibiliza. Site: http://rundeck.org/ ","date":"09/04/2018","objectID":"/rundeck-automatizando-suas-tarefas/:0:0","tags":["devops","rundeck"],"title":"Rundeck - Automatizando suas tarefas","uri":"/rundeck-automatizando-suas-tarefas/"},{"categories":null,"content":"Podcast - Conversa com Dionatan do Canal Diolinux [Vídeo]","date":"02/04/2018","objectID":"/podcast-conversa-com-dionatan-do-canal-diolinux/","tags":["diolinux","podcast"],"title":"Podcast - Conversa com Dionatan do Canal Diolinux","uri":"/podcast-conversa-com-dionatan-do-canal-diolinux/"},{"categories":null,"content":"Mais um podcast gravado para o canal do Slackjeff. Canal Diolinux ","date":"02/04/2018","objectID":"/podcast-conversa-com-dionatan-do-canal-diolinux/:0:0","tags":["diolinux","podcast"],"title":"Podcast - Conversa com Dionatan do Canal Diolinux","uri":"/podcast-conversa-com-dionatan-do-canal-diolinux/"},{"categories":null,"content":"Podcast - Mercado, Dinheiro e Opensource [Vídeo]","date":"02/04/2018","objectID":"/podcast-mercado-dinheiro-e-opensource/","tags":["opensource","podcast"],"title":"Podcast - Mercado, Dinheiro e Opensource","uri":"/podcast-mercado-dinheiro-e-opensource/"},{"categories":null,"content":"Podcast gravado recentemente no Canal do Slackjeff ","date":"02/04/2018","objectID":"/podcast-mercado-dinheiro-e-opensource/:0:0","tags":["opensource","podcast"],"title":"Podcast - Mercado, Dinheiro e Opensource","uri":"/podcast-mercado-dinheiro-e-opensource/"},{"categories":null,"content":"Hoje vamos a mais uma dica rápida. Pra que usa seus servidores virtualizados e precisa adicionar um novo HD seja por falta de espaço ou pelo motivo que for, não precisa reiniciar o servidor para ter o HD reconhecido. Basta apenas executar um simples comando que ordena um “scan” no barramento. Vale lembrar também que essa dica é para virtualizações com Hot plug habilitado. echo \"- – -\" \u003e /sys/class/scsi_host/host0/scan Obrigado e até a próxima. ","date":"30/01/2018","objectID":"/reconhecer-hd-novo-linux-sem-reiniciar/:0:0","tags":["linux"],"title":"Reconhecer HD novo Linux sem reiniciar","uri":"/reconhecer-hd-novo-linux-sem-reiniciar/"},{"categories":null,"content":"Para configurar o uso do uso sem senha, o que não é recomendado, somente em casos de algum programa precise de permissão para executar determinado comando. Podemos usar como exemplo o Zabbix que quer rodar algum programa com privilégio de root sem comprometer a segurança. O arquivo a ser editado será o /etc/sudoers: Configurar sudo sem senha para tudo: zabbix ALL=NOPASSWD: ALL Ou podemos configurar para executar somente algo em específico: zabbix ALL=NOPASSWD: /usr/bin/nmap # Mais de um comando zabbix ALL=NOPASSWD: /usr/bin/nmap, /etc/init.d/apache2 restart E por hoje era isso pessoal, aquele abraço ","date":"01/12/2017","objectID":"/configurar-sudo-sem-senha/:0:0","tags":["linux","sudo"],"title":"Configurar sudo sem senha","uri":"/configurar-sudo-sem-senha/"},{"categories":null,"content":"Como deixar a hora mais legível no dmesg","date":"20/10/2017","objectID":"/hora-mais-legivel-no-dmesg/","tags":["linux","dmesg"],"title":"Hora mais legível no dmesg","uri":"/hora-mais-legivel-no-dmesg/"},{"categories":null,"content":"Saída padrão do dmesg: [ 7515.054630] CPU7: Core temperature above threshold, cpu clock throttled (total events = 29938) [ 7515.055666] CPU3: Core temperature/speed normal [ 7515.055668] CPU7: Core temperature/speed normal [ 9253.929870] CPU4: Core temperature above threshold, cpu clock throttled (total events = 5697) [ 9253.929873] CPU0: Core temperature above threshold, cpu clock throttled (total events = 5697) [ 9253.930911] CPU4: Core temperature/speed normal [ 9253.930913] CPU0: Core temperature/speed normal Saída do comando dmesg -T: [Sex Out 20 21:56:10 2017] CPU7: Core temperature above threshold, cpu clock throttled (total events = 29938) [Sex Out 20 21:56:10 2017] CPU3: Core temperature/speed normal [Sex Out 20 21:56:10 2017] CPU7: Core temperature/speed normal [Sex Out 20 22:25:08 2017] CPU4: Core temperature above threshold, cpu clock throttled (total events = 5697) [Sex Out 20 22:25:08 2017] CPU0: Core temperature above threshold, cpu clock throttled (total events = 5697) [Sex Out 20 22:25:08 2017] CPU4: Core temperature/speed normal [Sex Out 20 22:25:08 2017] CPU0: Core temperature/speed normal Podemos incluise criar um alias no bashrc: alias dmesg=\"dmesg -T\" ","date":"20/10/2017","objectID":"/hora-mais-legivel-no-dmesg/:0:0","tags":["linux","dmesg"],"title":"Hora mais legível no dmesg","uri":"/hora-mais-legivel-no-dmesg/"},{"categories":null,"content":"Bloquear resposta ao ping com sysctl","date":"20/10/2017","objectID":"/bloquear-resposta-ao-ping-com-sysctl/","tags":["linux","rede"],"title":"Bloquear resposta ao ping com sysctl","uri":"/bloquear-resposta-ao-ping-com-sysctl/"},{"categories":null,"content":"A dica de hoje é super rápida e prática, para bloquear as respostas de ping podemos usar o comando sysctl: Para bloquear: sysctl -w net.ipv4.icmp_echo_ignore_all=1 Para desbloquear: sysctl -w net.ipv4.icmp_echo_ignore_all=0 ","date":"20/10/2017","objectID":"/bloquear-resposta-ao-ping-com-sysctl/:0:0","tags":["linux","rede"],"title":"Bloquear resposta ao ping com sysctl","uri":"/bloquear-resposta-ao-ping-com-sysctl/"},{"categories":null,"content":"Para podermos ter um controle maior sobre a segurança dos nossos sistemas e rede de computadores, podemos definir uma política de senhas onde as mesmas devem ter um grau alto de dificuldade. Podendo definir quantidade de caracteres especiais, números, tamanho da senha, tempo que ela vai expirar, não repetir a mesma senha digitada anteriormente, etc. Como não podemos confiar totalmente nas instruções passadas para os usuários, devemos forçar essas opções. Usaremos o pam para realizar esses ajustes. O PAM surgiu como um intermediador entre as aplicações e o mecanismo de autenticação. Todas as aplicações agora têm suporte ao PAM, que tem uma interface de comunicação única. Então quando quisermos fazer qualquer modificação de onde autenticar, basta apenas modificar a configuração do PAM e todo o resto das aplicações já estará configurada automaticamente. Muito mais prático. Na família Debian, o arquivo a ser ajustado será o /etc/pam.d/common-password. Em outros sistemas procure verificar se o arquivo será o mesmo. Como requisito precisaremos instalar o pacote libpam-cracklib. apt-get install libpam-cracklib Faça um backup do arquivo para garantir: cp /etc/pam.d/common-password /root/ E agora vamos editá-lo, deixando com apenas a linha abaixo: vi /etc/pam.d/common-password password requisite pam_cracklib.so minlen=8 difok=3 ucredit=-1 ocredit=-1 retry=3 Onde: retry = 3 : tentativas antes de retornar com erro. O padrão é 1. minlen = 8 : O tamanho mínimo aceitável para a nova senha. difok = 3 : Essa opção não deixa ter 3 letras iguais a senha antiga. Por exemplo a senha antigo é pastel e tentar alterar para pastoso irá ser rejeitada ucredit = -1 : A nova senha deve conter pelo menos 1 caracteres maiúsculos. ocredit = -2 : A nova senha deve conter pelo menos 2 caracteres especiais. Diferença entre opções positivas e negativas Como podemos ver na opção ucredit usamos um valor negativo isso porque os números negativos significam que queremos no mínimo o valor x, sendo uma exigência. Quando usamos o numero positivo estamos indicando o valor máximo. Outras opções dcredit=x: Informa a quantidade digitos, numeros, exigidos na senha lcredit=x: Representa a quantidade caracteres minusculos, acredito que seja pouco usada Proibir senhas já usadas No mesmo arquivos iremos acrescentar password sufficient pam_unix.so use_authtok md5 shadow remember=10 remember=10 : Senha não poderá ser igual as ultimas 10 Testando, lembrando que se tentar trocar senha como root, ele dará o aviso porém irá alterar a senha mesmo assim. Caso seja um usuário comum ele não irá aceita a troca da senha. passwd sidnei SENHA INCORRETA: é simples demais Fonte: http://blog.marcelocavalcante.net/blog/2011/09/27/politica-de-senhas-no-linux-senhas-com-data-para-expirar/ https://www.cyberciti.biz/faq/securing-passwords-libpam-cracklib-on-debian-ubuntu-linux/ ","date":"17/10/2017","objectID":"/alterar-politica-de-senhas-no-linux/:0:0","tags":["linux","segurança"],"title":"Alterar politica de senhas no Linux com PAM","uri":"/alterar-politica-de-senhas-no-linux/"},{"categories":null,"content":"Hoje vamos a uma dica rápida para quem esqueceu ou não sabe a senha de Admin do painel de administração do Zabbix. Eu estava testando a ferramenta e depois de um tempo se mexer havia esquecido a senha, tive que resetá-la. Para isso a única coisa que precisamos é ter a senha de root do mysql, tendo ela podemos logar no terminal: mysql -u root -p Enter password: Dentro do terminal a gente vai fazer o seguinte: mysql\u003e use zabbix; mysql\u003e UPDATE users SET passwd=md5(‘novasenha’) WHERE alias=’Admin’; Pronto, senha resetada. Fonte: ","date":"17/10/2017","objectID":"/resetar-senha-admin-zabbix/:0:0","tags":["zabbix"],"title":"Resetar senha Admin Zabbix","uri":"/resetar-senha-admin-zabbix/"},{"categories":null,"content":"Primeiramente o que devemos saber é que no Linux a extensão é opcional, o tipo de arquivo é reconhecido pelo seu conteúdo e não pela sua extensão. Mas para facilitar a vida é bom conhecer algumas extensões no Linux. Arquivos Executáveis out: formato binário usado nas primeiras versões do GNU/Linux pl: script em linguagem Perl py: script em linguagem Python sh: script de shell, usado para criar pequenos programas Códigos fontes e bibliotecas c: código em linguagem C cpp: código em linguagem C++ diff: conjunto de instruções que definem as trocas a aplicar um patch h: cabeçalho de arquivos programados em C lo: arquivo temporário criado pela compilação de uma library o: arquivo temporário criado pela compilação de um programa so: bibliotecas compartilhadas equivalentes aos “dll” em windows Arquivos compactados bz2: arquivo comprimido pelo Bzip2 gz: arquivo gerado pelo programa Gzip que substituiu o obsoleto Compress rar: substituto natural do Arj, que permite uma maior compressão e dividir arquivos grandes em vários menores tar: arquivo empacotado sem compressão, usado para num único ficheiro o conteúdo de um pasta com vários arquivos tbz2 (tar.bz2): arquivo resultante da compressão em Bzip2 dum ficheiro Tar tgz (tar.gz): resultado da compressão em Gzip dum ficheiro Tar. z: arquivo comprimido com o programa Compress zip: formato de compressão mais usado na internet. Tem menos compressão que o Bzip2. Arquivos do Sistema conf: arquivo de configuração de um programa ko: módulos do núcleo do kernel 2.6 lock: indica o bloqueio de um serviço, processo ou programa log: arquivo de de informação gerado pelo núcleo do kernel, pelos programas e pelos serviços instalados. É nele que ficam guardados os estados e erros que se produzem pelos programas pid: arquivos indicadores de processos necessários para o correto funcionamento dos serviços em execução socket: meio de comunicação entre dois programas situados em equipamentos diferentes tmp: ficheiro temporário criado por um programa para armazenar informação Arquivos de pacotes deb: usado pela Debian e distribuições derivadas da Debian dsc: arquivo de informação do código fonte de um pacote Debian ebuild: script usado pela Gentoo para compilar e instalar pacotes a partir do código fonte rpm: arquivo usado pela Red Hat, Fedora, CentOS, SUSE, Mandriva e outros tgz: arquivo Tar.gz já compilados para Slackware ","date":"19/09/2017","objectID":"/extensoes-de-arquivos-no-linux/:0:0","tags":["linux"],"title":"Extensões de arquivos no Linux","uri":"/extensoes-de-arquivos-no-linux/"},{"categories":null,"content":"Hoje falaremos sobre um assunto que a cada dia se torna mais importante no mundo técnologico e corporativo, Segurança da Informação. Segundo a ISO 27002 segurança da informação é: A proteção da informação contra vários tipos de ameaças para garantir a continuidade do negocio, minimizar riscos, maximizar o retorno sobre os investimentos e as oportunidades de negócios. Com a evolução da internet a empresas ampliaram seus aspectos de negócio, chegando praticamente em todos os setores e segmentos. A informatização das empresas se tornou algo necessário, migrando as informações para o formato digital. E essas informações deve ser protegidas devido ao riscos as quais elas podem estar expostas. O que se deve proteger: – Registro de negócios; – Base de dados; – Informações pessoais; – Registros financeiros; – Informações de mercado. Para a segurança da informação é importante lembrar que a proteção é indiferente de onde a informação esteja, papel, computador, trafegando na rede, backup. O que um ataque a essas informações pode acarretar: – Negativar a imagem da empresa; – Perda de clientes; – Vazamento de informações; – Prejuizo financeiro A segurança da informação baseia-se em 3 pilares: – Confidencialidade: Garantir que a informação esteja disponivel somente as pessoas autorizadas – Integridade: Garantir que a informação esteja integra, ou seja, completa e no seu estado original – Disponibilidade: Garantir que a informação esteja disponivel e utilizavel E pode envolver processos, tecnologia e pessoas (o elo mais fraco). Vulnerabilidade É uma possível falha em um procedimento ou controle de um sistema que possa ser explorada, resultando em uma brecha de segurança Vulnerabilidade tecnologias: – Protocolos – Sistema operacional – Equipamento rede Vulnerabilidade de configuração: – Manter configurações default ou inseguras – Senhas simples – Configuração incorreta de equipamento ou serviços Vulnerabilidade de Politica de segurança: – Falta de uma politica – Falta de controle de acessos – Instalações de software ou hardware que nao seguem a politica – Falta de orientação sobre a policita, quando existir Ameaça Quem ou que, pode explorar acidentalmente ou propositalmente alguma dessas vulnerabilidades Ameaças acidentais – Falha de equipamentos – Erro humano – Natureza Ameaças propositais – Espionagem – Crimes – Empregados desonestos ou insatisfeitos – Vandalismo – Terrorismo Risco É a probabilidade de uma ameaça explorar um vulnerabilidade, resultando algum impacto ou prejuizo para organização Engenharia social É a prática utilizada para obter informações importantes por meio das pessoas envolvidades. O atacante consegue retirar informações ou acessos sem mesmo chegar perto de um computador, somente se valendo da má instrução das pessoas. Tipos de ataques mais comuns realizados pela internet: Explorar vulnerabilidades Scan de rede Falsificação de emails Sniffing Força bruta Negação de serviço (DDos) Para diminuir os riscos pode-se usar alguns recursos, como: – Politica de segurança – Notificação de incidentes – Contas e senhas – Criptografia – Backup – Logs – Ferramentas de antivirus – Firewall Pode-se também adotar uma política de segurança da informação, que vem a ser de muita valia para as organizações, mas isso já cabe outro post mais pra frente. ","date":"05/09/2017","objectID":"/seguranca-da-informacao-o-que-preciso-saber/:0:0","tags":["segurança"],"title":"Segurança da Informação - O que preciso saber?","uri":"/seguranca-da-informacao-o-que-preciso-saber/"},{"categories":null,"content":"Bom essa dica é bem simples mas muito útil, vamos usar uma combinação de comandos para listar as 5 pastas que mais utilizam espaço no diretório corrente. O bom comando seria esse: du -Sh | sort -rh | head -5 Saida: 2,1G ./log/journal/457f9ec73a36473ab3a70f2a1ebce863 196M ./lib/mysql 189M ./lib/docker/aufs/diff/105ad3b8329fb9264b17543f7d70746b1c330f18523f27cdee5ad3fdff966697/usr/bin 116M ./lib/nvidia 111M ./lib/docker/aufs/diff/105ad3b8329fb9264b17543f7d70746b1c330f18523f27cdee5ad3fdff966697/usr/share/cattle/0e44936b6b56ae4372799b0f48e6e934/WEB-INF/lib Explicando: O comando du faz a verificação do uso das pastas em si; O comando sort faz a ordenação do maior pro menor; E o comando head mostra os 5 primeiros, pode ser usado qualquer quantidade. Se alguém tiver dúvidas quanto as opções usadas, basta digitar o nome do comando –help, que terá todas as informações. ","date":"17/08/2017","objectID":"/dica-rapida-verificar-pastas-que-ocupam-mais-espaco/:0:0","tags":["linux","shell script"],"title":"Dica rápida - Verificar pastas que ocupam mais espaço","uri":"/dica-rapida-verificar-pastas-que-ocupam-mais-espaco/"},{"categories":null,"content":"Para gerar uma lista dos pacotes instalados no sistema, poderemos usar o dpkg para isso. Pode ser muito útil na hora de criar sistemas com a mesma base Gerando lista de pacotes sudo dpkg --get-selections \u003e install.list Instalando pacotes a partir da lista sudo dpkg --set-selections \u003c install.list sudo apt-get -y update sudo apt-get dselect-upgrade Fonte ","date":"22/06/2017","objectID":"/gerar-lista-de-pacotes-instalados-no-debian-ubuntu-etc/:0:0","tags":["dpkg","linux"],"title":"Gerar lista de pacotes instalados no Debian, Ubuntu, etc","uri":"/gerar-lista-de-pacotes-instalados-no-debian-ubuntu-etc/"},{"categories":null,"content":"Limitando e atualizando limites de memória e CPU no docker","date":"13/06/2017","objectID":"/limitando-e-atualizando-limites-de-memoria-e-cpu-no-docker/","tags":["docker"],"title":"Limitando e atualizando limites de memória e CPU no docker","uri":"/limitando-e-atualizando-limites-de-memoria-e-cpu-no-docker/"},{"categories":null,"content":"Bom hoje vamos seguir com nosso aprendizado em docker, já vimos sobre comandos básicos, iniciar servidor apache, exportar e importar containers e agora a dica é bem simples porém muito útil. Toda vez que subimos um container sem colocar limites nos recursos, o container pode usar todo o recurso da máquina fisica, isso nem sempre é bom, seja por onerar o host ou mesmo para testes da sua aplicação. Então vamos as dicas. Antes da dica, vamos a outra dica :), com o comando docker stats podemos ver o consumo de nossos containers: Agora vamos as nossas dicas de hoje. Limitar memória do container # Para limitar a 512 MEGAS docker run -it -m 512M ubuntu /bin/bash #Para limitar a 1 GIGA docker run -it -m 1G ubuntu /bin/bash # Verificando a quantidade de memória docker inspect [container id] |grep -i mem Limitar CPU do container docker run -it --cpu-shares 1024 ubuntu /bin/bash docker inspect [container id] |grep -i cpu ","date":"13/06/2017","objectID":"/limitando-e-atualizando-limites-de-memoria-e-cpu-no-docker/:0:0","tags":["docker"],"title":"Limitando e atualizando limites de memória e CPU no docker","uri":"/limitando-e-atualizando-limites-de-memoria-e-cpu-no-docker/"},{"categories":null,"content":"Atualizar limites de container em execução Alterando limite de memória docker update -m 256M [container id] Atualizar limite CPU docker update --cpu-shares 512 [container id] Sempre lembrando que para pegar o id do container basta executar docker ps. ","date":"13/06/2017","objectID":"/limitando-e-atualizando-limites-de-memoria-e-cpu-no-docker/:0:1","tags":["docker"],"title":"Limitando e atualizando limites de memória e CPU no docker","uri":"/limitando-e-atualizando-limites-de-memoria-e-cpu-no-docker/"},{"categories":null,"content":"De uma maneira muito rápida podemos iniciar um servidor web para testarmos aplicações, páginas, sistemas, etc. Para isso precisaremos de duas ferramentas: Docker Docker Compose Vou levar em consideração de já tenha os mesmos instalados, pois cada sistema tem seu próprio gerenciador de pacotes e não vou especificar isso no momento. ","date":"31/05/2017","objectID":"/iniciando-servidor-web-php-e-mysql-com-docker/:0:0","tags":null,"title":"Iniciando servidor web PHP e Mysql com Docker","uri":"/iniciando-servidor-web-php-e-mysql-com-docker/"},{"categories":null,"content":"Iniciando DockerFile Para iniciar criaremos um Dockerfile, para quem não está muito familiarizado pode ver um post com comandos básico do docker aqui. Usaremos uma imagem base do Docker Hub, a tutum/lamp. FROM tutum/lamp MAINTAINER PAAS EMAIL \u003cemail@site.com\u003e Docker Compose Agora na mesma pasta iremos criar o arquivo docker-compose.yml. Com o conteúdo abaixo: Ps: Lembre de verificar se os caminhos dos arquivos estão corretos em seu sistema, pode variar de linux para linux. dev: dockerfile: Dockerfile volumes: - .:/var/www/html - /etc/timezone:/etc/timezone - /etc/localtime:/etc/localtime build: . expose: - \"80\" ports: - \"80:80\" Subindo a aplicação Subiremos a aplicação com o seguinte comando: docker-compose up Basta acessar seu localhost, ou ip de sua máquina que o servidor estará UP. A pasta onde foi criado os arquivos anteriores será a pasta raíz do servidor web. Ao iniciar será gerado uma saída parecido com a abaixo: Fonte ","date":"31/05/2017","objectID":"/iniciando-servidor-web-php-e-mysql-com-docker/:0:1","tags":null,"title":"Iniciando servidor web PHP e Mysql com Docker","uri":"/iniciando-servidor-web-php-e-mysql-com-docker/"},{"categories":null,"content":"Monitoramento via TCP no Nagios","date":"28/04/2017","objectID":"/monitoramento-via-tcp-no-nagios/","tags":["nagios"],"title":"Monitoramento via TCP no Nagios","uri":"/monitoramento-via-tcp-no-nagios/"},{"categories":null,"content":"Hoje vamos dar seguinte a configuração do Nagios que instalamos um tempo atrás. Iniciaremos por um dos monitramentos mais simples que é o monitoramento via TCP, caso tennha alguns sites e queira monitorar caso algum deles caia, será muito útil. Bom a estrutura do Nagios é bem simples mas não mostrarei hoje, para melhorar nos organizarmos vamos criar um arquivo de template próprio, dentro da pasta /usr/local/nagios/etc. Aqui no meu caso crei o arquivo templatesNagios.cfg. Já com o template do servico de monitoramento e templates para monitorar linux, windows e hosts de rede. ### Template do serviço de monitoramento de Rede e ICMP define service{ name TemplateService active_checks_enabled 1 notifications_enabled 1 passive_checks_enabled 0 retain_status_information 1 is_volatile 0 max_check_attempts 3 check_interval 3 normal_check_interval 5 retry_check_interval 5 check_period 24x7 notification_interval 0 notification_period 24x7 notification_options u,c,r register 0 } #### Template \"HOST\" Windows define host{ name TemplateHostWindows max_check_attempts 3 check_interval 5 retry_check_interval 5 active_checks_enabled 1 passive_checks_enabled 0 check_period 24x7 retain_status_information 1 notification_interval 60 ; tempo de envio de alerta notification_period 24x7 notification_options d,u,r register 0 } ### Template \"HOST\" Linux define host{ name TemplateHostLinux check_command check-host-alive max_check_attempts 3 check_interval 3 retry_check_interval 5 active_checks_enabled 1 check_period 24x7 retain_status_information 1 notification_interval 60 notification_period 24x7 notification_options d,u,r } ### Template \"HOST\" Rede define host{ name TemplateHostRede check_command check-host-alive max_check_attempts 2 check_interval 5 retry_check_interval 5 active_checks_enabled 1 check_period 24x7 retain_status_information 1 notification_interval 60 notification_period 24x7 notification_options d,u,r } # 'check_tcp' command definition define command{ command_name check_tcpNP command_line $USER1$/check_tcp -H $HOSTADDRESS$ -p $ARG1$ -w $ARG2$ -c $ARG3$ } Feito isso precisamos adicionar nosso arquivo de configuração no arquivo /usr/local/nagios/etc/nagios.cfg cfg_file=/usr/local/nagios/etc/templatesNagios.cfg Agora dentro da pasta /usr/local/nagios/etc/ criaremos a pasta network, onde adicionaremos todos os nossos hosts para monitoramento via TCP. Criaremos em outro momento uma pasta linux e uma windows, ficando muito mais organizada nossas configurações. Também precisamos adicionar esse caminho no arquivo /usr/local/nagios/etc/nagios.cfg cfg_dir=/usr/local/nagios/etc/network/ Dentro da pasta network vamos criar nosso primeiro host para monitorar. Vou criar o arquivo sidneiweber.cfg com o conteúdo abaixo. As opções são auto explicativas, mas comentei para facilitar o entendimento. define host{ host_name Site_Sidnei ; Nome que irá aparecer no nagios use TemplateHostRede ; Template a ser usado. Configura no nosso templatesNagios.cfg alias Site Sidnei Weber ; Um alias address www.sidneiweber.com.br ; O endereço contact_groups admins ; Grupo que receberá os alertas } define service{ use TemplateService ; Template do serviço host_name Site_Sidnei ; Nome do seu servidor service_description PING-Disponibilidade ; Descrição do Serviço a ser monitorado para o host check_command check_ping!100,20%!200,60% ; Plugin e Parametros contact_groups admins } define service{ use TemplateService host_name Site_Sidnei ; Nome do seu servidor service_description HTTP ; Descrição do Serviço a ser monitorado para o host check_command check_tcpNP!80!1!2! ; Plugin e Parametros contact_groups admins } Após essa configuração basta verificar se está tudo configurado sem erros com o comando: /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg Se não retornar nenhum erro, basta iniciar o serviço do nagios: /usr/local/nagios/bin/nagios -d /usr/local/nagios/etc/nagios.cfg Caso o serviço já esteja rodando e precise reiniciar, eu faço da seguinte maneira: # Mata","date":"28/04/2017","objectID":"/monitoramento-via-tcp-no-nagios/:0:0","tags":["nagios"],"title":"Monitoramento via TCP no Nagios","uri":"/monitoramento-via-tcp-no-nagios/"},{"categories":null,"content":"Script instalação automatizada Nagios no Debian","date":"26/04/2017","objectID":"/script-instalacao-automatizada-nagios-no-debian/","tags":["nagios"],"title":"Script instalação automatizada Nagios no Debian","uri":"/script-instalacao-automatizada-nagios-no-debian/"},{"categories":null,"content":"Script para instalação do Nagios e Nagios plugins no Debian baixando o código fonte. Script está funcional, porém pode vir a melhorar. Retirado de https://github.com/sidneiweber/meu-canivete-suico/blob/master/nagios/instalar-nagios-debian.sh #!/bin/bash # instalar-nagios-debian.sh # Criado por Sidnei Weber # Variaveis VERSAO_NAGIOS=4.2.4 VERSAO_PLUGINS=2.1.4 USUARIO=`whoami` # Verificar se é root if [ \"$USUARIO\" == \"root\" ] then echo \"O poder está em suas mãos!\" else echo \"Você precisa ter poderes de Super Vaca!\" exit 0 fi # Verificar internet clear echo \"Verificando conexão com internet\" curl www.google.com \u0026\u0026gt; /dev/null if [ \"$?\" != \"0\" ]; then echo \"Sem conexao. Saindo do instalador\" exit 0 else echo \"Conexao ok. Continuando!\" fi # Instalação das dependencias echo \"Instalando dependencias\" apt-get install wget build-essential apache2 php-gd libgdchart-gd2-xpm libgdchart-gd2-xpm-dev libapache2-mod-php # Baixando Nagios # Nagios core echo \"Baixando pacotes do Nagios\" wget -c https://assets.nagios.com/downloads/nagioscore/releases/nagios-$VERSAO_NAGIOS.tar.gz # Nagios plugins wget -c https://nagios-plugins.org/download/nagios-plugins-$VERSAO_PLUGINS.tar.gz # Extrair pacotes tar -xzvf https://assets.nagios.com/downloads/nagioscore/releases/nagios-$VERSAO_NAGIOS.tar.gz # Nagios plugins tar -xzvf https://nagios-plugins.org/download/nagios-plugins-$VERSAO_PLUGINS.tar.gz # Adicionar usuario e grupo useradd nagios groupadd nagios usermod -a -G nagios nagios usermod -a -G nagios www-data # Compilar Nagios cd nagios-$VERSAO_NAGIOS ./configure --with-command-group=nagios make all make install make install-init make install-config make install-commandmode make install-webconf # Reiniciar apache echo \"Reiniciando Apache\" service apache2 restart # Criar usuario e senha para acessar NAGIOS echo \"Escolha uma senha para o usuário nagiosadmin.\" htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin # Compilar plugins cd .. cd nagios-plugins-$VERSAO_PLUGINS ./configure --with-nagios-user=nagios --with-nagios-group=nagios make make install # Habilitar CGI no apache cp -r /etc/apache2/mods-available/cgi.load /etc/apache2/mods-enable/ service apache2 reload # Verificar configuracao /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg # Iniciar instancia /usr/local/nagios/bin/nagios -d /usr/local/nagios/etc/nagios.cfg ","date":"26/04/2017","objectID":"/script-instalacao-automatizada-nagios-no-debian/:0:0","tags":["nagios"],"title":"Script instalação automatizada Nagios no Debian","uri":"/script-instalacao-automatizada-nagios-no-debian/"},{"categories":null,"content":"Hoje vou falar um pouco sobre essa distribuição que conheci e acabei me envolvendo no projeto: Emmi Linux. Bom segue palavras do próprio autor do projeto, Jefferson Rocha: Assim como Debian todas versões serão LTS, com suporte ativo por 5 anos. Leve, um computador de 1 GB de ram vai rodar muito bem a Emmi, então aquele computador de 2007 vai ser ressucitado e vai ter um novo folego! O tamanho da iso é muito importante para nós, com apenas 700 mb, o que para as distros de hoje é dificil achar uma iso com este tamanho. Ambiente totalmente moderno e leve com XFCE. Não vamos de maneira alguma empurrar pacotes pré instalados, a distribuição vem com a base e alguns utilitarios, o resto o usuário pode moldar como querer do seu jeito, esse é o foco da distro, ou seja sabe aquela porrada de programas muitas vezes que não usamos nem uma parte que vem junto com algumas distribuições? na Emmi não vem. Boot e poweroff, incrivelmente rápido. Assim como Debian não incentivamos os usuários a instalar pacotes fora do repositorio, ppa? muito menos. Pacotes que não tem no Debian nos vamos testar, empacotar e disponibilizar em nosso repositorio. (não temos ainda um repositorio proprio, mas está nos planos já.) Agora falando em facilidade para usuários novos e leigos, a distribuição tem tudo para ser até mais fácil que o Linux mint, o plano é esse. Bom de resto é testando para você ver. Basicamente é isso, nossa proposta é diferente, com tempo tudo se acerta. Realmente o sistema está muito bonito e fluído, vale a pena testar. Em breve postarei um review sobre a distro com mais detalhes. Link para site: Emmi Linux ","date":"24/03/2017","objectID":"/emmi-linux-uma-distribuicao-pequena-e-leve/:0:0","tags":["emmi linux"],"title":"Emmi Linux - Uma distribuição pequena e leve","uri":"/emmi-linux-uma-distribuicao-pequena-e-leve/"},{"categories":null,"content":"Hoje vamos falar do Knock, uma ferramenta muito interessante para quem precisar acessar seus servidores remotamente. Bom o que o Knock faz, ele adiciona essa camada a mais da seguinte forma, por exemplo se acessamos nosso servidor pela porta 22 do ssh ela deveria estar liberada. Porém com Knock ela pode estar bloqueada, você acertando uma sequência específica de portas ele irá liberar a porta 22, e somente se acertar a sequencia definida. ","date":"21/03/2017","objectID":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/:0:0","tags":["ssh","segurança"],"title":"Knock SSH - Adicionando uma camada extra de segurança no servidor","uri":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/"},{"categories":null,"content":"No servidor Precisamos instalar somente um pacote em nosso servidor: apt-get install knockd O arquivo de configuração fica no /etc/knockd.conf. Eis a configuração padrão que veio no Debian. Eu alterei para a configuração ficar como no exemplo abaixo, sempre colocando a regra de ACCEPT na primeira linha, pois caso tenha sido bloqueada e seja adiciona no final do arquivo a regra não funcionará. [options] UseSyslog [openSSH] sequence = 7000,8000,9000 seq_timeout = 5 command = /sbin/iptables -I INPUT 1 -s %IP% -p tcp --dport 22 -j ACCEPT tcpflags = syn [closeSSH] sequence = 9000,8000,7000 seq_timeout = 5 command = /sbin/iptables -D INPUT -s %IP% -p tcp --dport 22 -j ACCEPT tcpflags = syn Após editaremos o arquivo /etc/default/knockd para especificar nossa placa de rede: START_KNOCKD=1 KNOCKD_OPTS=\"-i enp0s3\" Feito a configuração reiniciaremos o serviço: /etc/init.d/knockd restart Caso não tenha a porta 22 fechada, vamos fecha-lá. Lembrando que isso deve estar no script firewall do seu servidor. iptables -A INPUT -p tcp --dport 22 -j DROP ","date":"21/03/2017","objectID":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/:0:1","tags":["ssh","segurança"],"title":"Knock SSH - Adicionando uma camada extra de segurança no servidor","uri":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/"},{"categories":null,"content":"No cliente No cliente instalaremos o mesmo utilitário, porém sem precisar fazer as configurações feitas anteriormente. aptitude install knockd Agora vamos bater nas portas em sequência conforme configurado no nosso servidor (7000, 8000, 9000) knock 10.0.0.106 7000:tcp 8000:tcp 9000:tcp Com as batidas corretamente executadas, podemos verificar o log do nosso servidor e veremos que o foi passado por 3 estágios e após os mesmos estarem corretos, nosso porta 22 foi liberada pelo firewall Mar 21 15:49:21 server knockd: starting up, listening on enp0s3 Mar 21 15:49:26 server knockd: 10.0.0.103: openSSH: Stage 1 Mar 21 15:49:26 server knockd: 10.0.0.103: openSSH: Stage 2 Mar 21 15:49:26 server knockd: 10.0.0.103: openSSH: Stage 3 Mar 21 15:49:26 server knockd: 10.0.0.103: openSSH: OPEN SESAME Mar 21 15:49:26 server knockd: openSSH: running command: /sbin/iptables -I INPUT 1 -s 10.0.0.103 -p tcp --dport 22 -j ACCEPT E assim podemos conectar normalmente sem bloqueio nenhum. ssh sidnei@10.0.0.106 sidnei@10.0.0.106's password: ","date":"21/03/2017","objectID":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/:0:2","tags":["ssh","segurança"],"title":"Knock SSH - Adicionando uma camada extra de segurança no servidor","uri":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/"},{"categories":null,"content":"Fechando a porta Depois de fazer tudo que era necessário podemos fechar a porta novamente, acertando a sequência de fechamento que também é incluida no nosso arquivo de configuração do servidor. knock 10.0.0.106 9000:tcp 8000:tcp 7000:tcp E a porta será fechada novamente conforme o log nos informa: Mar 21 15:58:27 server knockd: 10.0.0.103: closeSSH: Stage 1 Mar 21 15:58:27 server knockd: 10.0.0.103: closeSSH: Stage 2 Mar 21 15:58:27 server knockd: 10.0.0.103: closeSSH: Stage 3 Mar 21 15:58:27 server knockd: 10.0.0.103: closeSSH: OPEN SESAME Mar 21 15:58:27 server knockd: closeSSH: running command: /sbin/iptables -D INPUT -s 10.0.0.103 -p tcp --dport 22 -j ACCEPT E era isso, acredito que seja uma camada bem interessante para nossos servidores e o mais importante, não colocando portas padrões na configuração, será muito mais dificil acertar a sequência para poder liberar o ssh. Fonte Um forte abraço ","date":"21/03/2017","objectID":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/:0:3","tags":["ssh","segurança"],"title":"Knock SSH - Adicionando uma camada extra de segurança no servidor","uri":"/knock-ssh-adicionando-uma-camada-extra-de-seguranca-no-servidor/"},{"categories":null,"content":"Definição: Resumidamente, o DHCP opera da seguinte forma: Um cliente envia um pacote UDP em broadcast (destinado a todas as máquinas) com uma requisição DHCP (para a porta 67); Os servidores DHCP que capturarem este pacote irão responder (se o cliente se enquadrar numa série de critérios — ver abaixo) para a porta 68 do Host solicitante com um pacote com configurações onde constará, pelo menos, um endereço IP, uma máscara de rede e outros dados opcionais, como o gateway, servidores de DNS, etc… Fonte: Wikipedia Esse seria o desenho dos envios de pacotes de um cliente para um servidor DHCP. ","date":"06/03/2017","objectID":"/instalando-servidor-dhcp/:0:1","tags":["linux","rede","dhcp"],"title":"Instalando servidor DHCP","uri":"/instalando-servidor-dhcp/"},{"categories":null,"content":"Instalação: Iremos fazer a instalação do nosso servidor no Debian. Para tal operação iremos instalar o pacote isc-dhcp-server, que substituiu o pacote dhcp-server3. apt-get install isc-dhcp-server ","date":"06/03/2017","objectID":"/instalando-servidor-dhcp/:0:2","tags":["linux","rede","dhcp"],"title":"Instalando servidor DHCP","uri":"/instalando-servidor-dhcp/"},{"categories":null,"content":"Configurando: Primeiramente editaremos o arquivo: /etc/default/isc-dhcp-server e colocaremos a placa de rede interna na configuração: # On what interfaces should the DHCP server (dhcpd) serve DHCP requests? # Separate multiple interfaces with spaces, e.g. \"eth0 eth1\". INTERFACESv4=\"enp0s8\" A configuração básica para o funcionamento é tão simples quanto a instalação. Editaremos o arquivo /etc/dhcp/dhcpd.conf. Acrescentaremos as opções básicas para o funcionamento. subnet 10.0.0.0 netmask 255.255.255.0 { range 10.0.0.100 10.0.0.120; option routers 10.0.0.1; option domain-name-servers 8.8.8.8; option broadcast-address 10.0.0.255; } Explicando: Subnet: Iniciaremos uma sub-rede para ceder IP’s. Range: A faixa de IP’s que será distribuida. Option Routers: Configura a rota padrão. Option domain-name-servers: Configura os servidores DNS.Option broadcast-address: Indica o fim da sub-rede. Alguns outros parâmetros básicos que já vem no arquivo por padrão: Option domain-name: domínio. Default-lease-time: Tempo que o servidor verifica se o IP ainda está em uso. Max-lease-time: Tempo máximo de um IP. Agora é só salvar o arquivo que editamos e reiniciar o serviço: /etc/init.d/isc-dhcp-server restart Pronto teremos um servidor DHCP dando IP para a nossa rede. Ainda temos algumas opções criar duas redes distintas dentro do mesmo servidor, atrelar IP’s ao Mac Address, negar máquinas que não estejam cadastradas no servidor DHCP, enfim, inúmeros recursos que estudaremos mais adiante. Obrigado e até a próxima. ","date":"06/03/2017","objectID":"/instalando-servidor-dhcp/:0:3","tags":["linux","rede","dhcp"],"title":"Instalando servidor DHCP","uri":"/instalando-servidor-dhcp/"},{"categories":null,"content":"Conceito de Firewall: O firewall é usado basicamente como um meio de proteção. Dividindo a rede que se pretende deixar segura da rede não segura. Geralmente um firewall é instalado na borta da rede, sendo a entrada e saida dos pacotes da mesma, fazendo a leitura de cada pacote e fazendo o controle do que pode passar para rede interna, ou dando o redirecinamento correto, servindo de filtro. O iptables é a ferramenta de firewall a nivel de pacotes do linux desde o kernel 2.4 substituindo o ipchains. Ele se baseia nas regras e parametros passados para fazer a filtragem dos pacotes, ou seja, compara as regras com os pacotes. Para termos uma segurança maior, incluindo um controle de navegação na rede interna, uma dupla muito usada e que combina muito bem, é a dupla Iptables + Squid. Squid é um proxy de navegação, mas essa solução falaremos em outra oportunidade ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:1","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Tabelas: Tabelas são os locais usados para armazenar as chains e conjunto de regras com uma determinada característica em comum. As tabelas podem ser referenciadas com a opção -t tabela e existem basicamente 4 tabelas disponíveis no iptables: Tabela FILTER: possui cadeias INPUT, OUTPUT, FORWARD Tabela NAT: possui cadeias PREROUTING, OUTPUT, POSTROUTING Tabela MANGLE: cadeias PREROUTING, OUTPUT, POSTROUTING, INPUT, FORWARD Tabela RAW: cadeias PREROUTING, OUTPUT ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:2","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"O que são chains? As Chains são locais onde as regras do firewall definidas pelo usuário são armazenadas para operação do firewall. INPUT: aplica regra aos pacotes que chegam ao servidor OUTPUT: aplica regras aos pacotes de rede originados e que partem do servidor FORWARD: aplica regras aos pacotes de rede roteados atraves do servidor (para outro servidor ou outra interface do mesmo servidor) PREROUTING: altera pacotes de rede na hora que chegam e antes do roteamento POSTROUTING: altera pacotes de rede após o roteamento. Usado para SNAT ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:3","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Politicas, ações (targets): ACCEPT: pacote permitido DROP: descartar pacote QUEUE: enviar o pacote ao userspace (codigo fora do kernel) RETURN: descontinuar o processamento do pacote e aplicar a regra padrao a ele REJECT: Descarta o pacote e envia feedback ao remetente DNAT: Reescreve endereço de destino (NAT) SNAT: Reescreve endereço de origem (NAT) LOG: coloca no log informações sobre o pacte ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:4","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Estrutura do comando: Comando principal: iptables subcomando chain parametro1 valor1 parametron valorn ação Subcomandos: -A cadeia – anexa a regra ao final da cadeia -L [cadeia] lista as regras da cadeia, ou todas caso a cadeia nao seja especificada -F [cadeia] apaga todas as regras na cadeia -N cadeia – Lista todas as regras na cadeia -P cadeia politica – configura a regra padrão da cadeia -D cadeia linha – apaga uma regra em um posição na cadeia -X [cadeia] excluiu uma cadeia vazia -I cadeia linha – insere uma regra em uma posição na cadeia -Z zera os contadores para todas as cadeias Parametros, alguns: -t tabela (filter é a padrao) -j ação -p protocolo (especifica o protocolo, icmp, tcp, udp, all) -s IP (IP de origem do pacote) -d IP (IP de destino do pacte) -i interface (nome da interface de rede de entrada do pacote) -o interface (nome da interface de rede de saida do pacote) –sport portas (Portas de origem) –dport portas (Portas de destino) –syn (identifica nova requisição de conexao) –icmp-type (tipo de mensagem icmp) ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:5","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Checagem de estado dos pacotes (state match): -m state –state OPCAO NEW cria uma nova conexao ESTABLISHED pacote que pertence a uma conexao existente RELATED pacote relacionado mas que nao faz parte de uma conexao existente INVALID pacote nao pode ser identificado (ex. falta memoria, erro ICMP de conexao nao conhecida) ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:6","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Extensões: Extensao TCP –tcp-flags (ALL, SYN, ACK, FIN, etc) –source-port ou –sport –destination-port ou –dport Extensao UDP Mesmas opções do TCP Extensao ICMP –icmp-type Outras extensoes -m limit quando usado em LOG serve para limitar o numero de pacotes escritos durante um certo ponto –limit valor ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:7","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Arquivos de logs criados pelo iptables: Todo tráfego que for registrado pelo iptables é registrado por padrão no arquivo /var/log/kern.log. ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:8","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Exemplos: Exibir todas as regras: iptables -L -n -v Verificar regras (padrão filter –line-numbers (Exibe linhas)) iptables -L iptables -S (lista comandos do iptables) Verificar regras tabela nat iptables -t nat -L Criando uma regra, DROP em tudo que vai pra porta 123 iptabels -A INPUT -p tcp --dport 123 -j DROP Inserindo uma regra, -I por padrao insere a regra no final # indicando a linha ja a regra para a posição referente iptables -I INPUT 1 -p tcp --sport 321 --dport 123 -J ACCEPT Substituindo uma regra, parametro -R # Substitui a regra 1 (no caso do nosso exemplo) iptables -R INPUT 1 -p tcp --sport 321 --dport 123 -J ACCEPT Deletar regra, parametro -D # remove linha 1 iptables -D INPUT 1 # apagar usando sintaxe, usar mesmo sintaxe com parametro -D iptables -D INPUT -p tcp --dport 80 -j ACCEPT Bloquear porta específica Sainte: iptables -A OUTPUT -p tcp --dport xxx -j DROP Entrante: iptables -A INPUT -p tcp --dport xxx -j ACCEPT Ou múltiplas portas: iptables -A INPUT -p tcp -m multiport --dports 22,80,443 -j ACCEPT iptables -A OUTPUT -p tcp -m multiport --sports 22,80,443 -j ACCEPT Manter registros de Log’s de pacotes bloqueados: iptables -A INPUT -i eth0 -j LOG --log-prefix \"Quantidade pacotes bloqueados:\" iptables -A INPUT -p tcp -dport 21 -j LOG -log-prefix “Serviço: ftp” Os log’s são salvos em /var/log/messages. Compartilhar internet, parametro ip_forward precisa ser 1, geralemte altera-se no arquivo “/proc/sys/net/ipv4/ip_forward”. Lembrando que a mudança não é permanente, a cada reinicialização deve-se alterar o parâmetro novamente ou quando criar um sript de firewall incluir o comando para alterar o arquivo com o cat. iptables -A INPUT -m state --state RELATED.ESTABLISHED -j ACCEPT iptables -A FORWARD -m state --state RELATED.ESTABLISHED -j ACCEPT Ip Masquarade iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE Encaminhamento de portas (Ip forwarding) Tentando acessar pela interface wan iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 80 -j DNAT --to 192.168.10.10:80 iptables -A FORWARD -p tcp -d 192.168.10.10 --dport 80 -j ACCPET Reject Descarta pacote e envia um retorno a quem enviou o pacote. iptables -A INPUT -s 192.168.10.2 -j REJECT --reject-with icmp-net-unreachable iptables -A INPUT -s 192.168.10.2 -j REJECT --reject-with icmp-host-unreachable iptables -A INPUT -s 192.168.10.2 -j REJECT --reject-with icmp-proto-unreachable entre outras opções do –reject-with Criar chain iptables -t filter -N [chain] Limpar regras iptables -t filter -F [CHAIN] remover Chain criada pelo usuario, parametro -X zerar contador, parametro -Z Alterar regra padrão, o ideal INPUT ser drop por padrão iptables -P INPUT DROP Liberar servidor web iptables -A INPUT -m state --state new -p tcp --dport 80 -j ACCEPT iptables -A INPUT -m state --state new -p tcp --dport 443 -j ACCEPT Liberar host especifico iptabels -A INPUT -s 192.168.1.20 -j ACCEPT Liberar ping (resposta liberada se output esta ACCEPT tbm) iptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPT Liberar respostas de ping para outras maquinas iptables -A INPUT -p icmp --icmp-type echo-reply -j ACCEPT Proteção contra Syn-flood: iptables -A FORWARD -p tcp --syn -m limit --limit 1/s -j ACCEPT Port scanner suspeito: iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j ACCEPT Ping da morte: iptables -A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPT Salvando e restaurando as regras: iptables-save \u003e arquivo iptables-restore \u003c arquivo ","date":"15/02/2017","objectID":"/introducao-firewall-iptables-comecando/:0:9","tags":["iptables","segurança","linux"],"title":"Introdução Firewall Iptables - Começando","uri":"/introducao-firewall-iptables-comecando/"},{"categories":null,"content":"Após a instalação e inicialização do Nagios no nosso servidor Debian, temos que configurar um script de inicialização, para que cada vez que a gente precisa reiniciar o serviço ou a própria máquina não precisaremos subir tudo na mão. A primeira coisa é deletar o script já existente, lembrando que esse tutorial é válido para o Debian. rm -rf /etc/init.d/nagios Copiar um esqueleto do sistema: cp /etc/init.d/skeleton /etc/init.d/nagios Vamos editar o arquivo /etc/init.d/nagios e colocar o seguinte conteúdo. Lembrando de remover ou comentar as duas linhas existentes no final do arquivo. # DESC=\"Description of the service\" # DAEMON=/usr/sbin/daemonexecutablename DESC=\"Nagios\" NAME=nagios DAEMON=/usr/local/nagios/bin/$NAME DAEMON_ARGS=\"-d /usr/local/nagios/etc/nagios.cfg\" PROFILE=/usr/local/nagios/var/$NAME.lock Dar as permissões para execução: chmod 755 nagios E inicializar o serviço para subir junto com o sistema, quando o servidor for ligado: update-rc.d nagios defaults Agora temos todas as opções disponíveis: /etc/init.d/nagios Usage: /etc/init.d/nagios {start|stop|status|restart|try-restart|force-reload} Forte abraço e até a próxima. ","date":"08/02/2017","objectID":"/criar-script-inicializacao-nagios-no-debian/:0:0","tags":["nagios"],"title":"Criar script inicialização Nagios no Debian","uri":"/criar-script-inicializacao-nagios-no-debian/"},{"categories":null,"content":"Para podermos alterar o nome da máquina sem precisar reiniciar é muito simples. Primeiramente precisamos alterar o arquivo /etc/hostname. Mas após a alteração notamos que o nome não muda, mesmo dando o comando hostname, o nome continua o antigo. Para essa alteração valer sem precisar reiniciar, pois as vezes pode se tratar de um servidor que não pode parar no momento, basta digitar o comando abaixo: echo \"novo-hostname\" \u003e /proc/sys/kernel/hostname Pronto, problema resolvido. Fonte ","date":"03/02/2017","objectID":"/alterando-hostname-sem-reiniciar-computador/:0:0","tags":["linux"],"title":"Alterando hostname sem reiniciar computador","uri":"/alterando-hostname-sem-reiniciar-computador/"},{"categories":null,"content":"Vamos fazer a instalação básica do Nagios. Pra quem não conhece o Nagios, segue um link para conhecer melhor. Nagios é uma popular aplicação de monitoramento de rede de código aberto distribuída sob a licença GPL. Ele pode monitorar tanto hosts quanto serviços, alertando quando ocorrerem problemas e também quando os problemas são resolvidos. Faremos a instalação no Debian, que é uma distribuição de minha preferência. O Nagios pode ser instalado em qualquer sistema Linux, a única diferença que pode ocorrer é a instalação de dependências e/ou alguma localização de pastas ","date":"31/01/2017","objectID":"/instalando-nagios-instalacao-basica/:0:0","tags":["nagios"],"title":"Instalando Nagios - Instalação básica","uri":"/instalando-nagios-instalacao-basica/"},{"categories":null,"content":"Instalação das dependências sudo apt-get install wget build-essential apache2 php-gd libgdchart-gd2-xpm libgdchart-gd2-xpm-dev libapache2-mod-php ","date":"31/01/2017","objectID":"/instalando-nagios-instalacao-basica/:0:1","tags":["nagios"],"title":"Instalando Nagios - Instalação básica","uri":"/instalando-nagios-instalacao-basica/"},{"categories":null,"content":"Baixando Nagios Baixaremos a última versão dos pacotes Nagios Core e Nagios Core Plugins pelo site https://www.nagios.org/downloads/. Ou diretamente pelos links abaixo: Nagios Core Nagios Plugins ","date":"31/01/2017","objectID":"/instalando-nagios-instalacao-basica/:0:2","tags":["nagios"],"title":"Instalando Nagios - Instalação básica","uri":"/instalando-nagios-instalacao-basica/"},{"categories":null,"content":"Extraindo Pacotes tar -xzvf nagios-4.2.4.tar.gz tar -xzvf nagios-plugins-2.1.4.tar.gz ","date":"31/01/2017","objectID":"/instalando-nagios-instalacao-basica/:0:3","tags":["nagios"],"title":"Instalando Nagios - Instalação básica","uri":"/instalando-nagios-instalacao-basica/"},{"categories":null,"content":"Adicionar usuário Nagios useradd nagios groupadd nagios usermod -a -G nagios nagios usermod -a -G nagios www-data ","date":"31/01/2017","objectID":"/instalando-nagios-instalacao-basica/:0:4","tags":["nagios"],"title":"Instalando Nagios - Instalação básica","uri":"/instalando-nagios-instalacao-basica/"},{"categories":null,"content":"Instalação Compilando Nagios cd nagios-4.2.4 ./configure --with-command-group=nagios make all make install make install-init make install-config make install-commandmode make install-webconf Reiniciando o apache service apache2 restart Criando usuário e senha do Nagios htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin Compilando os plugins cd .. cd nagios-plugins-2.1.4 ./configure --with-nagios-user=nagios --with-nagios-group=nagios make make install Habilitar CGI no apache cp /etc/apache2/mods-available/cgi.load /etc/apache2/mods-enabled/ service apache2 reload Antes de fazer qualquer alteração nas configurações, teste se está tudo ok : /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg Caso não ocorra nenhum erro, podemos iniciar o serviço: /usr/local/nagios/bin/nagios -d /usr/local/nagios/etc/nagios.cfg Basta acessar pelo endereço IP/nagios (ip da máquina na qual foi instalado ou localhost se for local), com usuário nagiosadmin e a senha criada anteriormente. Segue um print do meu nagios com alguns hosts sendo monitorados e com uma interface diferente. Falaremos desses detalhes em outros posts. ","date":"31/01/2017","objectID":"/instalando-nagios-instalacao-basica/:0:5","tags":["nagios"],"title":"Instalando Nagios - Instalação básica","uri":"/instalando-nagios-instalacao-basica/"},{"categories":null,"content":"Usando o bashrc como uma ferramenta de trabalho","date":"16/12/2016","objectID":"/usando-o-bashrc-como-uma-ferramenta-de-trabalho/","tags":["linux","shell script"],"title":"Usando o bashrc como uma ferramenta de trabalho","uri":"/usando-o-bashrc-como-uma-ferramenta-de-trabalho/"},{"categories":null,"content":"Segue o meu .bashrc com vários atalhos e alterações. # Cor Verde (Usuario comum) PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ ' # Cor Vermelha (root) #PS1='${debian_chroot:+($debian_chroot)}\\[\\033[1;31m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[1;34m\\]\\w\\[\\033[00m\\]\\$ ' # Completion if [ -f /etc/bash_completion ]; then . /etc/bash_completion fi # Configurações Historico export HISTIGNORE=\"\u0026:ls:[bf]g:exit:reset:clear:cd*\" export HISTSIZE=4096 export HISTCONTROL=\"ignoreboth:erasedups\" shopt -s histreedit; # Mans coloridas export MANPAGER=\"/usr/bin/most -s\" # Alias alias update='pacman -Syu' alias ls='ls --color=auto' alias grep='grep --color=auto' alias fgrep='fgrep --color=auto' alias egrep='egrep --color=auto' # Extração de arquivos # Uso: extrair \u003c arquivo \u003e extrair() { if [ -f $1 ] ; then case $1 in *.tar.bz2) tar xvjf $1 ;; *.tar.gz) tar xvzf $1 ;; *.tar.xz) tar xvJf $1 ;; *.bz2) bunzip2 $1 ;; *.rar) unrar x $1 ;; *.gz) gunzip $1 ;; *.tar) tar xvf $1 ;; *.tbz2) tar xvjf $1 ;; *.tgz) tar xvzf $1 ;; *.zip) unzip $1 ;; *.Z) uncompress $1 ;; *.7z) 7z x $1 ;; *.xz) unxz $1 ;; *.exe) cabextract $1 ;; *) echo \"\\`$1': unrecognized file compression\" ;; esac else echo \"\\`$1' is not a valid file\" fi } # Misc alias musica='mocp -m /media/Documentos/Musica/' # Top 10 ( mostra os 10 comandos mais utilizados ). copyright 2007 - 2010 Christopher Bratusek function top10() { history | awk '{a[$2]++ } END{for(i in a){print a[i] \" \" i}}' | sort -rn | head } # alisa previsao tempo alias tempo='curl http://wttr.in/sapiranga' ","date":"16/12/2016","objectID":"/usando-o-bashrc-como-uma-ferramenta-de-trabalho/:0:0","tags":["linux","shell script"],"title":"Usando o bashrc como uma ferramenta de trabalho","uri":"/usando-o-bashrc-como-uma-ferramenta-de-trabalho/"},{"categories":null,"content":"Entenda um pouco o sistema de permissões no sistema Linux Pelo fato do Linux ser multiusuário, as permissões deve estar bem alinhadas para que o usuário tenha acesso somente aquilo que é de seu direito, incluindo pastas, arquivos e inclusive periféricos, como impressoras e drivers de CD por exemplo. A Estrtutura básica das permissões é separada em três classes: Dono: define as permissões ao dono do arquivo, ou seja, que criou o arquivo. Grupo: define as permissões para o grupo de usuários ao qual o dono do arquivo pertence. Outros: define as permissões para os demais usuarios, que não seja o dono ou que faça parte do grupo. Dentro de cada classe citada anteriormente, temos os tipos de acesso: Leitura (r): permissão de leitura para arquivos. Caso seja um diretório permite a listagem do seu conteúdo. Escrita (w): permite a escrita em arquivos ou criação dentro de pastas. Execução (x): permite a execução de um programa “executável”. Quando a gente executa um ls -la no terminal, podemos ver como funciona: No começo de cada linha temos 10 colunas referente as permissões de cada arquivo, onde a primeira coluna identifica o tipo do arquivo, se é um arquivo, um diretório, um link, etc. Após a primeira coluna, temos um conjunto de três colunas para cada classe de permissões, ou seja, do dono, do grupo e outros contando da esquerda para direita. ","date":"13/12/2016","objectID":"/comandos-de-manipulacao-de-permissoes-no-linux/:1:0","tags":["linux"],"title":"Comandos de manipulação de permissões no Linux","uri":"/comandos-de-manipulacao-de-permissoes-no-linux/"},{"categories":null,"content":"Diferença de permissões entre arquivos e diretórios: Objeto Leitura (r) Gravação (w) Execução (x) Arquivo Permite ler o conteúdo do arquivo Permite alterar o arquivo Permite executar arquivo como um programa Diretório Permite listar o conteúdo do diretório Permite criar e apagar arquivos no diretório Permite ler e gravar arquvos no diretório ","date":"13/12/2016","objectID":"/comandos-de-manipulacao-de-permissoes-no-linux/:1:1","tags":["linux"],"title":"Comandos de manipulação de permissões no Linux","uri":"/comandos-de-manipulacao-de-permissoes-no-linux/"},{"categories":null,"content":"Lista de comandos para trabalhar as permissões ","date":"13/12/2016","objectID":"/comandos-de-manipulacao-de-permissoes-no-linux/:2:0","tags":["linux"],"title":"Comandos de manipulação de permissões no Linux","uri":"/comandos-de-manipulacao-de-permissoes-no-linux/"},{"categories":null,"content":"chmod Muda as permissões de acesso a um determinado arquivo ou diretório. Sintaxe chmod [opções] [permissões] [diretório/arquivo] Opções -v, –verbose Mostra todos os arquivos que estão sendo processados. -f, –silent Não mostra a maior parte das mensagens de erro. -c, –change Semelhante a opção -v, mas só mostra os arquivos que tiveram as permissões alteradas. -R, –recursive Muda permissões de acesso do diretório/arquivo no diretório atual e sub-diretórios. ugoa+-=rwxXst ugoa - Indica o nível de acesso será mudado. Especificam, em ordem, usuário (u), grupo (g), outros (o), todos (a). +-= - + adiciona a permissão, – retira a permissão do arquivo e = define a permissão exatamente como especificado. rwx - r permissão de leitura do arquivo. w permissão de gravação. x permissão de execução (ou acesso a diretórios). Exemplos chmod o-r teste.txt # Retira (-) a permissão de leitura (r) do arquivo teste.txt para os outros usuários (usuários que não são donos e não pertencem ao grupo do arquivo teste.txt). chmod a+x teste.txt # Inclui (+) a permissão de execução do arquivo teste.txt para o dono, grupo e outros usuários. chmod 777 teste.txt # Coloca permissão total de escrita, leitura e execução no arquivo teste.txt para todos usuários ","date":"13/12/2016","objectID":"/comandos-de-manipulacao-de-permissoes-no-linux/:2:1","tags":["linux"],"title":"Comandos de manipulação de permissões no Linux","uri":"/comandos-de-manipulacao-de-permissoes-no-linux/"},{"categories":null,"content":"chgrp Muda o grupo de um arquivo ou diretório Sintaxe chgrp [opções] [grupo] [arquivo/diretório] Opções -v, –verbose Mostra todas as mensagens e arquivos sendo modificados. -R, –recursive Altera os grupos de arquivos/sub-diretórios do diretório atual. ","date":"13/12/2016","objectID":"/comandos-de-manipulacao-de-permissoes-no-linux/:2:2","tags":["linux"],"title":"Comandos de manipulação de permissões no Linux","uri":"/comandos-de-manipulacao-de-permissoes-no-linux/"},{"categories":null,"content":"chown Altera dono de um arquivo ou diretório. Pode também ser usado para mudar o grupo Sintaxe chown [opções] [dono.grupo] [diretório/arquivo] Opções -v, –verbose Mostra os arquivos enquanto são alterados. -R, –recursive Altera dono e grupo de arquivos no diretório atual e sub-diretórios. Exemplos chown sidnei teste.txt # Muda o dono do arquivo teste.txt para sidnei. chown sidnei.admin teste.txt # Muda o dono do arquivo teste.txt para sidnei e seu grupo para admin. ","date":"13/12/2016","objectID":"/comandos-de-manipulacao-de-permissoes-no-linux/:2:3","tags":["linux"],"title":"Comandos de manipulação de permissões no Linux","uri":"/comandos-de-manipulacao-de-permissoes-no-linux/"},{"categories":null,"content":"umask O comando umask define as permissões iniciais quando um arquivo ou diretório for criado. Digitando umask sem nenhum parâmetro podemos visualizar nosso umask atual. O umask cria permissão diferente caso o arquivo seja um executável e se for um arquivo texto. Veja a tabela a seguir: --------------------------------------------- | | ARQUIVO | DIRETÓRIO | | UMASK |----------------------| | | | Binário | Texto | | |------------------------------|------------| | 0 | r-x | rw- | rwx | | 1 | r-- | rw- | rw- | | 2 | r-x | r-- | r-x | | 3 | r-- | r-- | r-- | | 4 | --x | -w- | -wx | | 5 | --- | -w- | -w- | | 6 | --x | --- | --x | | 7 | --- | --- | --- | --------------------------------------------- Caso seu umask seja 022, os arquivos de texto será criados por padrão com permissão 644, ou seja, rw- para o dono, r– para o grupo e r– para outros. Para que alterar o umask, geralmente deve-se alterar seu valor no arquivo /etc/profile. ","date":"13/12/2016","objectID":"/comandos-de-manipulacao-de-permissoes-no-linux/:2:4","tags":["linux"],"title":"Comandos de manipulação de permissões no Linux","uri":"/comandos-de-manipulacao-de-permissoes-no-linux/"},{"categories":null,"content":"Com este comando podemos conferir quais os 10 comandos mais rodados em nossa máquina","date":"28/11/2016","objectID":"/dica-rapida-meus-10-comandos-mais-rodados-no-linux/","tags":["linux"],"title":"[Dica rápida] Meus 10 comandos mais rodados no linux","uri":"/dica-rapida-meus-10-comandos-mais-rodados-no-linux/"},{"categories":null,"content":"Com este comando podemos conferir quais os 10 comandos mais rodados em nossa máquina: history|awk '{print $2}'|awk 'BEGIN {FS=\"|\"} {print $1}'|sort|uniq -c|sort -rn|head -10 Meu resultado foi: history|awk '{print $2}'|awk 'BEGIN {FS=\"|\"} {print $1}'|sort|uniq -c|sort -rn|head -10 248 sudo 148 vi 101 sh 49 ping 49 ls 40 systemctl 38 ifconfig 38 htop 31 ps 26 du sidnei@black:~$ ","date":"28/11/2016","objectID":"/dica-rapida-meus-10-comandos-mais-rodados-no-linux/:0:0","tags":["linux"],"title":"[Dica rápida] Meus 10 comandos mais rodados no linux","uri":"/dica-rapida-meus-10-comandos-mais-rodados-no-linux/"},{"categories":null,"content":"Introdução Nos dias de hoje é de suma importância proteger nossos servidores contra ataques e invasões. Nesse caso especifico do ssh é importante mantê-lo bem seguro pois é a nossa porta de entrada para o servidor, qualquer brecha pode causar uma catástrofe. Não devemos pensar que por ser um servidor de uma pequena empresa ou um servidor VPS que não devemos ter esse cuidado, hoje a informação disponível pode estar valendo muito. É uma questão de segurança básica que devemos estar atentos para não termos dores de cabeça e continuar com nossos servidores e serviços intactos. ","date":"23/11/2016","objectID":"/reforcando-seguranca-servidor-ssh/:0:1","tags":["linux","segurança","ssh"],"title":"Reforçando segurança servidor ssh","uri":"/reforcando-seguranca-servidor-ssh/"},{"categories":null,"content":"Restrições de acesso Caso queria restringir acesso somente a grupos ou usuários específicos, acrescentaremos ou editaremos as opções abaixo no arquivo de configuração do servidor ssh, o /etc/ssh/sshd_config. O mais correto ainda seria criar um grupo somente para acessos ssh. AllowGroups sysadmin suporte AllowUsers pedro juca Podendo usar ou somente restrição por grupo ou somente restrição por usuário. ","date":"23/11/2016","objectID":"/reforcando-seguranca-servidor-ssh/:0:2","tags":["linux","segurança","ssh"],"title":"Reforçando segurança servidor ssh","uri":"/reforcando-seguranca-servidor-ssh/"},{"categories":null,"content":"Não permitir acesso direto como root PermitRootLogin no ","date":"23/11/2016","objectID":"/reforcando-seguranca-servidor-ssh/:0:3","tags":["linux","segurança","ssh"],"title":"Reforçando segurança servidor ssh","uri":"/reforcando-seguranca-servidor-ssh/"},{"categories":null,"content":"Modificar porta padrão De preferência uma porta com valor alto. Port 2258 ","date":"23/11/2016","objectID":"/reforcando-seguranca-servidor-ssh/:0:4","tags":["linux","segurança","ssh"],"title":"Reforçando segurança servidor ssh","uri":"/reforcando-seguranca-servidor-ssh/"},{"categories":null,"content":"Bloquear ataques de força bruta com iptables iptables -I input -p tcp --dport 22 -i eth0 -m state --state NEW -m recent -set iptables -I input -p tcp --dport 22 -i eth0 -m state --state NEW -m recent --update --seconds 60 --hitcount 4 -j DROP iptables -A INPUT -P tcp --destination-port 22 -j ACCEPT ","date":"23/11/2016","objectID":"/reforcando-seguranca-servidor-ssh/:0:5","tags":["linux","segurança","ssh"],"title":"Reforçando segurança servidor ssh","uri":"/reforcando-seguranca-servidor-ssh/"},{"categories":null,"content":"Logando com chaves de criptografia Gerar a chave ssh-keygen -b 1024 -t dsa Copiar para a outra máquina a chave pública ssh-copy-id -i ~/.ssh/id_dsa.pub 192.168.1.100 Verificar se o arquivo foi copiado para o destino em .ssh/authorized_keys e modificar a permissão para 600, por questões de segurança ","date":"23/11/2016","objectID":"/reforcando-seguranca-servidor-ssh/:0:6","tags":["linux","segurança","ssh"],"title":"Reforçando segurança servidor ssh","uri":"/reforcando-seguranca-servidor-ssh/"},{"categories":null,"content":"Desabilitar autenticação por senha PasswordAuthentication no ","date":"23/11/2016","objectID":"/reforcando-seguranca-servidor-ssh/:0:7","tags":["linux","segurança","ssh"],"title":"Reforçando segurança servidor ssh","uri":"/reforcando-seguranca-servidor-ssh/"},{"categories":null,"content":"Exportando imagem Temos aqui novamente um processo bem simples no docker, para exportar uma imagem uitlizamos o comando docker save debian-apache \u003e /tmp/imagem.tar ls -lh /tmp/ -rw-r--r-- 1 root root 225M nov 18 14:50 imagem.tar ","date":"18/11/2016","objectID":"/exportar-e-importar-containers-no-docker/:0:1","tags":["docker"],"title":"Exportar e importar containers no docker","uri":"/exportar-e-importar-containers-no-docker/"},{"categories":null,"content":"Importando imagem docker load \u003c imagem.tar Fala a verdade é simples ou não é, mais fácil que isso não tem como. Fonte ","date":"18/11/2016","objectID":"/exportar-e-importar-containers-no-docker/:0:2","tags":["docker"],"title":"Exportar e importar containers no docker","uri":"/exportar-e-importar-containers-no-docker/"},{"categories":null,"content":"Para iniciar um servidor apache no docker é muito simples, caso tenha uma imagem que já tenha apache é mais simples ainda. Mas vamos partir do principio que não tenha essa imagem, usaremos uma imagem do repositório do docker. Caso queira só baixar a imagem, começaremos com o comando: docker pull eboraas/apache Para iniciar o container com nosso servidor rodaremos o comando: docker run -it -p 80:80 -d eboraas/apache Caso queira iniciar também expondo as portas para ter suporte SSL: docker run -it -p 80:80 -p 443:443 -d eboraas/apache Basta acessar o IP de sua máquina que o servidor já estará rodando. Caso queira usar algum projeto web que tenha em sua máquina podemos linkar essa pasta com a pasta do container. docker run -it -p 80:80 -v /home/sidnei/meusite/:/var/www/html/ -d eboraas/apache Se caso a porta 80 de seu host esteja sendo usada, é possível mapear outra porta no container. Bastando acessar o IP:8080 para ter acesso ao apache do container. docker run -it -p 8080:80 -v /home/sidnei/meusite/:/var/www/html/ -d eboraas/apache Fonte ","date":"17/11/2016","objectID":"/iniciando-servidor-apache-no-docker/:0:0","tags":["docker"],"title":"Iniciando servidor apache no docker","uri":"/iniciando-servidor-apache-no-docker/"},{"categories":null,"content":"Docker é um ferramenta que venha aprendendo a pouco tempo, não explicarei o que é o docker, apenas alguns detalhes no uso. Caso queira uma explicação melhor sobre o que é docker, recomendo esse artigo do Mundo Docker. Segue abaixo alista dos comandos mais básicos e explicações básicas sobre o docker: docker search ubuntu # Procura versões do sistema ubuntu docker pull [nome da imagem] # baixar imagem docker images # listar imagens docker run [nome da imagem ou id] # iniciar container com a imagem baixada docker ps # listar containers docker ps -a # Verifica todos os containers, inclusive os que estão parados docker exec [id do container] [comando] # executa comandos no container docker rm [id do container] Iniciar container com alguns detalhes a mais: docker run -it -p \u003cporta_host\u003e:\u003cporta_container\u003e --name \u003cnome_container\u003e \u003cnome_imagem\u003e Sendo que o -i significa interatividade e o -t que queremos um link com o terminal do container. Iniciar uma sessão bash em um container que já esteja rodando: docker exec -it \u003cnome_container\u003e bash Verificar os logs de um container: ```shell docker logs \u003cnome_container\u003e Remover todos os containers parados: docker rm -f $(docker ps -a -q) Remover uma imagem baixada: docker rmi -f \u003cnome_imagem\u003e Copiar um arquivo do container para o host: docker cp \u003cnome_container\u003e:/caminho/no/container /caminho/no/host ","date":"17/11/2016","objectID":"/comandos-basicos-docker/:0:0","tags":["docker","servidores"],"title":"Comandos básicos Docker","uri":"/comandos-basicos-docker/"},{"categories":null,"content":"Salvando alterações de um container modificado Após instalar alguns programas ou fazer modificações no seu container, é possível que queira salvá-lo para não perder essas alterações. Para isso existe a opção commit do docker que irá gerar uma nova imagem do seu container com as alterações. Pegaremos como base o ID do nosso container: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f8d74ee7155a 7e616530e7ea \"/bin/bash\" 12 minutes ago Up 12 minutes 0.0.0.0:8080-\u0026gt;80/tcp lonely_mccarthy root@black:/home/sidnei# Com nosso ID em mãos faremos o commit: docker commit f8d74ee7155a debian-apache sha256:9a232ff09aaf601dfbe487c3b20802079cd5e1a55115fb3a47473f9e44ab8bf0 root@black:/home/sidnei# docker images REPOSITORY TAG IMAGE ID CREATED SIZE debian-apache latest 9a232ff09aaf 4 seconds ago 226.9 MB ","date":"17/11/2016","objectID":"/comandos-basicos-docker/:1:0","tags":["docker","servidores"],"title":"Comandos básicos Docker","uri":"/comandos-basicos-docker/"},{"categories":null,"content":"Dockerfile Um Dockerfile é um script que automatiza a criação de imagens docker. Veja alguns exemplos de comandos que podem ser utilizados no Dockerfile. Em outros posts trarei com mais detalhes como cada um funciona. FROM Primeira instrução, define a imagem base. FROM ubuntu14:04 MAINTAINER Especifica o autor da imagem. MAINTAINER Foo foo@bar.com RUN Equivalente ao comando docker run. RUN apt-get install python ENV Define uma variável de ambiente. ENV PORT=8000 EXPOSE Expõe portas. EXPOSE 8000 ADD Copia arquivos do host hospedeiro para dentro da imagem. ADD foo.txt /bar/foo.txt ENTRYPOINT Permite que a imagem seja executada como uma aplicativo (a partir da linha de comando especificada). ENTRYPOINT [\"python\", \"app.py\"] CMD Comando que será executado quando a execução do container for acionada. CMD [\"supervisord\"] Exemplo de dockerfile FROM debian:lastest MAINTAINER Sidnei Weber \u003csidnei.weber@gmal.com\u003e RUN apt-get update RUN apt-get install -y apache2 RUN /etc/init.d/apache2 start Para gerar a imagem a partir do nosso dockerfile usaremos o docker build. Lembrando que se criamos o docker file em alguma pasta especifica, deveremos estar dentro desta pasta para executar o comando a seguir: docker build -t teste . Por hoje era isso pessoal, em breve estaremos estudando mais sobre o assunto. Fonte: Diego Garcia ","date":"17/11/2016","objectID":"/comandos-basicos-docker/:2:0","tags":["docker","servidores"],"title":"Comandos básicos Docker","uri":"/comandos-basicos-docker/"},{"categories":null,"content":"Já havia tentado de várias maneiras remover a extensão .php dos meus arquivos, mas todas sem sucesso. Porém consegui fazer de uma maneira muito simples, editando o arquivo .htaccess. Lembrando que para funcionar a modulo “mod_rewrite” deve estar habilitado no seu servidor web. Criaremos o arquivo .htaccess na raiz do nosso projeto com o seguinte conteúdo \u003cIfModule mod_rewrite.c\u003e RewriteEngine on RewriteCond %{REQUEST_FILENAME} !-d RewriteCond %{REQUEST_FILENAME}.php -f RewriteRule ^(.*)$ $1.php \u003c/IfModule\u003e E quando formos criarmos nosso link no php, aqui no caso estamos com o exemplo signup.php, basta digitar assim: \u003ca href=\"signup\"\u003esignup here\u003c/a\u003e Sem a extensão .php. O servidor irá fazer todo o resto do trabalho. Fonte ","date":"17/10/2016","objectID":"/remover-extensao-php-com-htaccess-rapido-e-facil/:0:0","tags":["php"],"title":"Remover extensão .php com .htaccess (Rápido e fácil)","uri":"/remover-extensao-php-com-htaccess-rapido-e-facil/"},{"categories":null,"content":"Gestão corporativa com Software Livre","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Segue um trabalho que fiz na faculdade sobre gestão corporativa com software livre. Também listarei aqui meu rascunho para apresentação do slide, caso alguem tenha interesse. ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:0","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 1 = Apresentação Assunto Nome ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:1","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 2 = Gestão corporativa Breve introdução do assunto Governança corporativa é o conjunto de processos, costumes, políticas, leis, regulamentos e instituições que regulam a maneira como uma empresa é dirigida, administrada ou controlada. Os principais atores tipicamente são os acionistas, a alta administração e o conselho de administração. Outros participantes da governança corporativa incluem os funcionários, fornecedores, clientes, bancos e outros credores, instituições reguladoras (como a CVM, o Banco Central, etc.) e a comunidade em geral. O corporate governance visa a diminuir os eventuais problemas que podem surgir na relação entre gestores e accionistas e, consequentemente, diminuir o risco de custos de agência. Definição A Governança Corporativa visa a aumentar a probabilidade dos fornecedores de recursos garantirem para si o retorno sobre seu investimento, por meio de um conjunto de mecanismos no qual se inclui o Conselho de Administração. Dito de outra forma, “corporate governance é uma área […] que investiga a forma de garantir/motivar a gestão eficiente das empresas, utilizando mecanismos de incentivo como sejam os contratos, os padrões organizacionais e a legislação. O que frequentemente se limita à questão da melhoria do desempenho financeiro, como, por exemplo, a forma como os proprietários das empresas podem garantir/motivar os gestores das empresas a apresentarem uma taxa de retorno competitiva” ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:2","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 3 = Sistemas de gestão corporativa Breve introdução [editar] Beneficios Existem algumas categorias e tipos de sistemas distintos de gestão empresarial. Muitas vezes, todos estão integrados sobre as asas de um mesmo sistema ERP, mas podem vir também separados, dependendo das necessidades: Sistema de Gestão Patrimonial Sistema de Gestão Eletrônica de Documentos Sistemas de Controle de Estoque Sistemas de Controle da Produção Os sistemas de gestão empresarial, nas empresas onde são implantados, trazem os seguintes beneficios: Eliminação de custos relativos a processos manuais e aumento da produtividade devido a automatização. Aumento do fluxo interno de informação e integração entre os departamentos distintos nas empresas. Otimização do processo de tomada de decisões. Diminuição da redundância das atividades já que os processos passam a ser automatizados. Aumento da precisão na obtenção de informações e relatórios, já que os dados passam a ser criteriosamente armazenados No entanto, sistemas de gestão empresarial podem trazer as seguintes desvatagens e obstáculos: A empresa passa a sofrer uma forte dependência da empresa que forneceu e implantou o sistema de ERP Muitas vezes o alto custo que um sistema de gestão empresarial não trás um benefício semelhante ( baixo custo/benefício ) O aumento do controle sobre os processo e as pessoas, pode gerar resistência através de funcionários que não querem mudar seu método de trabalho A integração dos departamentos da empresa pelo sistema, muitas vezes não se reflete em uma integração real da companhia ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:3","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 4 = Software Livre Introdução sobre Vantagens Desvantagens Como se ganha com software Livre Software livre, segundo a definição criada pela Free Software Foundation é qualquer programa de computador que pode ser usado, copiado, estudado e redistribuído sem restrições. O conceito de livre se opõe ao conceito de software restritivo (software proprietário), mas não ao software que é vendido almejando lucro (software comercial). A maneira usual de distribuição de software livre é anexar a este uma licença de software livre, e tornar o código fonte do programa disponível. Definição Um software é considerado como livre quando atende aos quatro tipos de liberdade para os usuários do software definidas pela Free Software Foundation: A liberdade para executar o programa, para qualquer propósito (liberdade n.º 0); A liberdade de estudar como o programa funciona, e adaptá-lo para as suas necessidades (liberdade n.º 1). Acesso ao código-fonte é um pré-requisito para esta liberdade; A liberdade de redistribuir, inclusive vender, cópias de modo que você possa ajudar ao seu próximo (liberdade n.º 2); A liberdade de modificar o programa, e liberar estas modificações, de modo que toda a comunidade se beneficie (liberdade n.º 3). Acesso ao código-fonte é um pré-requisito para esta liberdade; A liberdade de executar o programa significa a liberdade para qualquer tipo de pessoa física ou jurídica utilizar o software em quantas máquinas quiser, em qualquer tipo de sistema computacional, para qualquer tipo de trabalho ou atividade, sem nenhuma restrição imposta pelo fornecedor. A liberdade de redistribuir o programa compilado, isto é em formato binário, necessariamente inclui a obrigatoriedade de disponibilizar seus códigos-fonte. Caso o software venha a ser modificado e o autor da modificação queira distribuí-lo, gratuitamente ou não, será também obrigatória a distribuição do código fonte das modificações, desde que elas venham a integrar o programa. Não é necessária a autorização do autor ou do distribuidor do software para que ele possa ser redistribuído, já que as licenças de software livre assim o permitem. Para que seja possível estudar ou modificar o software (para uso particular ou para distribuir) é necessário ter acesso ao código-fonte. Por isso a disponibilidade desses arquivos é pré-requisito para a liberdade do software. Cada licença determina como será feito o fornecimento do código fonte para distribuições típicas, como é o caso de distribuições em mídia portátil somente com os códigos binários já finalizados (sem o fonte). No caso da licença GPL, a fonte deve ser disponibilizada em local de onde possa ser acessado, ou deve ser entregue ao usuário, se solicitado, sem custos adicionais (exceto transporte e mídia). [editar]Venda de Software Livre As licenças de software livre permitem que eles sejam vendidos, mas estes em sua grande maioria estão disponíveis gratuitamente. Uma vez que o comprador do software livre tem direito às quatro liberdades listadas, ele poderia redistribuir este software gratuitamente ou mediante remuneração. As versões pagas geralmente são acompanhadas de algum tipo de serviço adicional, como direito a assistência técnica por determinado período e manuais, por exemplo. Muitas vezes comprar o software é mais vantajoso para o cliente final que não tem muita experiência em programação, poupando tempo. [editar]Motivação Os desenvolvedores de software na década de 70 frequentemente compartilhavam seus programas de uma maneira similar aos princípios do software livre. No final da mesma década, as empresas começaram a impor restrições aos usuários com o uso de contratos de licença de software. Em 1983, Richard Stallman iniciou o projeto GNU, e em outubro de 1985 fundou a Free Software Foundation (FSF). Stallman introduziu os conceitos de software livre e copyleft, os quais foram especificamente desenvolvidos para garantir que a liberdade dos usuários fosse preservada. Para o Movimento do software livre, que é um","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:4","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 5 = Exemplos Sistemas (ERP) Resumo do que faz Exemplos (Em imagens) Quem usa ERP (Enterprise Resource Planning) (Sistemas Integrados de Gestão Empresarial), são sistemas de informação que integram todos os dados e processos de uma organização em um único sistema. A integração pode ser vista sob a perspectiva funcional (sistemas de: finanças, contabilidade, recursos humanos, fabricação, marketing, vendas, compras, etc) e sob a perspectiva sistêmica (sistema de processamento de transações, sistemas de informações gerenciais, sistemas de apoio a decisão, etc). São uma plataforma de software desenvolvida para integrar os diversos departamentos de uma empresa, possibilitando a automação e armazenamento de todas as informações de negócios. Assim, as informações trafegam pelos módulos em tempo real, ou seja, uma ordem de vendas dispara o processo de fabricação com o envio da informação para múltiplas bases, do estoque de insumos à logística do produto. Um bom exemplo de como o ERP revoluciona uma companhia é que com uma melhor administração da produção, um investimento, como uma nova infra-estrutura logística, pode ser repensado ou simplesmente abandonado. Neste caso, ao controlar e entender melhor todas as etapas que levam a um produto final, a companhia pode chegar ao ponto de produzir de forma mais inteligente, rápida e melhor, o que, em outras palavras, reduz o tempo que o produto fica parado no estoque. Algumas das vantagens da implementação de um ERP numa empresa são: Eliminar o uso de interfaces manuais Reduzir custos Otimizar o fluxo da informação e a qualidade da mesma dentro da organização (eficiência) Otimizar o processo de tomada de decisão Eliminar a redundância de atividades Reduzir os limites de tempo de resposta ao mercado Reduzir as incertezas do Lead time Incorporação de melhores práticas (codificadas no ERP) aos processos internos da empresa Reduzir o tempo dos processos gerenciais [editar]Fatores Críticos de Sucesso Segundo uma pesquisa Chaos e Unfinished Voyages (1995) os principais fatores críticos de sucesso para um projeto de implantação de um ERP são: Envolvimento do Usuário Apoio da direção Definição clara de necessidades Planejamento adequado Expectativas realistas Marcos intermediários Equipe competente Comprometimento Visão e objetivos claros Equipe dedicada Infraestrutura adequada OpenBravo ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:5","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 6 = Exemplos Sistemas (CRM) Resumo do que faz Exemplos (Em imagens) Quem usa SugarCRM: É uma solução flexível e de grande qualidade. É um produto de excelência a custos mais baixos. É totalmente customizável às necessidades do utilizador. liberdade de escolha de módulos a utilizar e assente sobre uma arquitectura open source (Plataforma LAMP: Linux, Apache, MySQL, PHP) e compatível com qualquer sistema operativo. http://www.sugarcrm.com Um CRM tem três grandes objectivos: Facilitar, automatizar e gerir toda a área de marketing; Facilitar, automatizar e gerir toda a área comercial, os canais e a força de vendas; Gerir os serviços prestados ao cliente. Customer relationship management Customer Relationship Management (CRM) pode ser traduzida para a língua portuguesa como Gestão de Relacionamento com o Cliente (Gestão de Relação com o Cliente, em Portugal). Foi criada para definir toda uma classe de ferramentas que automatizam as funções de contacto com o cliente, essas ferramentas compreendem sistemas informatizados e fundamentalmente uma mudança de atitude corporativa, que objetiva ajudar as companhias a criar e manter um bom relacionamento com seus clientes armazenando e inter-relacionando de forma inteligente, informações sobre suas atividades e interacções com a empresa. O seu objetivo principal é auxiliar as organizações a angariar e fidelizar clientes ou prospectos, fidelizar clientes atuais na busca de atingir a sua satisfação total, através do melhor entendimento das suas necessidades e expectativas e formação de uma visão global dos ambientes de marketing. O CRM abrange, na generalidade, três grandes áreas: Automatização da gestão de marketing Automatização da gestão comercial, dos canais e da força de vendas Gestão dos serviços ao cliente CRM e a Informática Por vezes o CRM é entendido única e exclusivamente como os sistemas de computador desenvolvidos para a gestão de clientes, ou mesmo como sistemas de vendas ainda mais simplificados. Na realidade o CRM é apenas o conceito conforme descrito acima, e os sistemas de informática são a ferramenta que auxilia na gestão do relacionamento com clientes, estas ferramentas são chamadas de Sistemas de CRM. ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:6","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 7 = Exemplos Sistemas (BPM) Resumo do que faz Exemplos (Em imagens) Quem usa O Gerenciamento de Processos de Negócio (português brasileiro) (em inglês Business Process Management ou BPM) é um conceito que une gestão de negócios e tecnologia da informação com foco na otimização dos resultados das organizações através da melhoria dos processos de negócio. São utilizados métodos, técnicas e ferramentas para analisar, modelar, publicar, otimizar e controlar processos envolvendo recursos humanos, aplicações, documentos e outras fontes de informação. ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:7","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 8 = Exemplos Sistemas (Colaboração) Resumo do que faz Exemplos (Em imagens) Quem usa Sistemas Cooperativos ou Sistemas Colaborativos são Sistemas de Informação que fornecem suporte computacional aos indivíduos que tentam resolver um problema em cooperação com outros, sem que todos estejam no mesmo local, ao mesmo tempo. Estas ferramentas, denominadas groupware, aplicam conceitos de sistemas distribuídos, comunicação multimídia, ciência da informação e teorias socio-organizacionais. http://pt.wikipedia.org/wiki/Sistema_cooperativo ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:8","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 9 = Exemplos Sistemas (Gerenciamento de conteúdo) Resumo do que faz Exemplos (Em imagens) Quem usa Sistema de gerenciamento de conteúdo Origem: Wikipédia, a enciclopédia livre. Um Sistema de Gestão de Conteúdo - SGC, (em inglês Content Management Systems - CMS), é um sistema gestor de websites, portais e intranets que integra ferramentas necessárias para criar, gerir (editar e inserir) conteúdos em tempo real, sem a necessidade de programação de código, cujo objetivo é estruturar e facilitar a criação, administração, distribuição, publicação e disponibilidade da informação. Sua maior característica é a grande quantidade de funções presentes. Podemos dizer que um CMS é um framework, “um esqueleto” de website pré-programado, com recursos básicos e de manutenção e administração já prontamente disponíveis. através de uma interface de utilizador via Internet. Um CMS permite que a empresa tenha total autonomia sobre o conteúdo e evolução da sua presença na internet e dispense a assistência de terceiros ou empresas especializadas para manutenções de rotina. Nem mesmo é preciso um funcionário dedicado (webmaster), pois cada membro da equipe poderá gerir o seu próprio conteúdo, diminuindo os custos com recursos humanos. A habilidade necessária para trabalhar com um sistema de gestão de conteúdo não vai muito além dos conhecimentos necessários para um editor de texto. A aparência de um website criado com um CMS é customizável, através da utilização de templates que podem ser facilmente substituídos. Um sistema de gestão de conteúdo reduz custos e ajuda a suplantar barreiras potenciais à comunicação web reduzindo o custo da criação, contribuição e manutenção de conteúdo. Um grande exemplo de CMS é o Wordpress, um sistema em PHP, Open Source e de altíssima qualidade para gerir blogs ou portais cada vez mais completos. O Wordpress é um CMS totalmente customizável por themes (ou templates). Tem-se observado que ferramentas como Gestores de Conteúdo podem se tornar excelentes ambientes para o processo de ensino e aprendizagem e para a organização da informação produzida em ambientes com fins educacionais. Sejam eles em ambientes acadêmicos, sejam em ambientes empresariais. A própria Wikipédia pode ser considerada um “gerenciador de conteúdo”, assim fomentando a busca, localização e criação de conhecimento em um ambiente distribuído e colaborativo. WordPress WordPress é um sistema de gerenciamento de conteúdos na web, escrito em PHP e executado em MySQL, especialmente para a criação de blogs Gera XML, XHTML, e CSS em conformidade com os padrões W3C Gerenciamento de ligações integrado Estrutura de permalink amigável aos mecanismos de busca Suporte extensivo a plug-ins Categorias aninhadas e múltiplas categorias para artigos TrackBack e Pingback Filtros tipográficos para formatação e estilização de texto corretas Páginas estáticas Múltiplos autores Suporte a tags (desde a versão 2.3) ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:9","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Silde 10 = Conclusão Comprar licenças e implantar softwares proprietários complexos como CRM (soluções de atendimento ao consumidor) e ERP (sistema de gestão empresarial) custa caro e nem sempre é acessível para boa parte das pequenas e médias empresas Onde se ganha Treinamentos Consultoria Suporte Hoje, com esse moderno sistema de gestão de alta administração, o Presidente e os seus sócios-proprietários poderão profissionalizar as empresas e controlar de modo efetivo o seu patrimônio, podendo tomar assento nos Conselhos e delegar as responsabilidades do dia a dia a profissionais contratados, podendo se afastar de seus afazeres sem perder o efetivo controle da empresa. Software Livre pode promover avanços tecnológicos em países periféricos •Proporciona a Inclusão Digital •Relação Custo x Benefício bastante positiva •Futuro promissor –Aumento do nº de usuários e pessoas que conhecendo as vantagens. ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:10","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Slide 11 = Bibliografia ","date":"05/10/2016","objectID":"/gestao-corporativa-com-software-livre/:0:11","tags":["linux"],"title":"Gestão corporativa com Software Livre","uri":"/gestao-corporativa-com-software-livre/"},{"categories":null,"content":"Para deixar a configuração do servidor ssh um pouco mais segura, podemos configurar uma opção para um usuario que ficar inativo por um determinado tempo seja deslogado automaticamente. É uma opção muito útil caso seja esquecido uma sessão aberta, o que é bastante perigoso por sinal. O arquivo que devemos alterar é o /etc/ssh/sshd_config, adicionando ou alterando os seguintes parametros: ClientAliveCountMax 0 ClientAliveInterval 30 Com isso, caso tenha inatividade na sessão por 30 segundos o usuário será deslogado. ClientAliveCountMax: Define o numero máximo de envio de pacotes para saber se o cliente está ou não ativo. ClientAliveInterval: Define um intervalo de tempo em segundos após o qual, se o terminal estiver ocioso, será finalizada a sessão. ","date":"19/09/2016","objectID":"/deslogar-sessao-ssh-por-inatividade/:0:0","tags":["ssh"],"title":"Deslogar sessão ssh por inatividade","uri":"/deslogar-sessao-ssh-por-inatividade/"},{"categories":null,"content":"Tutorial básico e rápido de Mysql","date":"12/07/2016","objectID":"/tutorial-basico-e-rapido-de-mysql/","tags":["mysql"],"title":"Tutorial básico e rápido de Mysql","uri":"/tutorial-basico-e-rapido-de-mysql/"},{"categories":null,"content":"Instalação Começamos pela instalação, que nas distribuições Debian like seria: sudo apt-get install mysql-server phpmyadmin Esse comando instalará a última versão do Mysql e do administrador visual que mais gosto o PHPmyadmin. A instalação irá pedir uma senha para o usuário padrão (root): A confirmação da senha: Em qual servidor web o Phpmyadmin irá rodar, no meu caso apache: E diga não a próxima opção: ","date":"12/07/2016","objectID":"/tutorial-basico-e-rapido-de-mysql/:1:0","tags":["mysql"],"title":"Tutorial básico e rápido de Mysql","uri":"/tutorial-basico-e-rapido-de-mysql/"},{"categories":null,"content":"Administrando via linha de comando mysql -h host -u root -p (o super usuário default é root) Assim terá acesso ao terminal do mysql. ","date":"12/07/2016","objectID":"/tutorial-basico-e-rapido-de-mysql/:2:0","tags":["mysql"],"title":"Tutorial básico e rápido de Mysql","uri":"/tutorial-basico-e-rapido-de-mysql/"},{"categories":null,"content":"Comandos de uso básico Para ter acesso a linha de comando mysql localhost, após o comando será solicitado a senha de admin do mysql mysql -u root -p Criar base de dados: create database nomebanco; Para editar o banco de dados: use nomebanco; Criar tabela: create table nometabela(campos tipos...); Exemplo CREATE TABLE usuario ( id int, nome varchar(255), sobrenome varchar(255), endereco varchar(255), cidade varchar(255) ); Mostrar conteudo da tabela: select * from nometabela; Exibir bancos de dados: show databases; Exibir tabelas: show tables; Exibir informações das tabelas, a formação das informações: describe nometabela; ","date":"12/07/2016","objectID":"/tutorial-basico-e-rapido-de-mysql/:3:0","tags":["mysql"],"title":"Tutorial básico e rápido de Mysql","uri":"/tutorial-basico-e-rapido-de-mysql/"},{"categories":null,"content":"Exportar e importar via linha de comando Exportar mysqldump -u user -p passwd banco \u003e banco.sql Importando: mysql -u user -p password banco \u003c banco.sql Esse é o tutorial bem básico sobre o uso do mysql. ","date":"12/07/2016","objectID":"/tutorial-basico-e-rapido-de-mysql/:4:0","tags":["mysql"],"title":"Tutorial básico e rápido de Mysql","uri":"/tutorial-basico-e-rapido-de-mysql/"},{"categories":null,"content":"Primeiro atualize o sistema pacman -Sy Após isso baixamos a última versão (Na data da postagem essa era última versão) wget http://javadl.sun.com/webapps/download/AutoDL?BundleId=111679 -O Java-latest Descompactamos tar -zxvf Java-latest Copiamos para a pasta correta cp -pr jre1.8.0_60 /opt Criamos o link para o programa ln -s /opt/jre1.8.0_60/bin/java /usr/bin/java E o link para os plugins: ln -s /opt/jre1.8.0_65/lib/amd64/libnpjp2.so ~/.mozilla/plugins/libnpjp2.so Fonte ","date":"12/11/2015","objectID":"/instalar-java-8-no-manjaroarchlinux/:0:0","tags":["arch","manjaro","java","linux"],"title":"Instalar Java 8 no Manjaro/Archlinux","uri":"/instalar-java-8-no-manjaroarchlinux/"},{"categories":null,"content":" include(\"conexao.php\"); $busca = $_POST['busca']; // comando like com variavel // retorna todos os produtos que tenham o valor da variável busca em qualquer posição $result = mysql_query(\"SELECT descricao FROM produtos WHERE descricao like '%\".$busca.\"%' \"); // comando like normal //retorna todos os nomes que tenham a palavra \"pedro\" em qualquer posição $result = mysql_query(\" SELECT nome FROM funcionarios WHERE nome like '%pedro%' \");\u003c/pre\u003e ","date":"10/07/2015","objectID":"/utilizando-o-comando-like-com-variavel-php-mysql/:0:0","tags":["mysql","php"],"title":"Utilizando o comando like com variável [PHP-MySQL]","uri":"/utilizando-o-comando-like-com-variavel-php-mysql/"},{"categories":null,"content":" find . | xargs grep 'texto a pesquisar' ","date":"06/07/2015","objectID":"/shell-script-procurar-texto-em-varios-arquivos/:0:0","tags":["shell script"],"title":"[Shell Script] Procurar texto em vários arquivos","uri":"/shell-script-procurar-texto-em-varios-arquivos/"},{"categories":null,"content":"A sequência de teclas “CTRL+D” encerra uma sessão bash. Às vezes digitamos estas teclas por acidente e encerramos uma sessão acidentalmente. Para evitar que isto ocorra, definimos a variável de ambiente IGNOREEOF: export IGNOREEOF=1 Desta forma, para encerrar uma sessão bash, precisamos digitar a sequência CTRL+D duas vezes ou então digitar exit. Esta variável de ambiente deve ser definida no arquivo .bashrc. Fonte: Dicas-L ","date":"06/07/2015","objectID":"/evitando-encerramento-acidental-de-sessoes-bash/:0:0","tags":["linuxss","servidores","shell script"],"title":"Evitando encerramento acidental de sessões bash","uri":"/evitando-encerramento-acidental-de-sessoes-bash/"},{"categories":null,"content":"Pesquisar em um intervalo de datas Mysql","date":"06/07/2015","objectID":"/pesquisar-em-um-intervalo-de-datas-mysql/","tags":["mysql"],"title":"Pesquisar em um intervalo de datas Mysql","uri":"/pesquisar-em-um-intervalo-de-datas-mysql/"},{"categories":null,"content":" SELECT * FROM `contas_pagar` WHERE data BETWEEN ('2014-09-01') AND ('2014-09-31'); E para fazer uma soma em um intervalo de datas: SELECT SUM(valor) as total FROM contas_pagar WHERE valor BETWEEN ('2014-09-01') AND ('2014-09-31'); ","date":"06/07/2015","objectID":"/pesquisar-em-um-intervalo-de-datas-mysql/:0:0","tags":["mysql"],"title":"Pesquisar em um intervalo de datas Mysql","uri":"/pesquisar-em-um-intervalo-de-datas-mysql/"},{"categories":null,"content":"Editar o arquivo .bashrc e adicionar a linha a seguir #PS1='[u@h W]$ ' PS1='┌─[u@h W][e[0;32m][${cwd}t][\u003cwbr /\u003e033[0m] ${fill}n[\\033[0m]└─■ ' ","date":"06/07/2015","objectID":"/colocando-uma-firula-no-terminal/:0:0","tags":["linux","shell script"],"title":"Colocando uma firula no terminal","uri":"/colocando-uma-firula-no-terminal/"},{"categories":null,"content":"Backup de uma base específica mysqldump --database -d NOME DA BASE DE DADOS -u USUARIO -p \u003e c:meu_db.sql Backup de todas as bases mysqldump --all-databases -u USUARIO -p \u003e meu_mysql.sql ","date":"06/07/2015","objectID":"/backup-mysql-linha-comando/:0:0","tags":["linux","mysql"],"title":"Backup Mysql - Linha comando","uri":"/backup-mysql-linha-comando/"},{"categories":null,"content":"Maiúsculas e Minúsculas em PHP","date":"06/07/2015","objectID":"/maiusculas-e-minusculas-em-php/","tags":["php"],"title":"Maiúsculas e Minúsculas em PHP","uri":"/maiusculas-e-minusculas-em-php/"},{"categories":null,"content":"$texto =“warquia pereira santos” vamos transformar a variavel $texto =\u003e Converte a string para letras minúsculas strtolower(); srttolower($texto); vai sair assim = warquia pereira santos =\u003e Converte a string para letras maiúsculas strtoupper(); srttoupper($texto); vai sair assim = WARQUIA PEREIRA SANTOS =\u003e Converte o primeiro caractere de uma string em maiúsculo ucfirst(); ucfirst($texto); vai sair assim = Warquia pereira santos =\u003e Converte em maiúsculo o primeiro caractere de cada palavra contida em uma string ucwords(); ex: ucwords($texto); vai sair assim = Warquia Pereira Santos Fonte ","date":"06/07/2015","objectID":"/maiusculas-e-minusculas-em-php/:0:0","tags":["php"],"title":"Maiúsculas e Minúsculas em PHP","uri":"/maiusculas-e-minusculas-em-php/"},{"categories":null,"content":" vboxmanage modifyhd disco.vdi --resize 30000 ","date":"06/07/2015","objectID":"/redimensionar-disco-de-uma-maquina-virtual-virtualbox/:0:0","tags":["virtualização"],"title":"Redimensionar disco de uma máquina virtual - VirtualBox","uri":"/redimensionar-disco-de-uma-maquina-virtual-virtualbox/"},{"categories":null,"content":"Dentro do arquivo /etc/ssh/sshd_config altere as seguintes linhas: LoginGraceTime 2m MaxStartups 3:50:6 Explicando: O primeiro parâmetro informa que a conexão será cortada caso fique inativa por 2 minutos. O segundo quer dizer que depois de 3 tentativas não autenticadas, 50% das conexões do IP são recusadas e quando o número de de tentavivas chegar a 6 todas as tentativas de conexões do IP serão recusadas. Fonte: Dicas-l ","date":"06/07/2015","objectID":"/diminuindo-tentativas-de-invasao-via-ssh/:0:0","tags":["linux","servidores"],"title":"Diminuindo tentativas de invasão via SSH","uri":"/diminuindo-tentativas-de-invasao-via-ssh/"},{"categories":null,"content":"Utilizando o Crontab","date":"06/07/2015","objectID":"/utilizando-o-crontab/","tags":["linux"],"title":"Utilizando o Crontab","uri":"/utilizando-o-crontab/"},{"categories":null,"content":" Comando Função crontab -e Edita o crontab atual do usuário crontab -l Exibe o atual conteúdo do crontab do usuário crontab -r Remove o crontab do usuário A linha é dividida em 6 campos separados por tabs ou espaço: Campo Função 1° Minuto 2° Hora 3° Dia do mês 4° Mês 5° Dia da semana 6° Programa para execução Campo Valores Minuto 0-59 Hora 0-23 Dia do mês 1-31 Mês 1-12 Dia da semana 0-6 (o “0″ é domingo), 1 é segunda, etc. Fonte ","date":"06/07/2015","objectID":"/utilizando-o-crontab/:0:0","tags":["linux"],"title":"Utilizando o Crontab","uri":"/utilizando-o-crontab/"},{"categories":null,"content":"Códigos do Squid","date":"06/07/2015","objectID":"/codigos-do-squid/","tags":["squid"],"title":"Códigos do Squid","uri":"/codigos-do-squid/"},{"categories":null,"content":"COD DESCRIÇÃO 0 Resposta não recebida Respostas de informação: 100 Continue 101 Troca de protocolos Acessos bem-sucedidos: 200 OK 201 Criado 202 Aceito 203 Informação não autorizada 204 Sem conteúdo 205 Conteúdo apagado 206 Conteúdo parcial 207 Status múltiplos Redirecionamentos: 300 Escolhas múltiplas 301 Movido permanentemente 302 Movido temporariamente 303 Veja outros 304 Não modificado 305 Use o proxy 307 Redirecionamento temporário Erros no cliente: 400 Resposta ruim 401 Não autorizado 402 Pagamento requisitado 403 Negado 404 Não encontrado 405 Método não aceito 406 Não aceito 407 Autenticação do proxy solicitado 408 Tempo de resposta excedido 409 Conflito 410 Feito 411 Tamanho requerido 412 Falha pré-condicional 413 Requisição de entrada extensa 414 URL requisitada muito extensa 415 Tipo de mídia não suportada 416 Faixa requisitada não satisfatória 417 Falha na espera Erros no servidor: 500 Erro interno 501 Não implantado 502 Gateway incorreto 503 Serviço indisponível 504 Tempo excedido do gateway 505 Versão HTTP não suportada 507 Espaço em disco insuficiente Fonte ","date":"06/07/2015","objectID":"/codigos-do-squid/:0:0","tags":["squid"],"title":"Códigos do Squid","uri":"/codigos-do-squid/"},{"categories":null,"content":"@media A regra @media não só nos permite definir estilos para nossa página da web quando impressa na tela. Hoje em dia esta regra atingiu um patamar mais avançado com as “media queries“, que são associadas à criação de sites “adaptativos” ou “responsivos”, ou seja, que se ajustam ao tamanho da tela do dispositivo no qual estiverem sendo acessados. Você pode criar uma media query usando propriedades como min-width para ajustar seu layout de acordo com o tamanho do “viewport” do dispositivo do usuário. @media screen and (max-width: 960px) { // seus estilos vão aqui .... } ","date":"06/07/2015","objectID":"/regras-css-que-todo-desenvolvedor-web-deve-saber/:0:1","tags":["css"],"title":"11 regras CSS que todo desenvolvedor web deve saber","uri":"/regras-css-que-todo-desenvolvedor-web-deve-saber/"},{"categories":null,"content":"background-size Aí está uma propriedade CSS3 muito útil que ganhou total suporte nos navegadores modernos. Antes, para fazer com que uma imagem, definida como background, fosse ajustada 100% (full size), de acordo com o tamanho do elemento que faz parte, era necessário algumas linhas de código, hacks e até javascripts. Agora nós precisamos de apenas uma linha de código, ou melhor, apenas uma propriedade:background-size body { background: url(image.jpg) no-repeat; background-size: 100%; } ","date":"06/07/2015","objectID":"/regras-css-que-todo-desenvolvedor-web-deve-saber/:0:2","tags":["css"],"title":"11 regras CSS que todo desenvolvedor web deve saber","uri":"/regras-css-que-todo-desenvolvedor-web-deve-saber/"},{"categories":null,"content":"@font-face @font-face { font-family: Blackout; src: url(\"assests/blackout.ttf\") format(\"truetype\"); } ","date":"06/07/2015","objectID":"/regras-css-que-todo-desenvolvedor-web-deve-saber/:0:3","tags":["css"],"title":"11 regras CSS que todo desenvolvedor web deve saber","uri":"/regras-css-que-todo-desenvolvedor-web-deve-saber/"},{"categories":null,"content":"overflow:hidden .container { overflow: hidden; } Existe uma série de soluções e hacks para ajudar a resolver o problema com os elementos flutuantes. Este problema ocorre quando temos, dentro de um elemento de bloco (um DIV por exemplo), um outro elemento com float. Esse elemento que “flutua” não força automaticamente a altura do elemento container, ou seja, a altura do elemento container não acompanha a altura do elemento com float. Isto ocorre porque o elemento que está flutuando deixa de considerar o elemento container como pai. Um jeito hiper simples de “limpar” os elementos flutuantes é simplesmente declarar overflow: hidden; no elemento container. Isto é muito interessante, porque não precisamos mais adicionar “lixo” no nosso código html, como o tão famoso \u003cbr style=\"clear:both\" /\u003e. ","date":"06/07/2015","objectID":"/regras-css-que-todo-desenvolvedor-web-deve-saber/:0:4","tags":["css"],"title":"11 regras CSS que todo desenvolvedor web deve saber","uri":"/regras-css-que-todo-desenvolvedor-web-deve-saber/"},{"categories":null,"content":"margin: 0 auto; #container { margin: 0 auto; } É surpreendente que até então não exista nenhuma propriedade especifica para centralizar elementos. Mas enquanto isso não acontece, nós podemos utilizar o recurso de margem automática. Ao adicionarmos margin: 0 auto; em um elemento de bloco, este será centralizado. ","date":"06/07/2015","objectID":"/regras-css-que-todo-desenvolvedor-web-deve-saber/:0:5","tags":["css"],"title":"11 regras CSS que todo desenvolvedor web deve saber","uri":"/regras-css-que-todo-desenvolvedor-web-deve-saber/"},{"categories":null,"content":"input[type=“text”] O seletor input[type=\"text\"], bem como outros seletores avançados no geral, irão elevar suas habilidades com CSS do nível intermediário para o avançado. Seletores de atributos, em particular, são extremamente úteis para estilizar elementos sem que precisemos criar classes adicionais. Você poderá manipular não só campos do tipo texto, mas também radio, checkbox, submit, password, file, etc. input[type=\"text\"] { width: 200px; } input[type=\"checkbox\"]{ margin-right: 1em; } Fonte ","date":"06/07/2015","objectID":"/regras-css-que-todo-desenvolvedor-web-deve-saber/:0:6","tags":["css"],"title":"11 regras CSS que todo desenvolvedor web deve saber","uri":"/regras-css-que-todo-desenvolvedor-web-deve-saber/"},{"categories":null,"content":"Migração banco de dados Mysql","date":"06/07/2015","objectID":"/migracao-banco-de-dados-mysql/","tags":["mysql"],"title":"Migração banco de dados Mysql","uri":"/migracao-banco-de-dados-mysql/"},{"categories":null,"content":"Para fazer um backup de uma base de dados mysql e copiar para outra base basta fazer os seguintes passos Os dados que deverão ser alterados são os seguintes: base_origem endereco_base_original usuario_base_original senha_base_original base_destino endereco_base_destino usuario_base_destino senha_base_destino Sabendo os dados a alterar, substitua-os no comando abaixo e o execute: mysqldump base_origem --opt -h endereco_base_original -uusuario_base_original -psenha_base_original --routines --triggers | mysql base_destino -hendereco_base_destino -uusuario_base_destino -psenha_base_destino ","date":"06/07/2015","objectID":"/migracao-banco-de-dados-mysql/:0:0","tags":["mysql"],"title":"Migração banco de dados Mysql","uri":"/migracao-banco-de-dados-mysql/"},{"categories":null,"content":"Para atualizar o WordPress instalado localmente, basta trocar o método do sistema de arquivos com o parâmetro: FS_METHOD A seguir, estão as constantes válidas para atualizações do WordPress: FS_METHOD obriga o método do sistema de arquivos. Deve ser “direct”, “ssh”, “ftpext”, ou “ftpsockets”. Geralmente, você deve apenas mudar isso se estiver enfrentando problemas de atualização, se mudar, e não adiantar mude de volta/remova, Na maioria das circunstâncias, definir ftpsockets vai funcionar se o método escolhido automaticamente não funcionar. (Primary Preference) “Direct” obriga a usar solicitações Direct File I/O de dentro do PHP, o que possui muitas questões de segurança em servidores mal configurados, pode ser escolhido automaticamente quando necessário. (Secondary Preference) “ssh” obriga a usar a extensão SSH PHP. (3rd Preference) “ftpext” obriga a usar a extensão FTP PHP para acesso FTP e finalmente: (4th Preference) “ftpsockets” usa classe de Sockets PHP para acesso FTP. define('FS_METHOD', direct); ","date":"06/07/2015","objectID":"/atualizar-wordpress-localhost/:0:0","tags":["wordpress"],"title":"Atualizar WordPress localhost","uri":"/atualizar-wordpress-localhost/"},{"categories":null,"content":"Este plugin coloca WooCommerce em destaque na administração do WordPress, com destaque para as encomendas, relatórios, clientes, produtos e menus cupons, além de adicionar novos botões na barra de administração. Uma verdadeira mão na roda. Link para o plugin. ","date":"06/07/2015","objectID":"/woocommerce-domination-melhorando-a-usabilidade-do-woocommerce/:0:0","tags":["wordpress"],"title":"WooCommerce Domination - Melhorando a usabilidade do WooCommerce","uri":"/woocommerce-domination-melhorando-a-usabilidade-do-woocommerce/"},{"categories":null,"content":"Essa configuração útil quando estamos desenvolvendo e precisamos ver alguns erros gerados pelo nosso código. Basta editar o arquivo php.ini que no Linux geralmente fica em /etc/php5/apache2/php.ini e trocar a configuração da chave: _display_errors = Off_ Para On ","date":"06/07/2015","objectID":"/configurar-php-para-exibir-erros/:0:0","tags":["apache","php"],"title":"Configurar PHP para exibir erros","uri":"/configurar-php-para-exibir-erros/"},{"categories":null,"content":"Alerta de espaço em disco via e-mail","date":"06/07/2015","objectID":"/alerta-de-espaco-em-disco-via-e-mail/","tags":["shell script"],"title":"Alerta de espaço em disco via e-mail","uri":"/alerta-de-espaco-em-disco-via-e-mail/"},{"categories":null,"content":"Script para enviar e-mail quando o uso de disco chegar a 90% de uso df -k | grep -e 'lv' | awk '{ print $4 \" \" $7 }' | while read output; do echo $output usep=$(echo $output | awk '{ print $1}' | cut -d'%' -f1 ) partition=$(echo $output | awk '{ print $2 }' ) if [ $usep -ge 90 ]; then echo \"Verifique o diretorio \"$partition\" com ($usep%) de uso no servidor $(hostname)\" | mail -s \"Alerta! Disco excedido em $usep%\" seu_email@provedor.com fi done ","date":"06/07/2015","objectID":"/alerta-de-espaco-em-disco-via-e-mail/:0:0","tags":["shell script"],"title":"Alerta de espaço em disco via e-mail","uri":"/alerta-de-espaco-em-disco-via-e-mail/"},{"categories":null,"content":"Atalhos úteis para a linha de comando","date":"06/07/2015","objectID":"/atalhos-uteis-para-a-linha-de-comando/","tags":["linux","shell script"],"title":"Atalhos úteis para a linha de comando","uri":"/atalhos-uteis-para-a-linha-de-comando/"},{"categories":null,"content":" Atalho Ação Ctrl+A move o cursor para o começo da linha Ctrl+E move o cursor para o fim da linha Alt+F move o cursor para o fim da próxima palavra Alt+B move o cursor para o começo da palavra anterior Ctrl+T troca os dois últimos caracteres de posição, por exemplos “sl” se torna “ls” Alt+T troca as duas últimas palavras de posição, por exemplo “list cat” se torna “cat list” Ctrl+U corta o texto do começo da linha até o começo da palavra antes do cursor Ctrl+W corta apenas a palavra antes do cursor Ctrl+K cut the text of the current command after the cursor. Ctrl+Y cola o texto cortado anteriormente após o cursor. Este recurso é útil quando você acabou de digitar um comando longo e concluiu que esqueceu de fazer algo antes Alt+U converte para maiúsculas próxima palavra Alt+L converte para minúsculas a próxima palavra Alt+C converte para maiúsculas a primeira letra da próxima palavra Ctrl+L limpa a tela, deixando a linha corrente no topo Ctrl+_ undo (incremental). Fonte ","date":"06/07/2015","objectID":"/atalhos-uteis-para-a-linha-de-comando/:0:0","tags":["linux","shell script"],"title":"Atalhos úteis para a linha de comando","uri":"/atalhos-uteis-para-a-linha-de-comando/"},{"categories":null,"content":"netstat -putona - Um comando para monitorar as conexões de rede","date":"06/07/2015","objectID":"/netstat-putona-um-comando-para-monitorar-as-conexoes-de-rede/","tags":["linux"],"title":"netstat -putona - Um comando para monitorar as conexões de rede","uri":"/netstat-putona-um-comando-para-monitorar-as-conexoes-de-rede/"},{"categories":null,"content":" netstat -putona Onde os parâmetros significam: p Mostra as conexões para o protocolo especificado pelo TCP ou UDP u Lista todas as portas UDP t Lista portas em TCP o Exibe temporizadores n Exibe o número da porta a Exibe todas as conexões do sistema ativo Por exemplo, para saber que processo ocupa a porta 1521 pode utilizar: netstat -putona | grep :1521 Fonte ","date":"06/07/2015","objectID":"/netstat-putona-um-comando-para-monitorar-as-conexoes-de-rede/:0:0","tags":["linux"],"title":"netstat -putona - Um comando para monitorar as conexões de rede","uri":"/netstat-putona-um-comando-para-monitorar-as-conexoes-de-rede/"},{"categories":null,"content":"Fazer com que todas as conexões passem pelo proxy Criar o arquivo: cd /etc/init.d touch rc.firewall Adicionar o código: #! /bin/sh # Limpando tabelas do iptables iptables -F iptables -t nat -F iptables -t mangle -F # Definição da rede local rede_interna=”192.168.0.0/16” # Habilitando encaminhamento de pacotes e outras opções echo “1″ \u003e /proc/sys/net/ipv4/ip_forward echo “1″ \u003e /proc/sys/net/ipv4/icmp_echo_ignore_broadcasts echo “1″ \u003e /proc/sys/net/ipv4/icmp_echo_ignore_all # Carregando modulos necessários para o iptables /sbin/modprobe iptable_nat /sbin/modprobe ip_tables /sbin/modprobe ipt_state /sbin/modprobe ip_conntrack /sbin/modprobe ipt_multiport /sbin/modprobe iptable_mangle iptables -I PREROUTING -t nat -p tcp -s $rede_interna –dport 80 -j REDIRECT –to-port 3128 iptables -t nat -I POSTROUTING -s $rede_interna -j MASQUERADE iptables -A FORWARD -s $rede_interna -d loginnet.passport.com -j REJECT Permissao de execução chmod +x rc.firewall Cuide para que o firewall inicie automaticamente na próxima inicialialização: update-rc.d rc.firewall defaults Fonte ","date":"16/02/2014","objectID":"/proxy-transparente/:0:0","tags":["firewall","squid"],"title":"Proxy transparente","uri":"/proxy-transparente/"},{"categories":null,"content":"Instalação: apt-get install squid Arquivo base de configuração (/etc/squid/squid.conf): http_port 3128 visible_hostname KORZOS acl all src 0.0.0.0/0.0.0.0 acl manager proto cache_object acl localhost src 127.0.0.1/255.255.255.255 acl SSL_ports port 443 563 acl Safe_ports port 21 80 443 563 70 210 280 488 59 777 901 1025-65535 acl purge method PURGE acl CONNECT method CONNECT http_access allow manager localhost http_access deny manager http_access allow purge localhost http_access deny purge http_access deny !Safe_ports http_access deny CONNECT !SSL_ports acl redelocal src 192.168.0.0/24 http_access allow localhost http_access allow redelocal http_access deny all # Define o caminho das páginas de erro do squid. error_directory /usr/share/squid/errors/Portuguese # Define o e-mail que vai aparecer na página de erro do Squid, assim o usuário terá mais informações para interagir com o responsável. cache_mgr admin@seu_dominio.com.br # Esta ACL é responsável por não armazenar conteúdo CGI em cache. acl QUERY urlpath_regex cgi-bin ? no_cache deny QUERY # Define a quantidade de memória RAM reservada para o uso do Squid. cache_mem 64 MB # Esta linha é responsável por limitar o tamanho dos arquivos que serão armazenados no cache da memória RAM. maximum_object_size_in_memory 64 KB # Aqui definimos o tamanho máximo e mínimo respectivamente dos arquivos que serão armazenados no cache do HD. maximum_object_size 512 MB minimum_object_size 0 KB # Com essas duas linhas podemos definir a porcentagem de atualização do cache, estamos dizendo que quando o cache chegar em 95% o Squid irá apagar os arquivos mais antigos até chegar a 90%. cache_swap_low 90 cache_swap_high 95 # Nessa linha conseguimos definir o tamanho e alguns parâmetros do cache feito em HD, a linha é composta por quatro valores, o 1º define o caminho do cache (/var/spool/squid), o 2º o tamanho que será alocado em MB para o cache (2Gb), o 3º a quantidade de diretórios criados para o cache (16) e o 4º é o numero de subdiretórios que serão criados. Se você possuir bastante espaço em disco e quiser armazenar os arquivos por mais tempo, aumente a opção do tamanha do cache. cache_dir ufs /var/spool/squid 2048 16 256 # Define onde serão armazenados os registros de log do Squid. cache_access_log /var/log/squid/access.log refresh_pattern ^ftp: 15 20% 2280 refresh_pattern ^gopher: 15 0% 2280 refresh_pattern . 15 20% 2280 Reiniciar squid: /etc/init.d/squid restart ","date":"16/02/2014","objectID":"/servidor-proxy-com-squid/:0:0","tags":["servidores","squid"],"title":"Servidor Proxy com squid","uri":"/servidor-proxy-com-squid/"},{"categories":null,"content":"Entendendo configuração: http_port 3128: Define em qual porta o Squid vai atuar, a porta default é a 3128, mas podemos definir qualquer outra porta. visible_hostname SERVIDOR: Define o nome do servidor, lembre-se de substituir o “KORZOS” pelo nome do seu servidor. acl all src 0.0.0.0/0.0.0.0: Esta linha cria uma ACL, uma política de acesso com nome “all” contendo qualquer IP. acl localhost src 127.0.0.1/255.255.255.255: Aqui criamos uma ACL de nome “localhost” contendo localhost. acl SSL_ports port 443 563: Cria a ACL contendo as portas que são utilizadas no protocolo HTTPS. acl Safe_ports port 21 80 443 563 70 210 280 488 59 777 901 1025-65535: Cria a ACL contendo as portas de diversos protocolos conhecidos na Internet. acl manager proto cache_object: Cria a ACL manager do tipo proto. acl purge method PURGE : Cria a ACL manager do tipo method. acl CONNECT method CONNECT: Cria a ACL CONNECT também do tipo method. http_access allow manager localhost: Libera a ACL manager e localhost. http_access deny manager : Bloqueia a ACL manager. http_access allow purge localhost: Libera a ACL purge e localhost http_access deny purge: Bloqueia a ACL purge. http_access deny !Safe_ports: Esta linha se torna bastante interessante pelo uso da “!”, pois ela bloqueia qualquer conexão que não contenha o conteúdo da ACL Safe_Ports. http_access deny CONNECT !SSL_ports: Bloqueia qualquer conexão que não esteja no conteúdo da ACL SSL_ports. acl redelocal src 192.168.0.0/24: Cria a ACL redelocal contendo a faixa de endereço da rede. http_access allow localhost: Libera a ACL localhost. http_access allow redelocal: Libera a ACL redelocal. http_access deny all: Bloqueia a ACL all Criando ACLs Arquivos: Neste arquivo, iremos adicionar palavras que serão bloqueadas, como: sexo, porno… pico /etc/squid/palavras_bloqueadas.txt Neste arquivo, serão adicionados os sites que não terão acesso, como: 4shared.com, rapidshare.com, megavideo.com, filesonic.com, etc: pico /etc/squid/sites_bloqueados.txt Aqui, iremos colocar as redes sociais, como: facebook.com, orkut.com, twiter.com, etc: pico /etc/squid/redes_sociais.txt Neste arquivo, iremos colocar os IPs das máquinas dos gerentes (e “daquela” estagiária que entrou semana passada…:)): pico /etc/squid/ips_liberados.txt Lista de sites adultos: redtub, xvideos pico /etc/squid/sites_porno.txt Este arquivo limita os tipos de arquivos que serão baixados, tudo que contiver neste arquivo será bloqueado. Exemplos: .avi$, .mp3$, .wmv$: pico /etc/squid/formato_arquivo.txt Adicionar ACLs: acl rede_local src 192.168.0.0/24 acl palavras_bloqueadas url_regex -i \"/etc/squid/palavras_bloqueadas.txt \" acl sites_bloqueados url_regex -i \"/etc/squid/ sites_bloqueados.txt \" acl redes_sociais url_regex -i \"/etc/squid/redes_sociais.txt\" acl liberados src \"/etc/squid/ips_liberados.txt \" acl porno url_regex -i \"/etc/squid/sites_porno.txt \"e acl formato_arquivo url_regex -i \"/etc/squid/formato_arquivo.txt\" acl horario_almoco time 12:00-13:00 http_access allow liberados http_access allow redes_sociais horario_almoco http_access deny redes_sociais http_access deny sites_bloqueados http_access deny palavras_bloqueadas http_access deny porno http_access deny formato_arquivo http_access allow redelocal Criar arquivos de swap squid -z E iniciar os serviços Fonte ","date":"16/02/2014","objectID":"/servidor-proxy-com-squid/:0:1","tags":["servidores","squid"],"title":"Servidor Proxy com squid","uri":"/servidor-proxy-com-squid/"},{"categories":null,"content":"Primeiramente instalaremos o pacote: apt-get install samba Depois alteramos a configuração do arquivo: vi /etc/samba/smb.conf E alteramos alguns parametros: [global] #nome do grupo de trabalho workgroup = casa #como a maquina irá aparecer na rede Windows netbios name = servidor de arquivos #autenticação #modo de acesso ao servidor security = user / share #lembrado que user é quando se criará um usuário no sistema, e share sem usuário #compartilhamentos [arquivos] #descrição do compartilhamento comment = meus arquivos #caminho da pasta no servidor path = /arquivos # ou o diretório desejado public = yes browseable = yes #se está visível ou oculto na rede writeable = yes #permite escrita read only = no #somente leitura valid users = VOCE # define a mascara em que os arquivos serão criados create mask = 0700 #(terão a permissão rwx somente para o root) # define a mascara em que os diretórios serão criados directory mask = 0700 Vamos criar o diretório compartilhado no servidor: mkdir /arquivos Adicionando um usuário para acessar o Samba: smbpasswd -a VOCE Reinicie o serviço: service smbd restart Pronto, servidor disponível. Fonte ","date":"11/02/2014","objectID":"/instalar-servidor-samba-dica-rapida/:0:0","tags":["samba","servidores"],"title":"Instalar servidor Samba [Dica rápida]","uri":"/instalar-servidor-samba-dica-rapida/"},{"categories":null,"content":"Instalando um dashboard para seu servidor linux","date":"04/02/2014","objectID":"/instalando-um-dashboard-para-seu-servidor-linux/","tags":["linux","servidores"],"title":"Instalando um dashboard para seu servidor linux","uri":"/instalando-um-dashboard-para-seu-servidor-linux/"},{"categories":null,"content":" cd /var/www/ git clone https://github.com/afaqurk/linux-dash.git yum -y install php php-common php-gd php-mbstring php-xml php-xmlrpc /etc/init.d/httpd start Agora acesse: http://endereco.ip.do.server/linux-dash Fonte ","date":"04/02/2014","objectID":"/instalando-um-dashboard-para-seu-servidor-linux/:0:0","tags":["linux","servidores"],"title":"Instalando um dashboard para seu servidor linux","uri":"/instalando-um-dashboard-para-seu-servidor-linux/"},{"categories":null,"content":"Dicas segurança para WordPress","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Não divulgue a versão do seu WordPress Esta informação fica localizadas no arquivo header.php de seu tema. Para desabilitar, remova a linha a seguir: \u003cmeta name=\"generator\" content=\"WordPress \u003c?php bloginfo('version'); ?\u003e\" /\u003e Outra maneira de remover esta informação é adicionar o código abaixo ao seu arquivos functions.php: \u003cpre\u003e\u003c?php remove_action(‘wp_head’, ‘wp_generator’); ?\u003e\u003c/pre\u003e ","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/:0:1","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Remoção dos arquivos readme.html e install.php ","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/:0:2","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Remova os plugins e temas que não estão sendo utilizados ","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/:0:3","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Não use o login padrão do Admin do WordPress ","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/:0:4","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Bloqueie a listagem de arquivos em suas pastas Para impedir que os arquivos de suas pastas sejam listados, crie ou modifique o arquivo .htaccess (se seu site rodar em Linux) e inclua a seguinte linha: Options All -Indexes O arquivo deve estar na pasta principal (“/”) da instalação do WordPress juntamente com o arquivo wp-config.php. ","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/:0:5","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Desabilite o WP_DEBUG. A variável global WP_DEBUG permite ao desenvolvedor, depurar a aplicação. Deixar estas informações visíveis também pode fornecer informações valiosas aos atacantes. Para desabilitar a variável WP_DEBUG, edite o arquivo wp-config.php e altere de true para false. define(‘WP_DEBUG’, false); ","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/:0:6","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Desabilite o registro de novos usuários Ao fazer isso você impede que qualquer um tenha acesso ao painel de administração do site. Vá até a seção Geral e desmarque a opção Qualquer pessoa pode se registrar, ou simplesmente delete o arquivo wp-register.php Este post, de maneira nenhuma tem o objetivo de ser um guia definitivo mas sim apenas um ponto de partida para aqueles que conhecem pouco de segurança no WordPress ou para complementar os conhecimentos daqueles que já aplicam técnicas para proteção de sites e blogs. Fonte ","date":"20/01/2014","objectID":"/dicas-seguranca-wordpress/:0:7","tags":["wordpress"],"title":"Dicas segurança WordPress","uri":"/dicas-seguranca-wordpress/"},{"categories":null,"content":"Para isso, utilizaremos o comando chage. Antes, listamos as propriedades de login deste usuário: chage -l Exemplo: chage -l perm Última mudança de senha : Jan 07, 2014 Senha expira : nunca Senha inativa : nunca Conta expira : nunca Número mínimo de dias entre troca de senhas : 0 Número máximo de dias entre troca de senhas : 99999 Número de dias de avisos antes da expiração da senha : 7 Como podemos visualizar, a senha deste usuário “nunca expira”. Então, forçaremos a expiração de senha para o próximo login que este usuário venha fazer, executando o comando a seguir: chage -d 0 perm Fonte: http://www.vivaolinux.com.br/dica/Configurando-troca-de-senha-de-usuario-no-proximo-login ","date":"12/01/2014","objectID":"/configurando-troca-de-senha-de-usuario-no-proximo-login/:0:0","tags":["linux"],"title":"Configurando troca de senha de usuário no próximo login","uri":"/configurando-troca-de-senha-de-usuario-no-proximo-login/"},{"categories":null,"content":" ls -lct /etc | tail -1 | awk '{print $6, $7, $8}' ","date":"20/11/2013","objectID":"/comando-para-saber-quando-foi-instalado-o-seu-linux/:0:0","tags":["linux"],"title":"Comando para saber quando foi instalado o seu Linux","uri":"/comando-para-saber-quando-foi-instalado-o-seu-linux/"},{"categories":null,"content":"Se você quer converter uma data vinda do MYSQL para o formato PT-BR use o seguinte comando: $data = implode(\"/\",array_reverse(explode(\"-\",$data))); Assim vai converter a data do mysql para o formato brasileiro. Ex: 2010-31-04 para 31/04/2010 Se você quer converter uma data em formato brasileiro para inserir no mysql use: $data = implode(\"-\",array_reverse(explode(\"/\",$data))); O resultado será: 31/04/2010 para 2010-31-04 Fonte: http://www.l9web.com.br/blog/?p=68 ","date":"19/11/2013","objectID":"/melhor-maneira-de-converter-data-para-mysql-php/:0:0","tags":["mysql","php"],"title":"Melhor maneira de converter data para mysql [PHP]","uri":"/melhor-maneira-de-converter-data-para-mysql-php/"},{"categories":null,"content":"Desenvolvido por Jeremy D. Zawodny, o Mytop é uma ferramenta para monitorar o MySQL baseada em console (sem interface gráfica). É utilizada para verificar o desempenho geral e threads do MySQL. Roda na maioria dos sistemas Linux/Unix (incluindo Mac OS X), que tenham o Perl, DBI e Term:: ReadKey instalados. E com o Term:: ANSIColor instalado, você ainda terá cores. Se você instalar o Time::HiRes, você terá consultas de status em tempo real/segundos. Plataformas suportadas: Linux FreeBSD Mac OS X BSDI Solaris Windows Vamos instalar o Mytop, abra o terminal (console) e siga as instruções. Para sistemas que utilizam o apt-get, você pode instalar como este comando: sudo apt-get install mytop Em sistemas baseados no Red Hat, como Fedora, você pode executar o comando: yum -y install mytop Se preferir, você pode fazer o download do arquivo em: http://jeremy.zawodny.com/mysql/mytop/ Execute estes comandos para descompactar e instalar o Mytop: tar -zxvf mytop-\u003cversion\u003e.tar.gz $ cd mytop-\u003cversion\u003e $ perl Makefile.PL $ make $ make test $ sudo make install Pronto, a ferramenta está instalada! Executando o Mytop A maneira mais simples de executar Mytop é executar o comando diretamente na linha de comando. No terminal digite: mytop -u \u003cusuário\u003e -p -h _ Por exemplo: mytop -u tsarmento -p vol2011 -h 172.16.99.253 Alguns outros argumentos: ” ? ” – Exibe ajuda; ” d ” – Mostra as conexões a uma determinada base de dados – Nome da base de dado; ” f ” – Mostra a consulta completa de uma dado ID de processo (deve ser um processo ativo); ” F “- Desabilita todos os filtros (host, user, and db); ” h ” – Mostra apenas as consultas de um determinado host, conectar a um computador remoto; ” I ” – Mostra o status do InnoDB; ” k ” – Mata um processo; ” m ” – Muda o modo de exibição de top para qps (Queries Per Second Mode). Ele exibirá na tela a quantidade de querys por segundo; ” o ” – Inverte a ordem padrão de ordenação; ” p ” – Pausa a exibição; ” q ” – Sair do mytop; ” r ” – Reset os contadores de status do servidor via comando FLUSH STATUS; ” s ” – Muda o tempo de atualização do refresh (em segundos); ” u ” – Mostra os processos de um determinado usuário; ” P ” – Especifica uma porta não-padrão do MySQL para conectar; Se você não quer ter que lembrar suas opções, pode criar um arquivo ~/.mytop para armazenar os argumentos neste formato: user=root pass= host=localhost db=minhabasededados delay=5 port=3306 socket= batchmode=0 header=1 color=1 idle=1 Usando um arquivo de configuração irá ajudar a assegurar que a sua senha do banco de dados não fique visível aos usuários na linha de comando. Apenas certifique-se de que as permissões do arquivo ~/.mytop estão de tal forma que os outros usuários não tenham permissão de leitura (a menos que você queira, claro). Você pode ter algum espaço em branco nas linhas do arquivo de configuração, depois do =. Para mais informações acesse: http://jeremy.zawodny.com/mysql/mytop Agradeço a todos pela atenção. Viva o Linux, porque nós amamos a Liberdade! Fonte ","date":"23/04/2013","objectID":"/monitorar-a-performance-do-mysql-com-mytop/:0:0","tags":["mysql"],"title":"Monitorar a performance do MySQL com Mytop","uri":"/monitorar-a-performance-do-mysql-com-mytop/"},{"categories":null,"content":"Para programar o computador para desligar em um certo horário, basta como root usar o seguinte comando: shutdown -h hh:mm Sendo que hh são as horas no formato de 24 horas e mm são os minutos. Outra maneira para programar o desligamento do seu pc é usar o seguinte comando: shutdown -h +m Sendo que m é o número de minutos que você deseja até o computador desligar. Ex: shutdown -h +300 Significa que o computador desligará daqui a 300 minutos. Depois de executar um desses comandos começará uma contagem regressiva no seu terminal. Da mesma maneira podemos utilizar esses dois modelos para reiniciar o computador. A diferença é que em vez de passar o parâmetro -h, passaremos o parâmetro -r. Ficaria assim: shutdown -r hh:mm ou shutdown -r +m Fonte ","date":"23/04/2013","objectID":"/desligar-ou-reiniciar-o-computador-com-hora-marcada/:0:0","tags":["linux","shell script"],"title":"Desligar ou reiniciar o computador com hora marcada","uri":"/desligar-ou-reiniciar-o-computador-com-hora-marcada/"},{"categories":null,"content":"Semana passada me deparei com a seguinte situação, tinha um servidor com duas placas de rede , eth0 e eth1 , só que a placa de rede eth0 deu pau e foi trocada, porem, quando foi instalada a nova placa o servidor reconheceu como eth2s. Para resolver essa situação faça o seguinte: Com o usuário root edite o arquivo: vi /etc/udev/rules.d/70-persistent-net.rules Apague as linhas: Salva, saia e reinicie ! Suas placas voltarão novamente eth0 e eth1. Fonte ","date":"23/04/2013","objectID":"/mudando-o-nome-da-placa-de-rede/:0:0","tags":["hardware","linux"],"title":"Mudando o nome da placa de rede","uri":"/mudando-o-nome-da-placa-de-rede/"},{"categories":null,"content":"Ontem fiz download de um arquivo RAR e para minha surpresa o mesmo estava com senha. Antes de procurar outros links resolvi tentar quebrar a senha deste arquivo mesmo, e buscando uma solução no Google eis que acho o rarcrack, um brute force para arquivos .rar, .zip e 7-zip. Faça download do arquivo em: http://sourceforge.net/projects/rarcrack/files/rarcrack-0.2/%5BUnnamed%20release%5D/ Feito o download, como root, navegue até a pasta onde salvou o arquivo e faça: tar -xjf rarcrack-VERSAO.tar.bz2 cd rarcrack-VERSAO Você precisará do gcc ou outro compilador C: make make install Pronto, instalado. Para usar o rarcrack: rarcrack --type *rar nomedoarquivo.rar o type fica a seu critério, dependendo do seu arquivo compactado. Obs.: Infelizmente acabei não lembrando de cronometrar o processo. Mas após 30~45min o arquivo já estava extraído. Fonte ","date":"23/04/2013","objectID":"/rarcrack-quebrando-senhas-de-arquivos-rar-7z-e-zip/:0:0","tags":["linux"],"title":"Rarcrack - Quebrando senhas de arquivos rar, 7z e zip","uri":"/rarcrack-quebrando-senhas-de-arquivos-rar-7z-e-zip/"},{"categories":null,"content":"O SSL (Secure Socket Layer) é o protocolo usado para criar páginas seguras, encriptando toda a transmissão entre o cliente e o servidor. Os dois usos mais comuns são em páginas de comércio eletrônico, onde é necessário oferecer um ambiente seguro para concluir a transação e transmitir dados confidenciais e também na criação de ambientes administrativos, como os usados pela maioria dos gestores de conteúdo, que permitem que você gerencie o conteúdo do site. Na grande maioria das distribuições, o pacote com o mod_ssl é instalado juntamente com o pacote principal do Apache, ou é pelo menos disponibilizado como um pacote separado, instalável através do gerenciador de pacotes. No caso das distribuições derivadas do Debian, você precisa apenas ativar o módulo usando o comando “a2enmod”. Reinicie o serviço para que a alteração entre em vigor: a2enmod ssl /etc/init.d/apache2 force-reload No caso do CentOS, é necessário instalar o pacote “mod_ssl” usando o yum. O script de pós-instalação se encarrega de adicionar o script de carregamento na pasta “/etc/httpd/conf.d” automaticamente, concluindo a instalação. Não se esqueça de reiniciar o serviço para que a alteração entre em vigor: yum install mod_ssl service httpd restart Com o módulo carregado, fica faltando apenas o componente mais importante, que é o certificado SSL propriamente dito. Se você quer ativar o SSL para testes ou para uso interno (para acessar alguma ferramenta administrativa instalada no servidor, ou para uso em uma página disponibilizada apenas para um grupo de amigos, por exemplo), você pode simplesmente gerar seu próprio certificado, o que é rápido, grátis e indolor. Se, por outro lado, você está ativando o SSL para uso em um site de comércio eletrônico, é necessário obter um certificado reconhecido através da Verisign ou outra entidade certificadora. Os certificados caseiros são chamados de certificados self-signed (auto-assinados), já que você mesmo faz o papel de entidade certificadora, gerando e assinando o certificado. O algoritmo de encriptação usado é o mesmo, de forma que um certificado self-signed corretamente gerado oferece a mesma segurança que um certificado reconhecido. O grande problema é que os navegadores nos clientes não serão capazes de verificar a autenticidade do certificado, de forma que os visitantes receberão um aviso de “certificado não reconhecido” ao acessarem a página: O propósito de entidades certificadoras, como a Verisign, é confirmar a titularidade dos certificados, confirmando que o certificado recebido ao acessar determinado site pertence realmente à entidade que o está fornecendo. É isso que garante que você está mesmo acessando o home banking do banco em que tem conta e não o site de um script kiddie qualquer. Certificados assinados por entidades certificadoras são automaticamente aceitos pelos navegadores (já que sua identidade já foi confirmada pela entidade certificadora), o que evita a exibição da mensagem. Vamos então começar com a configuração de um certificado self-signed, e em seguida entender o que muda ao utilizar um certificado reconhecido. Fonte: ","date":"23/04/2013","objectID":"/ativando-o-suporte-a-ssl-em-servidores-web/:0:0","tags":["servidores"],"title":"Ativando o suporte a SSL em servidores web","uri":"/ativando-o-suporte-a-ssl-em-servidores-web/"},{"categories":null,"content":"Validando Formulários PHP","date":"23/04/2013","objectID":"/validando-formularios-php/","tags":["php"],"title":"Validando Formulários PHP","uri":"/validando-formularios-php/"},{"categories":null,"content":"Validando CEP O código abaixo valida o CEP informado através do método POST (conforme script abaixo). \u003c?php \u003cspan style=\"font-family:Consolas, Monaco, monospace;\"\u003e // Validando CEP\u003c/span\u003e if($_POST['cep']){ if (!eregi(\"^[0-9]{5}-[0-9]{3}$\", $_POST['cep'])) { echo \"\u003cscript language=\"JavaScript\"\u003ealert('CEP inválido !!!');\u003c/script\u003e\"; }else{ echo \"O CEP $cep foi validado com sucesso!!!\"; } } ?\u003e Onde informamos que o CEP foi validado com sucesso, tu poderá customizar de acordo com suas necessidades! ","date":"23/04/2013","objectID":"/validando-formularios-php/:1:0","tags":["php"],"title":"Validando Formulários PHP","uri":"/validando-formularios-php/"},{"categories":null,"content":"Validando Data O código abaixo valida a Data informada através do método POST (conforme script abaixo). \u003c?php // Validando Data if($_POST['data']){ if (!eregi(\"^[0-9]{2}/[0-9]{2}/[0-9]{4}$\", $_POST['data'])) { echo \"\u003cscript language=\"JavaScript\"\u003ealert('Data inválida !!!');\u003c/script\u003e\"; }else{ echo \"A Data $data foi validada com sucesso!!!\"; } } ?\u003e Onde informamos que validação da Data foi efetuada com sucesso, tu poderá customizar de acordo com suas necessidades! ","date":"23/04/2013","objectID":"/validando-formularios-php/:2:0","tags":["php"],"title":"Validando Formulários PHP","uri":"/validando-formularios-php/"},{"categories":null,"content":"Validando Endereço de EMail O código abaixo deverá validar o Endereço de Email informado através do método POST (conforme script abaixo). \u003c?php // Validando o EMail if ($_POST['email']){ if (!eregi(\"^[a-z0-9_.-]+@[a-z0-9_.-]*[a-z0-9_-]+.[a-z]{2,4}$\", $_POST['email'])) { echo \"\u003cscript language=\"JavaScript\"\u003ealert('Email inválido !!!');\u003c/script\u003e\"; }else{ echo \"O EMail $email foi validado com sucesso!!!\"; } } ?\u003e Onde informamos que validação do EMail foi efetuado com sucesso, tu poderá customizar de acordo com suas necessidades! ","date":"23/04/2013","objectID":"/validando-formularios-php/:3:0","tags":["php"],"title":"Validando Formulários PHP","uri":"/validando-formularios-php/"},{"categories":null,"content":"Validando Telefones Abaixo temos 2 exemplos de validação de telefone. Exemplo 01: \u003c?php // Validando Telefone no Formato xxxx-xxxx if($_POST['telefone']){ if (!eregi(\"^[0-9]{4}-[0-9]{4}$\", $_POST['telefone'])) { echo \"\u003cscript language=\"JavaScript\"\u003ealert('Telefone inválido !!!');\u003c/script\u003e\"; }else{ echo \"O Telefone $telefone foi validado com sucesso!!!\"; } } ?\u003e Exemplo 02: \u003c?php // Validando Telefone no Formato (DDD) xxxx-xxxx if($_POST['telefone']){ if (!eregi(\"^([0-9]{3}) [0-9]{4}-[0-9]{4}$\", $_POST['telefone'])) { echo \"\u003cscript language=\"JavaScript\"\u003ealert('Telefone inválido !!!');\u003c/script\u003e\"; }else{ echo \"O Telefone $telefone foi validado com sucesso!!!\"; \u003cspan style=\"font-family:Consolas, Monaco, monospace;\"\u003e}\u003c/span\u003e } ?\u003e Onde informamos que a validação do Telefone foi efetuada com sucesso, tu poderá customizar de acordo com suas necessidades! ","date":"23/04/2013","objectID":"/validando-formularios-php/:4:0","tags":["php"],"title":"Validando Formulários PHP","uri":"/validando-formularios-php/"},{"categories":null,"content":"Validando Página Esse script é especial e necessário para quem é desenvolvedor web! Imagine aquele sistema enorme que você produziu e deixou no Servidor de seu cliente? Após receber o conteúdo ele vende ou fornece cópia para um “amigo” que quer uma solução similar! Criptografando o código e colocando este conteúdo, você garantirá a segurança de suas informações! Vamos dar uma olhada no código? \u003c?php \u003cspan style=\"font-family:Consolas, Monaco, monospace;\"\u003e// Valida a cópia do Sistema\u003c/span\u003e $server = $_SERVER['SERVER_NAME']; $endereco = $_SERVER ['REQUEST_URI']; $url =\"http://\" . $server . $endereco; $url_certa = \"http://enderecodosite.com/\"; if($url != $url_certa) { echo \"\u003cscript language=\"JavaScript\"\u003ealert('VOCÊ NÃO TEM LICENÇA PARA USAR ESTA LOJA - Entre em contato com o EMail email@seuemail.com.br para validar sucópia.');\u003c/script\u003e\"; }else{ echo \"COLOQUE AQUI O CÓDIGO DA PÁGINA\"; } \u003cspan style=\"font-family:Consolas, Monaco, monospace;\"\u003e?\u003e \u003ca href=\"http://www.webmaster.pt/como-validar-formulario-8269.html\"\u003eFonte\u003c/a\u003e\u003c/span\u003e ","date":"23/04/2013","objectID":"/validando-formularios-php/:5:0","tags":["php"],"title":"Validando Formulários PHP","uri":"/validando-formularios-php/"},{"categories":null,"content":"Mais uma dica rápida sobre o jogo Pac-Man para o Ubuntu. Instalação: sudo apt-get install pacman4console E depois, com o terminal aberto, digite: pacman4console Aparecerá esta mensagem: Sorry. To play Pacman for Console, your console window must be at least 32×29 Please resize your window/resolution and re-run the game. Resumindo, o terminal tem que estar maximizado. E pronto. Já poderá jogar: Na dúvida, verifique a man page: man pacman4console ","date":"19/04/2013","objectID":"/pac-man-no-terminal-ubuntu/:0:0","tags":["ubuntu"],"title":"Pac-Man no terminal Ubuntu","uri":"/pac-man-no-terminal-ubuntu/"},{"categories":null,"content":"Estava interessado em criar uma forma de scannear a rede para saber quantos micros estavam conectados a ela, saber nome, grupo, MAC ADDRESS. Para que o script funcione será preciso instalar alguns softwares: dialog: apt-get install dialog nmap: apt-get install nmap Copie o código e cole em um arquivo texto e salve com um nome de sua preferência, de permissão para executar (chmod +x nome_do_arquivo.sh) e em seguida execute-o (./nome_do_arquivo.sh): #!/bin/bash Principal ( ) { ## Inicio Primeiro Bloco clear # Loop que mostra o menu principal while : ; do # Mostra o menu na tela, com as ações disponíveis opcao=$( dialog --stdout --title 'Menu principal' --menu 'Escolha as opções:' 0 0 0 1 'Scannear IPs da Rede' 0 'Sair') [ $? -ne 0 ] \u0026\u0026 Sair # Se apertado CANCELAR ou ESC, então vamos Sair... case $opcao in ## ## Inicio case 1)ipscan ;; 0)Sair ;; esac ## Fim da verificação done } ## FIM MENU PRINCIPAL ## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ## ipscan ( ) { clear inicio=$(dialog --stdout --title 'Firerock ipscan' --inputbox 'Inicio (Ex.192.168.0.1)' 0 0 ) [ $? -ne 0 ] \u0026\u0026 Principal # Se apertado CANCELAR ou ESC, então vamos Sair... final=$(dialog --stdout --title 'Firerock ipscan' --inputbox 'Final (Ex.192.168.0.254)' 0 0 ) [ $? -ne 0 ] \u0026\u0026 ipscan # Se apertado CANCELAR ou ESC, então vamos Sair... #faixa_rede=`echo \"$inicio\" | cut -d '.' -f 1-3` inicio_host=`echo \"$inicio\" | cut -d '.' -f 4` final_host=`echo \"$final\" | cut -d '.' -f 4` inicio_host=$(expr $inicio_host - 1) hosts_verificados=$(expr $final_host - $inicio_host) dialog --yesno 'O processo pode levar alguns minutos! Deseja Continuar?' 6 45 if [ $? = 0 ]; then continua else clear ipscan fi } continua ( ) { echo \" \" echo \"STATUS ENDEREÇO IPv4 MAC ADDRESS NOME GRUPO \" \u0026gt; /tmp/hosts.txt echo \"------------------------------------------------------------------------------------------\" \u0026gt;\u0026gt; /tmp/hosts.txt ips_on=$(nmap -sP \"$inicio-$final_host\" | awk '/^Host/ {print $2}') online=\"0\" offline=\"0\" for ip in $ips_on; do $(nmblookup -A $ip \u0026gt; /tmp/nm_hosts.txt) ## Saída do comando é # entre clientes Windows e Unix (Linux) mac_address_win2003=$(cat /tmp/nm_hosts.txt | awk 'NR==9 {print $4}') mac_address_xp=$(cat /tmp/nm_hosts.txt | awk 'NR==7 {print $4}') nm_pc=$(cat /tmp/nm_hosts.txt | awk 'NR==2 {print $1}') nm_grupo=$(cat /tmp/nm_hosts.txt | awk 'NR==3 {print $1}') mac_address_unix=$(cat /tmp/nm_hosts.txt | awk 'NR==10 {print $4}') ##inicio de verificação p/ ver se é cliente Unix if [ \"$mac_address_unix\" == \"00-00-00-00-00-00\" ]; then ## Se $mac_address_unix for igual a 00-00-00-00-00-00 é um cliente unix #mac_address=$(cat /tmp/nm_hosts.txt | awk 'NR==10 {print $4}') nm_pc=$(cat /tmp/nm_hosts.txt | awk 'NR==2 {print $1}') nm_grupo=$(cat /tmp/nm_hosts.txt | awk 'NR==6 {print $1}') echo \"On $ip $mac_address_unix $nm_pc $nm_grupo\" \u0026gt;\u0026gt; /tmp/hosts.txt online=$(expr $online + 1) else if [ \"$mac_address_xp\" == \"\" ]; then echo \"On $ip $mac_address_win2003 $nm_pc $nm_grupo\" \u0026gt;\u0026gt; /tmp/hosts.txt online=$(expr $online + 1) else if [ ! $nm_pc == 'No' ]; then echo \"On $ip $mac_address_xp $nm_pc $nm_grupo\" \u0026gt;\u0026gt; /tmp/hosts.txt online=$(expr $online + 1) else mac_address= nm_pc= nm_grupo= echo \"On $ip $mac_address $nm_pc $nm_grupo\" \u0026gt;\u0026gt; /tmp/hosts.txt online=$(expr $online + 1) fi fi fi done offline=$(expr $hosts_verificados - $online) echo \"------------------------------------------------------------------------------------------\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \" \" \u0026gt;\u0026gt; /tmp/hosts.txt echo \"Informações:\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \"Faixa de IPs verificados:\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \"Inicio: $inicio\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \"Final : $final\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \" \" \u0026gt;\u0026gt; /tmp/hosts.txt echo \"Hosts Verificado: $hosts_verificados\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \"Hosts Online: $online\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \"Hosts Offline: $offline\" \u0026gt;\u0026gt; /tmp/hosts.txt echo \" \" \u0026gt;\u0026gt; /tmp/hosts.t","date":"28/01/2013","objectID":"/verificar-maquinas-ligadas-do-shell-script/:0:0","tags":["linux","rede"],"title":"Verificar máquinas ligadas com shell script","uri":"/verificar-maquinas-ligadas-do-shell-script/"},{"categories":null,"content":"Abra o terminal e digite o comando: gsettings set org.gnome.desktop.wm.preferences button-layout 'menu:minimize,maximize,close' ","date":"31/12/2012","objectID":"/mudando-a-posicao-dos-botoes-do-menu-ubuntu-12-10/:0:0","tags":["ubuntu"],"title":"Mudando a posição dos botões do menu ubuntu 12.10","uri":"/mudando-a-posicao-dos-botoes-do-menu-ubuntu-12-10/"},{"categories":null,"content":"As imagens VDI são dinamicamente expansíveis. Isto é legal, porque é possível criar um arquivo pequeno que vai crescendo a medida que o disco da máquina virtual precisa armazenar mais arquivos. Mas se depois de um tempo você liberar espaço no “disco virtual”, o arquivo VDI não é reduzido. Para resolver isto, é preciso seguir as seguintes etapas: Zerar os setores não utilizados no sistema de arquivos virtual do arquivo VDI. Se o sistema convidado for Linux, você provavelmente vai encontrar uma solução com o dd. No meu caso, o sistema virtual era o Windows XP, então utilizei o aplicativo ccleaner que, além de remover arquivos desnecessários, possui a opção (em avançado) de preencher com zero o espaço livre. Rode o seguinte programa (na máquina hospedeira): vboxmanage modifyvdi nome_do_seu_arquivo.vdi compact Aqui consegui reduzir de 5 para 3,8GB o meu arquivo. Fonte: http://www.vivaolinux.com.br/dica/VirtualBox-Reduzindo-imagens-VDI ","date":"29/09/2009","objectID":"/virtualbox-reduzindo-imagens-vdi/:0:0","tags":["virtualização"],"title":"VirtualBox: Reduzindo imagens VDI","uri":"/virtualbox-reduzindo-imagens-vdi/"},{"categories":null,"content":"Uma dúvida muito constante dos usuários Openfire é como fazer para atualizarem seu servidor para uma versão mais recente. Segue então um pequeno howto (adaptado do orginal da Ignite Realtime): Pare o Openfire Faça um backup do diretório de instalação do Openfire (isso é preciso porque ao abrir o novo .tar.gz ou .zip os dados serão sobreescritos). No meu caso, que mantenho o openfire no /opt, um simples mv /opt/openfire /opt/openfire.old já resolve. Backupeie o banco de dados (se você usar o DB interno, isso já foi feito no passo anterior). Se você usa MySQL, por exemplo, um simples mysqldump da base já resolve. Abra o .tar.gz ou .zip (isso irá criar um novo diretório openfire, se você moveu o anterior, como eu costumo fazer) Copie o diretório conf do backup para a nova instalação. Se você usar o DB interno, copie o diretório embedded-db do backup para a nova instalação. Copie o diretório enterprise do backup para a nova instalação (se ele existir) Copie o diretório plugins do backup para a nova instalação, exceto por _plugins/admin_ (esse passo eu dispenso, e sempre instalo os plugins novamente, já que as configurações e dados dos mesmos estão no DB) Copie os arquivos modificados localizados em resources/security do backup para a nova instalação. Inicie o Openfire. Voilà. Seu servidor está atualizado e no ar novamente. FONTE: http://mundoopensource.blogspot.com/2008/08/openfire-como-atualizar-o-servidor-para.html ","date":"29/09/2009","objectID":"/atualizar-openfire/:0:0","tags":["openfire"],"title":"Atualizar Openfire","uri":"/atualizar-openfire/"},{"categories":null,"content":"Escondendo a versão dos serviços que estão rodando em seu servidor para aumentar a segurança Pessoal. Importante para a segurança de um servidor é esconder a versão de seus serviços para que o invasor não fique procurando uma falha de segurança para aquela versão específica do daemon. Então vamos ocultar alguns serviços mais utilizados: Proftpd Basta adicionar a seguinte linha no proftpd.conf: ServerIdent on \"\" A linha acima informa a versão do serviço como sendo “”, isso quer dizer que será em branco. Para validar é necessário reiniciar o Proftpd. SSH Já esse é necessário baixar o fonte do site oficial www.openssh.com/ e compilar : D Após descompactar, terá um arquivo chamado version.h. Altere o conteúdo da seguinte linha: #define SSH_VERSION \"\" Depois é só compilar normalmente com ./configure, make e make install. Obs.: O ssh escuta por padrão na porta 22. É altamente recomendável alterar essa porta para qualquer outra porta. Apache O Apache, assim como o Proftpd, basta apenas acrescentar uma opção em seu conf conforme a linha baixo: ServerTokens Prod Necessário reiniciar o serviço também. Para testar se as versões dos daemons estão ocultadas, use o nmap para verificar conforme o exemplo: nmap localhost -sV Starting nmap 3.75 ( http://www.insecure.org/nmap/ ) at 2008-03-05 09:46 BRT Interesting ports on localhost (127.0.0.1): (The 1658 ports scanned but not shown below are in state: closed) PORT STATE SERVICE VERSION 21/tcp open ftp? 8080/tcp open http Apache httpd Nmap run completed - 1 IP address (1 host up) scanned in 100.332 seconds Porque o ssh não apareceu quando utilizados o nmap para varrer as portas da máquina? Porque foi alterada para uma porta que não está na lista que o nmap utiliza que está em /usr/share/nmap/nmap-services. Alguns outros programas identificam o tipo de serviço em qualquer porta que seja, mas não saberá a versão do serviço. Um outro programa que pode ser usado é o Nessus para esse tipo de verificação. ","date":"29/09/2009","objectID":"/esconder-versao-dos-servicos-de-rede/:0:0","tags":["rede","servidores"],"title":"Esconder versão dos serviços de rede","uri":"/esconder-versao-dos-servicos-de-rede/"},{"categories":null,"content":"Hardware - Guia ilustrado","date":"29/09/2009","objectID":"/hardware-guia-ilustrado/","tags":["hardware"],"title":"Hardware - Guia ilustrado","uri":"/hardware-guia-ilustrado/"},{"categories":null,"content":"Acesso negado - Squid","date":"28/09/2009","objectID":"/acesso-negado-squid/","tags":["squid"],"title":"Acesso negado - Squid","uri":"/acesso-negado-squid/"},{"categories":null,"content":"ACESSO NEGADO: A página não pode ser exibida # ACESSO NEGADO ![]() ## A página não pode ser exibida \u003chr size=\"1px\" /\u003e Você não tem permissão para acessar esta URL: \u003c%U\u003e O Servidor de Controle do Nome da Sua Empresa negou a sua requisição, pois este site infringe regras da Política de Segurança da Informação ou não foi solicitado pelo seu superior. Em caso de dúvidas entre em contato com o Departamento de Tecnologia da Informação-DTI E-mail: Seu E-mail. Ramal: Seu Ramal.\u003c/p\u003e ","date":"28/09/2009","objectID":"/acesso-negado-squid/:0:0","tags":["squid"],"title":"Acesso negado - Squid","uri":"/acesso-negado-squid/"},{"categories":null,"content":"Fork bomb para Windows @echo off c: deltree /y c:\\*.\\* ","date":"28/09/2009","objectID":"/apaga-tudobat/:0:0","tags":["windows"],"title":"Apaga tudo.bat","uri":"/apaga-tudobat/"},{"categories":null,"content":"Apache restrito httpd.conf","date":"28/09/2009","objectID":"/apache-restrito-httpdconf/","tags":["ldap","apache"],"title":"Apache restrito httpd.conf","uri":"/apache-restrito-httpdconf/"},{"categories":null,"content":"Exemplo de como restringir o acesso com apache realizando autenticação no LDAP. Diretório Restrito Options Indexes FollowSymLinks Includes AllowOverride AuthConfig #Autenticao AuthName \"Acesso ao SARG\" AuthType Basic AuthBasicProvider \"ldap\" AuthLDAPURL \"ldap://201.7.197.39:389/dc=topazio,dc=com?uid?sub\" authzldapauthoritative Off #AuthUserfile /etc/apache2/apache_passwd require user sweber #AuthUserfile /etc/apache2/apache_passwd #require valid-user Order allow,deny Allow from all Diretorio Install Options Indexes FollowSymLinks Includes AllowOverride AuthConfig AuthName \"Acesso ao INSTALL\" AuthType Basic AuthBasicProvider \"ldap\" AuthLDAPURL \"ldap://201.7.197.39:389/dc=topazio,dc=com?uid?sub\" authzldapauthoritative Off #AuthUserfile /etc/apache2/apache_passwd require user sweber Order allow,deny Allow from all ","date":"28/09/2009","objectID":"/apache-restrito-httpdconf/:0:0","tags":["ldap","apache"],"title":"Apache restrito httpd.conf","uri":"/apache-restrito-httpdconf/"},{"categories":null,"content":"Executar comando NMAP de forma agressiva nmap -T Aggressive -A -v 127.0.0.1 ","date":"28/09/2009","objectID":"/nmap-agressivo/:0:0","tags":["nmap"],"title":"Nmap agressivo","uri":"/nmap-agressivo/"},{"categories":null,"content":"linux apm=off acpi=off noapic nolapic nopcmcia noapci nosmp pnpbios=off nomce – Se quiser pode substituir o correspondente por algum destes aqui: (apm=power-off ou noapm) (pci=noacpi) (apci=off ou pci=noapci) APM – Advanced Power Management: Esse comando de inicialização do x86 desativa o Gerenciador Avançado de Energia. É útil porque algumas BIOS têm erros no gerenciamento de energia e tendem a travar ACPI – Advanced Configuration and Power Interface: Desliga o recurso, responsável pela configuração e gerenciamento de energia no computador. É usado em notebooks e desktops para, por exemplo, colocar o computador em estado de hibernação. Algumas placas simplesmente têm uma implementação furada da ACPI ou precisam de configuração especial pra funcionar corretamente. Outras placas, por outro lado, precisam do parâmetro acpi=force porque têm problemas se o ACPI não estiver ativado. APIC – Advanced Programmable Interrupt Controller: É um controlador de interrupções integrado no processador. Esse comando de inicialização do x86 diz ao kernel para não utilizar o chip APIC. Pode ser útil para algumas placas-mãe com um APIC danificado (como o Abit BP6) ou com um BIOS cheio de erros. Sistemas baseados nos chips nForce3 da NVIDIA (como o ASUS SK8N) foram conhecidos por caírem durante a detecção do IDE no momento da inicialização ou por apresentarem outros problemas de interrupção. PCMCIA – Esse comando ignora qualquer controlador PCMCIA no sistema, que geralmente são de notebook/laptop pelo que sei NOSMP – Desativa o suporte da placa mãe a multi-processamento e hyperthreading. Algumas placas sequer têm um segundo processador, mas são esquizofrênicas, acreditam que têm e reclamam bem alto se você não concordar com elas. PNPBIOS=OFF – Desliga o recurso plug-and-play do barramento ISA. Isso resolve nos casos em que a placa-mãe acha que é uma boa idéia reservar um monte de interrupções para dispositivos não existentes ou interrupções que deveriam ficar com dispositivos on-board no barramento PCI. ","date":"24/09/2009","objectID":"/parametros-de-inicializacao/:0:0","tags":["linux"],"title":"Parâmetros de Inicialização","uri":"/parametros-de-inicializacao/"},{"categories":null,"content":"Codecs ubuntu 9.04","date":"23/09/2009","objectID":"/codecs-ubuntu-904/","tags":["ubuntu"],"title":"Codecs ubuntu 9.04","uri":"/codecs-ubuntu-904/"},{"categories":null,"content":"Paso #1: Agregar el Repositorio de Medibuntu Abre el terminal ubicado en Aplicaciones/Accesorios/Terminal, y ejecuta el siguiente comando: sudo wget http://www.medibuntu.org/sources.list.d/jaunty.list –output-document=/etc/apt/sources.list.d/medibuntu.list Paso #2: Agregar la llave GPG Ahora ejecuta este otro comando: sudo apt-get update \u0026\u0026 sudo apt-get install medibuntu-keyring \u0026\u0026 sudo apt-get update Paso #3: Instalar Codec’s Ahora podemos instalar los codec’s que necesitemos. Ejecuta cada linea en el Terminal para instalar el codec nombrado: sudo apt-get install libdvdcss2 sudo apt-get install w32codecs sudo apt-get install non-free-codecs sudo apt-get install ffmpeg Si deseas instalar todo de una sola vez solo ejecuta esto: sudo apt-get install libdvdcss2 w32codecs non-free-codecs ffmpeg ","date":"23/09/2009","objectID":"/codecs-ubuntu-904/:0:0","tags":["ubuntu"],"title":"Codecs ubuntu 9.04","uri":"/codecs-ubuntu-904/"},{"categories":null,"content":"sources.list | Debian Squeeze/Sid","date":"20/07/2009","objectID":"/sourceslist-debian-squeezesid/","tags":["debian"],"title":"sources.list | Debian Squeeze/Sid","uri":"/sourceslist-debian-squeezesid/"},{"categories":null,"content":"Descomente os que você quiser # deb cdrom:[Debian GNU/Linux testing \\_squeeze\\_ \u0026#8211; Official Snapshot i386 CD Binary-1 20081201-10:57]/ squeeze main #deb cdrom:[Debian GNU/Linux testing \\_squeeze\\_ \u0026#8211; Official Snapshot i386 CD Binary-1 20081201-10:57]/ squeeze main #deb-src http://ftp.br.debian.org/debian/ squeeze main #deb-src http://security.debian.org/ squeeze/updates main #deb http://ftp.br.debian.org/debian/ squeeze main # mains contribs non-frees deb http://ftp.br.debian.org/debian/ squeeze main contrib non-free deb http://security.debian.org/ squeeze/updates main contrib non-free #media deb http://www.debian-multimedia.org squeeze main # Experimental Staging deb http://www.debian-multimedia.org experimental main #virtualbox deb http://download.virtualbox.org/virtualbox/debian lenny non-free #debian experimental kernels deb http://kernel-archive.buildserver.net/debian-kernel/ trunk main # Debian Volatile http://www.debian.org/volatile/ #deb http://volatile.debian.org/debian-volatile squeeze/volatile main #deb-src http://volatile.debian.org/debian-volatile squeeze/volatile main deb http://volatile.debian.org/debian-volatile lenny/volatile main contrib non-free # Google testing repository #deb http://dl.google.com/linux/deb/ testing non-free #(wget -q -O – https://dl-ssl.google.com/linux/linux\\_signing\\_key.pub | sudo apt-key add – ) # swiftfox http://www.getswiftfox.com/index.htm #deb http://getswiftfox.com/builds/debian unstable non-free #compiz-fusion deb http://apt-get.if.uff.br lenny-ifuff compiz ### KDE 4.2 #SID(Precisa porquê várias dependências estão aqui) #deb http://ftp.de.debian.org/debian/ sid main contrib non-free #deb-src http://ftp.de.debian.org/debian/ sid main contrib non-free #Experimental(Repositório onde se encontra o KDE4) #deb http://ftp.de.debian.org/debian/ experimental main #deb-src http://ftp.de.debian.org/debian/ experimental main ","date":"20/07/2009","objectID":"/sourceslist-debian-squeezesid/:0:0","tags":["debian"],"title":"sources.list | Debian Squeeze/Sid","uri":"/sourceslist-debian-squeezesid/"},{"categories":null,"content":"Guia rápido Docker ","date":"01/01/0001","objectID":"/guia-rapido-docker/:0:0","tags":null,"title":"Guia Rápido Docker","uri":"/guia-rapido-docker/"},{"categories":null,"content":"Comandos Básicos ","date":"01/01/0001","objectID":"/guia-rapido-docker/:1:0","tags":null,"title":"Guia Rápido Docker","uri":"/guia-rapido-docker/"},{"categories":null,"content":"Container Comando Descrição docker version Verifica versão do Docker docker container run Executa container docker container ls Lista containers em execução docker container inspect \u003cID\u003e docker container ls -a Lista containers, inclusive os que já encerraram docker container stop \u003cID\u003e Para um container que está em execução docker container start \u003cID\u003e Inicia um container que está parado docker container restart \u003cID\u003e Reinicia container docker container rm \u003cID\u003e docker container rm -f \u003cID\u003e docker container top \u003cID\u003e docker container stats Exibe informações sobre containers em execução (CPU, Mem, etc) docker container exec docker container attach ","date":"01/01/0001","objectID":"/guia-rapido-docker/:1:1","tags":null,"title":"Guia Rápido Docker","uri":"/guia-rapido-docker/"},{"categories":null,"content":"Imagens Comando Descrição docker image ls Lista imagens presentes no host docker image inspect docker pull ","date":"01/01/0001","objectID":"/guia-rapido-docker/:1:2","tags":null,"title":"Guia Rápido Docker","uri":"/guia-rapido-docker/"},{"categories":null,"content":"Rede ","date":"01/01/0001","objectID":"/guia-rapido-docker/:2:0","tags":null,"title":"Guia Rápido Docker","uri":"/guia-rapido-docker/"},{"categories":null,"content":"Serviços Comando Descrição docker service create docker service ls docker service inspect docker service scale docker service ps docker service logs docker service rm ","date":"01/01/0001","objectID":"/guia-rapido-docker/:3:0","tags":null,"title":"Guia Rápido Docker","uri":"/guia-rapido-docker/"},{"categories":null,"content":"Um pouco sobre mim","date":"01/01/0001","objectID":"/sobre/","tags":null,"title":"Sobre mim","uri":"/sobre/"},{"categories":null,"content":" Olá eu sou Sidnei Weber 👋. Formado em Segurança da Informação, apaixonado por software livre, sempre buscando me aperfeiçoar e aprender novas tecnologias e tendências do mercado. Em busca de conhecimento (como diria o ET Bilu). ","date":"01/01/0001","objectID":"/sobre/:0:0","tags":null,"title":"Sobre mim","uri":"/sobre/"},{"categories":null,"content":"Conhecimentos Técnicos Redes TCP/IP; Linguagem de programação: Shell Script, PHP, Python, NodeJs; Ferramentas CMS: Wordpress, Magento; Sistemas Operacionais: Linux, Windows; Escâneres de rede (NMAP); Controle de versão (GIT); Monitoramento de sistemas e serviços (Nagios/Zabbix); Containers (Docker); Gerenciador de configurações (Ansible), Scheduler Jobs (Rundeck) Segurança em servidores Linux; Firewall Iptables, Pfsense, Fortinet; Servidores de controle de acesso á internet (Proxy – Squid), servidor DHCP, servidor web Apache, servidor de mensagens instantâneas (Openfire), servidor de impressão (Cups), servidor de usuários e arquivos (LDAP/ Samba), servidor de acesso remoto (SSH/FTP), Banco de dados (MYSQL, Postgresql). Virtualização (VirtualBox, Vmware, Proxmox); Cloud (AWS, GCloud) ","date":"01/01/0001","objectID":"/sobre/:1:0","tags":null,"title":"Sobre mim","uri":"/sobre/"},{"categories":null,"content":"Skills + usadas AWS Terraform Ansible Docker ","date":"01/01/0001","objectID":"/sobre/:1:1","tags":null,"title":"Sobre mim","uri":"/sobre/"},{"categories":null,"content":"Linguagens + usadas Python Shell Script ","date":"01/01/0001","objectID":"/sobre/:1:2","tags":null,"title":"Sobre mim","uri":"/sobre/"},{"categories":null,"content":"Certificações ","date":"01/01/0001","objectID":"/sobre/:2:0","tags":null,"title":"Sobre mim","uri":"/sobre/"},{"categories":null,"content":"Cursos Tecnólogo em Segurança da Informação - UNIP (Concluído em 2022) ","date":"01/01/0001","objectID":"/sobre/:3:0","tags":null,"title":"Sobre mim","uri":"/sobre/"}]